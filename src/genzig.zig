const builtin = @import("builtin");
const std = @import("std");
const ArrayList = std.ArrayList;
const StringHashMap = std.StringHashMap;
const json = std.json;
const StringPool = @import("stringpool.zig").StringPool;
const path_sep = std.fs.path.sep_str;

const cameltosnake = @import("cameltosnake.zig");

const common = @import("common.zig");
const fatal = common.fatal;
const Nothing = common.Nothing;
const jsonPanic = common.jsonPanic;
const jsonPanicMsg = common.jsonPanicMsg;
const jsonEnforce = common.jsonEnforce;
const jsonEnforceMsg = common.jsonEnforceMsg;
const fmtJson = common.fmtJson;

const BufferedWriter = std.io.BufferedWriter(std.mem.page_size, std.fs.File.Writer);

var arena = std.heap.ArenaAllocator.init(std.heap.page_allocator);
const allocator = arena.allocator();

const autogen_header = "//! NOTE: this file is autogenerated, DO NOT MODIFY\n";

var global_symbol_pool = StringPool.init(allocator);

var global_symbol_none: StringPool.Val = undefined;
var global_symbol_None: StringPool.Val = undefined;

var global_pass1: json.ObjectMap = undefined;
var global_notnull: json.ObjectMap = undefined;
var global_union_pointers: json.ObjectMap = undefined;

const ValueType = enum {
    Byte,
    UInt16,
    Int32,
    UInt32,
    Int64,
    UInt64,
    Single,
    Double,
    String,
    PropertyKey,
};
const global_value_type_map = std.ComptimeStringMap(ValueType, .{
    .{ "Byte", ValueType.Byte },
    .{ "UInt16", ValueType.UInt16 },
    .{ "Int32", ValueType.Int32 },
    .{ "UInt32", ValueType.UInt32 },
    .{ "Int64", ValueType.Int64 },
    .{ "UInt64", ValueType.UInt64 },
    .{ "Single", ValueType.Single },
    .{ "Double", ValueType.Double },
    .{ "String", ValueType.String },
    .{ "PropertyKey", ValueType.PropertyKey },
});
fn valueTypeToZigType(t: ValueType) []const u8 {
    return switch (t) {
        .Byte => return "u8",
        .UInt16 => return "u16",
        .Int32 => return "i32",
        .UInt32 => return "u32",
        .Int64 => return "i64",
        .UInt64 => return "u64",
        .Single => return "f32",
        .Double => return "f64",
        .String => return "[]const u8",
        .PropertyKey => @panic("cannot call valueTypeToZigType for ValueType.PropertyKey"),
    };
}

const Pass1TypeKindCategory = enum { default, ptr, com };
const pass1_type_kind_info = std.ComptimeStringMap(Pass1TypeKindCategory, .{
    .{ "Integral", .default },
    .{ "Enum", .default },
    .{ "Struct", .default },
    .{ "Union", .default },
    .{ "Com", .com },
    .{ "Pointer", .ptr },
    .{ "FunctionPointer", .ptr },
});

const NativeType = enum {
    Boolean,
    SByte,
    Byte,
    Int16,
    UInt16,
    Int32,
    UInt32,
    Int64,
    UInt64,
    Char,
    Single,
    Double,
    String,
    IntPtr,
    UIntPtr,
    Guid,
};
const global_native_type_map = std.ComptimeStringMap(NativeType, .{
    .{ "Boolean", NativeType.Boolean },
    .{ "SByte", NativeType.SByte },
    .{ "Byte", NativeType.Byte },
    .{ "Int16", NativeType.Int16 },
    .{ "UInt16", NativeType.UInt16 },
    .{ "Int32", NativeType.Int32 },
    .{ "UInt32", NativeType.UInt32 },
    .{ "Int64", NativeType.Int64 },
    .{ "UInt64", NativeType.UInt64 },
    .{ "Char", NativeType.Char },
    .{ "Single", NativeType.Single },
    .{ "Double", NativeType.Double },
    .{ "String", NativeType.String },
    .{ "IntPtr", NativeType.IntPtr },
    .{ "UIntPtr", NativeType.UIntPtr },
    .{ "Guid", NativeType.Guid },
});
fn nativeTypeToZigType(t: NativeType) []const u8 {
    return switch (t) {
        .Boolean => return "bool",
        .SByte => return "i8",
        .Byte => return "u8",
        .Int16 => return "i16",
        .UInt16 => return "u16",
        .Int32 => return "i32",
        .UInt32 => return "u32",
        .Int64 => return "i64",
        .UInt64 => return "u64",
        .Char => return "u16",
        .Single => return "f32",
        .Double => return "f64",
        .String => return "[]const u8",
        .IntPtr => return "isize",
        .UIntPtr => return "usize",
        .Guid => @panic("cannot call nativeTypeToZigType for NativeType.Guid"),
    };
}

const TargetKind = enum {
    Default,
    FunctionPointer,
    Com,
};
const target_kind_map = std.ComptimeStringMap(TargetKind, .{
    .{ "Default", TargetKind.Default },
    .{ "FunctionPointer", TargetKind.FunctionPointer },
    .{ "Com", TargetKind.Com },
});

const Module = struct {
    optional_parent: ?*Module,
    name: StringPool.Val,
    zig_basename: []const u8,
    children: StringPool.HashMap(*Module),
    file: ?SdkFile,
    pub fn alloc(optional_parent: ?*Module, name: StringPool.Val) !*Module {
        const module = try allocator.create(Module);
        module.* = Module{
            .optional_parent = optional_parent,
            .name = name,
            .zig_basename = try std.mem.concat(allocator, u8, &[_][]const u8{ name.slice, ".zig" }),
            .children = StringPool.HashMap(*Module).init(allocator),
            .file = null,
        };
        return module;
    }
};

const import_prefix_table = &[_][]const u8{
    "",
    "../",
    "../../",
    "../../../",
    "../../../../",
};

const ApiImport = struct {
    arches: ArchFlags,
    api: StringPool.Val,
};

// TODO: this is defined in std, maybe it should be pub?
const fail_allocator = std.mem.Allocator{
    .ptr = undefined,
    .vtable = &fail_allocator_vtable,
};
const fail_allocator_vtable = std.mem.Allocator.VTable{
    .alloc = failAllocatorAlloc,
    .resize = std.mem.Allocator.noResize,
    .free = std.mem.Allocator.noFree,
};
fn failAllocatorAlloc(_: *anyopaque, n: usize, alignment: u8, ra: usize) ?[*]u8 {
    _ = n;
    _ = alignment;
    _ = ra;
    return null;
}
const empty_json_object_map = json.ObjectMap{
    .ctx = .{},
    .allocator = fail_allocator,
    .unmanaged = .{},
};

fn StringPoolArrayHashMap(comptime T: type) type {
    return std.ArrayHashMap(StringPool.Val, T, StringPool.ArrayHashContext, false);
}

const AvoidLookupFn = switch (builtin.zig_backend) {
    .stage1 => fn (s: []const u8) ?Nothing,
    else => *const fn (s: []const u8) ?Nothing,
};

const SdkFile = struct {
    json_basename: []const u8,
    json_name: []const u8,
    zig_name: []const u8,
    depth: u2,
    const_exports: ArrayList(StringPool.Val),
    uses_guid: bool,
    top_level_api_imports: StringPool.HashMap(ApiImport),
    // maintin insertion order so they appear in the same order in everything.zig
    type_exports: StringPoolArrayHashMap(Nothing),
    // maintin insertion order so they appear in the same order in everything.zig
    func_exports: StringPoolArrayHashMap(Nothing),
    // this field is only needed to workaround: https://github.com/ziglang/zig/issues/4476
    tmp_func_ptr_workaround_list: ArrayList(StringPool.Val),
    param_names_to_avoid_map_get_fn: AvoidLookupFn,
    not_null_funcs: json.ObjectMap,
    not_null_funcs_applied: StringPool.HashMap(Nothing),
    union_pointer_funcs: json.ObjectMap,
    union_pointer_funcs_applied: StringPool.HashMap(Nothing),

    pub fn getWin32DirImportPrefix(self: SdkFile) []const u8 {
        return import_prefix_table[self.depth];
    }
    pub fn getSrcDirImportPrefix(self: SdkFile) []const u8 {
        return import_prefix_table[self.depth + 1];
    }

    pub fn addApiImport(self: *SdkFile, arches: ArchFlags, name: []const u8, api: []const u8, parents: json.Array) !void {
        if (!std.mem.eql(u8, self.json_name, api)) {
            const top_level_symbol = try global_symbol_pool.add(if (parents.items.len == 0) name else parents.items[0].string);
            const pool_api = try global_symbol_pool.add(api);
            if (self.top_level_api_imports.getPtr(top_level_symbol)) |import| {
                jsonEnforceMsg(pool_api.eql(import.api), "symbol conflict '{s}', api mismatch '{s}' and '{s}'", .{ name, pool_api, import.api });
                //jsonEnforceMsg(other.parents.len == 0, "symbol conflict '{s}', parents mismatch", .{name});
                const new_flags = import.arches.flags | arches.flags;
                if (new_flags != import.arches.flags) {
                    import.arches.flags = new_flags;
                }
            } else {
                try self.top_level_api_imports.put(top_level_symbol, .{ .arches = arches, .api = pool_api });
            }
        }
    }
};

const notnull_filename: []const u8 = "notnull.json";
const union_pointers_filename: []const u8 = "unionpointers.json";

const Times = struct {
    git_fetch_time_millis: u64 = 0,
    parse_time_millis: i64 = 0,
    read_time_millis: i64 = 0,
    generate_time_millis: i64 = 0,
};
var global_times = Times{};

pub fn main() !u8 {
    const main_start_millis = std.time.milliTimestamp();
    var print_time_summary = false;
    defer {
        if (print_time_summary) {
            var total_millis = std.time.milliTimestamp() - main_start_millis;
            if (total_millis == 0) total_millis = 1; // prevent divide by 0
            std.debug.print("Git Fetch Time: {} millis ({}%)\n", .{ global_times.git_fetch_time_millis, @divTrunc(100 * global_times.git_fetch_time_millis, @as(u64, @intCast(total_millis))) });
            std.debug.print("Parse Time: {} millis ({}%)\n", .{ global_times.parse_time_millis, @divTrunc(100 * global_times.parse_time_millis, total_millis) });
            std.debug.print("Read Time : {} millis ({}%)\n", .{ global_times.read_time_millis, @divTrunc(100 * global_times.read_time_millis, total_millis) });
            std.debug.print("Gen Time  : {} millis ({}%)\n", .{ global_times.generate_time_millis, @divTrunc(100 * global_times.generate_time_millis, total_millis) });
            std.debug.print("Total Time: {} millis\n", .{total_millis});
        }
    }
    global_symbol_none = try global_symbol_pool.add("none");
    global_symbol_None = try global_symbol_pool.add("None");

    const all_args = try std.process.argsAlloc(allocator);
    // don't care about freeing args

    const cmd_args = all_args[1..];
    if (cmd_args.len != 5) {
        std.log.err("expected 5 cmdline arguments but got {}", .{cmd_args.len});
        return 1;
    }
    const win32json_path = cmd_args[0];
    const pass1_json = cmd_args[1];
    const src_path = cmd_args[2];
    const zigwin32_repo = cmd_args[3];
    const fetch_enabled_str = cmd_args[4];

    const fetch_enabled = if (std.mem.eql(u8, fetch_enabled_str, "fetch"))
        true
    else if (std.mem.eql(u8, fetch_enabled_str, "nofetch"))
        false
    else
        fatal("expected 'fetch' or 'nofetch' but got '{s}'", .{fetch_enabled_str});

    var win32json_dir = try std.fs.cwd().openDir(win32json_path, .{});
    defer win32json_dir.close();

    std.fs.cwd().access(zigwin32_repo, .{}) catch |e| switch (e) {
        error.FileNotFound => {
            std.debug.print("error: zigwin32 repository to write generated files to does not exist, clone it with:\n", .{});
            std.debug.print("    git clone https://github.com/marlersoft/zigwin32 {s}\n", .{zigwin32_repo});
            std.os.exit(0xff);
        },
        else => return e,
    };

    try run("git clean", &.{"git", "-C", zigwin32_repo, "clean", "-xffd"});
    try run("git reset", &.{"git", "-C", zigwin32_repo, "reset", "--hard", "HEAD"});
    {
        const result = try std.ChildProcess.run(.{
            .allocator = allocator,
            .argv = &.{
                "git",
                "-C",
                zigwin32_repo,
                "status",
                "--porcelain",
            },
        });
        defer {
            allocator.free(result.stderr);
            allocator.free(result.stdout);
        }
        if (result.stderr.len > 0) {
            std.log.err("stderr output from git status:\n---\n{s}\n---\n", .{result.stderr});
        }
        if (result.stdout.len > 0) {
            std.log.info("TODO: handle non-clean git status:\n---\n{s}\n---\n", .{result.stdout});
            return error.Todo;
        }
    }

    const version = blk: {
        const file = try win32json_dir.openFile("version.txt", .{});
        defer file.close();
        break :blk try file.reader().readAllAlloc(allocator, 100);
    };
    defer allocator.free(version);

    {
        if (fetch_enabled) {
            var timer = try std.time.Timer.start();
            const branch_exists = try gitFetch(zigwin32_repo, version);
            global_times.git_fetch_time_millis = timer.read() / std.time.ns_per_ms;
            if (branch_exists) {
                const origin_branch = try std.fmt.allocPrint(allocator, "origin/{s}", .{version});
                defer allocator.free(origin_branch);
                try run("git checkout", &.{"git", "-C", zigwin32_repo, "checkout", origin_branch, "-B", version});
            } else if (try gitBranchExists(zigwin32_repo, version)) {
                try run("git checkout", &.{"git", "-C", zigwin32_repo, "checkout", "-B", version});
            } else {
                std.log.err(
                    "there's no local nor remote branch for version '{s}' in the zigwin32 repo.",
                    .{version},
                );
                fatalSuggestNewVersion(version, zigwin32_repo);
            }
        } else if (try gitBranchExists(zigwin32_repo, version)) {
            try run("git checkout", &.{"git", "-C", zigwin32_repo, "checkout", "-B", version});
        } else {
            std.log.err(
                "there's no local branch for version '{s}' in the zigwin32 repo and fetch has been disabled.",
                .{version},
            );
            fatalSuggestNewVersion(version, zigwin32_repo);
        }
    }

    global_pass1 = try readJson(pass1_json);
    global_notnull = try readJson(notnull_filename);
    global_union_pointers = try readJson(union_pointers_filename);

    var out_dir = try std.fs.cwd().openDir(zigwin32_repo, .{});
    defer out_dir.close();
    out_dir.deleteFile("win32.zig") catch |e| switch (e) {
        error.FileNotFound => {},
        else => return e,
    };
    out_dir.deleteFile("build.zig") catch |e| switch (e) {
        error.FileNotFound => {},
        else => return e,
    };
    try cleanDir(out_dir, "win32");
    var out_win32_dir = try out_dir.openDir("win32", .{});
    defer out_win32_dir.close();

    const src_modules = &[_][]const u8{
        "zig",
        "missing",
        "windowlongptr",
    };

    const root_module = try Module.alloc(null, try global_symbol_pool.add("win32"));

    {
        var api_dir = try win32json_dir.openDir("api", .{ .iterate = true });
        defer api_dir.close();

        var api_list = std.ArrayList([]const u8).init(allocator);
        defer {
            for (api_list.items) |api_name| {
                allocator.free(api_name);
            }
            api_list.deinit();
        }
        try common.readApiList(api_dir, &api_list);

        // sort the list of APIs so our api order is not dependent on the file-system ordering
        std.mem.sort([]const u8, api_list.items, Nothing{}, common.asciiLessThanIgnoreCase);

        std.debug.print("-----------------------------------------------------------------------\n", .{});
        std.debug.print("loading {} api json files...\n", .{api_list.items.len});

        for (api_list.items, 0..) |api_json_basename, api_index| {
            const api_num = api_index + 1;
            std.debug.print("{}/{}: loading '{s}'\n", .{ api_num, api_list.items.len, api_json_basename });
            //
            // TODO: would things run faster if I just memory mapped the file?
            //
            var file = try api_dir.openFile(api_json_basename, .{});
            defer file.close();
            try readAndGenerateApiFile(root_module, out_win32_dir, api_json_basename, file);
        }

        for (src_modules ++ &[_][]const u8{
            "everything",
        }) |submodule_str| {
            const submodule = try global_symbol_pool.add(submodule_str);
            try root_module.children.put(submodule, try Module.alloc(root_module, submodule));
        }

        try generateContainerModules(out_dir, root_module);
        try generateEverythingModule(out_win32_dir, root_module);
    }

    // copy zig.zig, missing.zig and windowlongptr.zig modules
    {
        var src_dir = try std.fs.cwd().openDir(src_path, .{});
        defer src_dir.close();
        inline for (src_modules) |mod| {
            try src_dir.copyFile(mod ++ ".zig", out_win32_dir, mod ++ ".zig", .{});
        }
        try src_dir.copyFile("zigwin32.build.zig", out_dir, "build.zig", .{});
    }
    print_time_summary = true;

    try run("git status", &.{"git", "-C", zigwin32_repo, "status"});

    return 0;
}

fn fatalSuggestNewVersion(version: []const u8, zigwin32_repo: []const u8) noreturn {
    fatal(
        \\If {s} a new version/branch, create it with:
        \\    git -C {s} checkout 6f193db913584e59a366d94553d8271a8d160309 -b {0s}
        \\
        , .{version, zigwin32_repo},
    );
}

fn childProcFailed(term: std.ChildProcess.Term) bool {
    return switch (term) {
        .Exited => |code| code != 0,
        .Signal => true,
        .Stopped => true,
        .Unknown => true,
    };
}
const FormatTerm = struct {
    term: std.ChildProcess.Term,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        _ = fmt;
        _ = options;
        switch (self.term) {
            .Exited => |code| try writer.print("exited with code {}", .{code}),
            .Signal => |sig| try writer.print("exited with signal {}", .{sig}),
            .Stopped => |sig| try writer.print("stopped with signal {}", .{sig}),
            .Unknown => |sig| try writer.print("terminated abnormally with signal {}", .{sig}),
        }
    }
};
fn fmtTerm(term: std.ChildProcess.Term) FormatTerm {
    return .{ .term = term };
}

const FormatArgv = struct {
    argv: []const []const u8,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        _ = fmt;
        _ = options;
        var prefix: []const u8 = "";
        for (self.argv) |arg| {
            try writer.print("{s}{s}", .{prefix, arg});
            prefix = " ";
        }
    }
};
fn fmtArgv(argv: []const []const u8) FormatArgv {
    return .{ .argv = argv };
}

fn run(name: []const u8, argv: []const []const u8) !void {
    var child = std.ChildProcess.init(argv, allocator);
    std.log.info("{}", .{fmtArgv(child.argv)});
    try child.spawn();
    const term = try child.wait();
    if (childProcFailed(term)) {
        fatal("{s} {}", .{name, fmtTerm(term)});
    }
}
fn gitFetch(path: []const u8, branch: []const u8) !bool {
    var child = std.ChildProcess.init(&.{
        "git",
        "-C", path,
        "fetch",
        "origin",
        branch,
    }, allocator);
    std.log.info("{}", .{fmtArgv(child.argv)});
    try child.spawn();
    const term = try child.wait();
    switch (term) {
        .Exited => |code| return code == 0,
        else => fatal("git fetch {}", .{fmtTerm(term)}),
    }
}

fn gitBranchExists(path: []const u8, branch: []const u8) !bool {
    var child = std.ChildProcess.init(&.{
        "git",
        "-C", path,
        "rev-parse",
        "--verify",
        branch,
    }, allocator);
    std.log.info("{}", .{fmtArgv(child.argv)});
    try child.spawn();
    const term = try child.wait();
    switch (term) {
        .Exited => |code| return code == 0,
        else => fatal("git fetch {}", .{fmtTerm(term)}),
    }
}

fn readJson(filename: []const u8) !std.json.ObjectMap {
    const content = blk: {
        const file = try std.fs.cwd().openFile(filename, .{});
        defer file.close();
        break :blk try file.readToEndAlloc(allocator, std.math.maxInt(usize));
    };

    const json_tree = blk: {
        //var parser = json.Parser.init(allocator, false); // false is copy_strings
        //defer parser.deinit();

        const start = if (std.mem.startsWith(u8, content, "\xEF\xBB\xBF")) 3 else @as(usize, 0);
        const json_content = content[start..];
        std.log.info("parsing '{s}'...", .{filename});
        //break :blk try parser.parse(json_content);
        // TODO: parseFromSliceLeaky?
        break :blk try json.parseFromSlice(json.Value, allocator, json_content, .{});
    };
    return json_tree.value.object;
}

fn gatherSdkFiles(sdk_files: *ArrayList(*SdkFile), module: *Module) anyerror!void {
    if (module.file) |_| {
        try sdk_files.append(&module.file.?);
    }
    const children = try common.allocMapValues(allocator, *Module, module.children);
    defer allocator.free(children);
    std.mem.sort(*Module, children, {}, moduleLessThan); // sort so the order is predictable
    for (children) |child| {
        try gatherSdkFiles(sdk_files, child);
    }
}

fn generateEverythingModule(out_win32_dir: std.fs.Dir, root_module: *Module) !void {
    var everything_file = try out_win32_dir.createFile("everything.zig", .{});
    defer everything_file.close();
    var buffered_writer = BufferedWriter{ .unbuffered_writer = everything_file.writer() };
    defer buffered_writer.flush() catch @panic("flush failed");
    const writer = buffered_writer.writer();
    try writer.writeAll(comptime removeCr(autogen_header ++
        \\//! This module contains aliases to ALL symbols inside the Win32 SDK.  It allows
        \\//! an application to access any and all symbols through a single import.
        \\
        \\pub const L = @import("zig.zig").L;
        \\
        \\pub usingnamespace @import("missing.zig");
        \\
    ));

    var sdk_files = ArrayList(*SdkFile).init(allocator);
    defer sdk_files.deinit();

    try gatherSdkFiles(&sdk_files, root_module);

    // TODO: workaround issue where constants/functions are defined more than once, not sure what the right solution
    //       is for all these, maybe some modules are not compatible with each other.  This could just be the permanent
    //       solution as well, if there are conflicts, we could just say the user has to import the specific module they want.
    // TODO: I think the right way to reslve conflicts in everything.zig is to have a priority order for the apis.
    //       If I just sort the API's in the right order, more common apis go first, then my current logic will work.
    var shared_export_map = StringPool.HashMap(*SdkFile).init(allocator);
    defer shared_export_map.deinit();

    // populate the shared_export_map, start with types first
    // because types can be referenced within the modules (unlike consts/functions)
    for (sdk_files.items) |sdk_file| {
        var type_export_it = sdk_file.type_exports.iterator();
        while (type_export_it.next()) |kv| {
            const type_name = kv.key_ptr.*;
            if (shared_export_map.get(type_name)) |_| {
                //try shared_export_map.put(type_name, .{ .first_sdk_file_ptr = entry.first_sdk_file_ptr, .duplicates = entry.duplicates + 1 });
            } else {
                //try shared_export_map.put(type_name, .{ .first_sdk_file_ptr = sdk_file, .duplicates = 0 });
                try shared_export_map.put(type_name, sdk_file);
            }
        }
    }

    for (sdk_files.items) |sdk_file| {
        try writer.print("// {s} exports {} constants:\n", .{ sdk_file.zig_name, sdk_file.const_exports.items.len });
        for (sdk_file.const_exports.items) |constant| {
            if (shared_export_map.get(constant)) |other_sdk_file| {
                try writer.print("// WARNING: redifinition of constant symbol '{s}' in module '{s}' (going with module '{s}')\n", .{ constant, sdk_file.zig_name, other_sdk_file.zig_name });
            } else {
                try writer.print("pub const {s} = @import(\"../win32.zig\").{s}.{0s};\n", .{ constant, sdk_file.zig_name });
                try shared_export_map.put(constant, sdk_file);
            }
        }
        try writer.print("// {s} exports {} types:\n", .{ sdk_file.zig_name, sdk_file.type_exports.count() });
        var export_it = sdk_file.type_exports.iterator();
        while (export_it.next()) |kv| {
            const type_name = kv.key_ptr.*;
            const first_type_sdk = shared_export_map.get(type_name) orelse unreachable;
            if (first_type_sdk != sdk_file) {
                try writer.print("// WARNING: redefinition of type symbol '{s}' from '{s}', going with '{s}'\n", .{ type_name, sdk_file.zig_name, first_type_sdk.zig_name });
            } else {
                try writer.print("pub const {s} = @import(\"../win32.zig\").{s}.{0s};\n", .{ type_name, sdk_file.zig_name });
            }
        }
        try writer.print("// {s} exports {} functions:\n", .{ sdk_file.zig_name, sdk_file.func_exports.count() });
        var func_it = sdk_file.func_exports.iterator();
        while (func_it.next()) |kv| {
            const func = kv.key_ptr.*;
            if (shared_export_map.get(func)) |other_sdk_file| {
                try writer.print("// WARNING: redifinition of function '{s}' in module '{s}' (going with module '{s}')\n", .{ func, sdk_file.zig_name, other_sdk_file.zig_name });
            } else {
                try writer.print("pub const {s} = @import(\"../win32.zig\").{s}.{0s};\n", .{ func, sdk_file.zig_name });
                try shared_export_map.put(func, sdk_file);
            }
        }
    }
}

fn moduleLessThan(context: void, lhs: *Module, rhs: *Module) bool {
    _ = context;
    return std.ascii.lessThanIgnoreCase(lhs.name.slice, rhs.name.slice);
}

fn generateContainerModules(dir: std.fs.Dir, module: *Module) anyerror!void {
    if (module.children.count() == 0) {
        return;
    }

    var file = blk: {
        if (module.file) |_| {
            const file = try dir.openFile(module.zig_basename, .{ .mode = .write_only });
            try file.seekFromEnd(0);
            break :blk file;
        }
        break :blk try dir.createFile(module.zig_basename, .{});
    };
    defer file.close();
    var buffered_writer = BufferedWriter{ .unbuffered_writer = file.writer() };
    defer buffered_writer.flush() catch @panic("flush failed");
    const writer = buffered_writer.writer();

    const children = try common.allocMapValues(allocator, *Module, module.children);
    defer allocator.free(children);

    std.mem.sort(*Module, children, {}, moduleLessThan);
    if (module.file) |_| {
        try writer.print("//--------------------------------------------------------------------------------\n", .{});
        try writer.print("// Section: SubModules ({})\n", .{children.len});
        try writer.print("//--------------------------------------------------------------------------------\n", .{});
    } else {
        try writer.writeAll(autogen_header);
    }
    for (children) |child| {
        try writer.print("pub const {s} = @import(\"{s}/{0s}.zig\");\n", .{ child.name, module.name.slice });
    }

    if (module.file) |_| {} else {
        try writer.writeAll(comptime removeCr(
            \\test {
            \\    @import("std").testing.refAllDecls(@This());
            \\}
            \\
        ));
    }

    var next_dir = try dir.openDir(module.name.slice, .{});
    defer next_dir.close();

    for (children) |child| {
        try generateContainerModules(next_dir, child);
    }
}

fn readAndGenerateApiFile(root_module: *Module, out_dir: std.fs.Dir, json_basename: []const u8, file: std.fs.File) !void {
    const read_start_millis = std.time.milliTimestamp();
    const content = try file.readToEndAlloc(allocator, std.math.maxInt(usize));
    const read_end_millis = std.time.milliTimestamp();
    global_times.read_time_millis += read_end_millis - read_start_millis;
    defer allocator.free(content);
    std.debug.print("  read {} bytes\n", .{content.len});

    // Parsing the JSON is VERY VERY SLOW!!!!!!
    var json_tree = blk: {
        //var parser = json.Parser.init(allocator, false); // false is copy_strings
        //defer parser.deinit();
        //break :blk try parser.parse(content);
        break :blk try json.parseFromSlice(json.Value, allocator, content, .{});
    };
    defer json_tree.deinit();
    global_times.parse_time_millis += std.time.milliTimestamp() - read_end_millis;

    const json_basename_copy = try allocator.dupe(u8, json_basename);
    const json_name = json_basename_copy[0 .. json_basename_copy.len - ".json".len];
    const zig_name = try cameltosnake.camelToSnakeAlloc(allocator, json_name);
    errdefer allocator.free(zig_name);

    var module_dir = out_dir;
    defer if (module_dir.fd != out_dir.fd) module_dir.close();

    var module: *Module = root_module;
    var depth: u2 = 0;

    {
        var it = std.mem.tokenize(u8, zig_name, ".");
        while (it.next()) |name_part| {
            if (module != root_module) {
                depth += 1;
                if (module.children.count() == 0) {
                    try module_dir.makeDir(module.name.slice);
                }
                const next_dir = try module_dir.openDir(module.name.slice, .{});
                if (module_dir.fd != out_dir.fd)
                    module_dir.close();
                module_dir = next_dir;
            }

            const name_pool = try global_symbol_pool.add(name_part);
            if (module.children.get(name_pool)) |existing| {
                module = existing;
            } else {
                const new_module = try Module.alloc(module, name_pool);
                try module.children.put(name_pool, new_module);
                module = new_module;
            }
        }
    }

    if (module.file) |_| {
        jsonPanicMsg("qualified name '{s}' already has an sdk file?", .{zig_name});
    }

    var not_null_funcs = empty_json_object_map;
    if (global_notnull.get(json_name)) |*api_node| {
        const api_obj = api_node.object;
        try jsonObjEnforceKnownFieldsOnly(api_obj, &[_][]const u8{"Functions"}, notnull_filename);
        not_null_funcs = (try jsonObjGetRequired(api_obj, "Functions", notnull_filename)).object;
    }
    var union_pointer_funcs = empty_json_object_map;
    if (global_union_pointers.get(json_name)) |*api_node| {
        const api_obj = api_node.object;
        try jsonObjEnforceKnownFieldsOnly(api_obj, &[_][]const u8{"Functions"}, union_pointers_filename);
        union_pointer_funcs = (try jsonObjGetRequired(api_obj, "Functions", union_pointers_filename)).object;
    }

    module.file = SdkFile{
        .json_basename = json_basename_copy,
        .json_name = json_name,
        .zig_name = zig_name,
        .depth = depth,
        .const_exports = ArrayList(StringPool.Val).init(allocator),
        .uses_guid = false,
        .top_level_api_imports = StringPool.HashMap(ApiImport).init(allocator),
        .type_exports = StringPoolArrayHashMap(Nothing).init(allocator),
        .func_exports = StringPoolArrayHashMap(Nothing).init(allocator),
        .tmp_func_ptr_workaround_list = ArrayList(StringPool.Val).init(allocator),
        .param_names_to_avoid_map_get_fn = getParamNamesToAvoidMapGetFn(json_name),
        .not_null_funcs = not_null_funcs,
        .not_null_funcs_applied = StringPool.HashMap(Nothing).init(allocator),
        .union_pointer_funcs = union_pointer_funcs,
        .union_pointer_funcs_applied = StringPool.HashMap(Nothing).init(allocator),
    };

    const generate_start_millis = std.time.milliTimestamp();
    try generateFile(module_dir, module, json_tree);
    global_times.generate_time_millis += std.time.milliTimestamp() - generate_start_millis;
}

pub fn EmptyComptimeStringMap(comptime V: type) type {
    return struct {
        pub fn get(str: []const u8) ?V {
            _ = str;
            return null;
        }
    };
}

fn ArchSpecificMap(comptime T: type) type {
    return StringPoolArrayHashMap(ArchSpecificObjects(T));
}

fn generateFile(module_dir: std.fs.Dir, module: *Module, tree: json.Parsed(json.Value)) !void {
    const sdk_file = &module.file.?;

    var out_file = try module_dir.createFile(module.zig_basename, .{});
    defer out_file.close();
    var buffered_writer = BufferedWriter{ .unbuffered_writer = out_file.writer() };
    defer buffered_writer.flush() catch @panic("flush failed");
    var code_writer = CodeWriter{ .writer = buffered_writer.writer(), .depth = 0, .midline = false };
    // need to specify type explicitly because of https://github.com/ziglang/zig/issues/12795
    const writer: *CodeWriter = &code_writer;

    try writer.writeBlock(autogen_header);
    // We can't import the everything module because it will re-introduce the same symbols we are exporting
    //try writer.print("usingnamespace @import(\"everything.zig\");\n", .{});
    const root_obj = tree.value.object;
    const constants_array = (try jsonObjGetRequired(root_obj, "Constants", sdk_file)).array;
    const types_array = (try jsonObjGetRequired(root_obj, "Types", sdk_file)).array;
    const functions_array = (try jsonObjGetRequired(root_obj, "Functions", sdk_file)).array;
    const unicode_aliases = (try jsonObjGetRequired(root_obj, "UnicodeAliases", sdk_file)).array;
    try writer.line("//--------------------------------------------------------------------------------");
    try writer.linef("// Section: Constants ({})", .{constants_array.items.len});
    try writer.line("//--------------------------------------------------------------------------------");
    for (constants_array.items) |*constant_node_ptr| {
        try generateConstant(sdk_file, writer, constant_node_ptr.object);
    }
    std.debug.assert(constants_array.items.len == sdk_file.const_exports.items.len);
    try writer.line("");
    try writer.line("//--------------------------------------------------------------------------------");
    try writer.linef("// Section: Types ({})", .{types_array.items.len});
    try writer.line("//--------------------------------------------------------------------------------");
    {
        var arch_specific_types = ArchSpecificMap(json.ObjectMap).init(allocator);
        defer arch_specific_types.deinit();
        var enum_alias_conflicts = StringPool.HashMap(StringPool.Val).init(allocator);
        defer enum_alias_conflicts.deinit();
        for (types_array.items) |*type_node_ptr| {
            try generateType(sdk_file, writer, &arch_specific_types, type_node_ptr.object, &enum_alias_conflicts);
            try writer.line("");
        }
        var it = arch_specific_types.iterator();
        while (it.next()) |entry| {
            const name = entry.key_ptr.*;
            try writer.linef("pub const {s} = switch(@import(\"{s}zig.zig\").arch) {{", .{ name, import_prefix_table[sdk_file.depth] });
            var combined_arches: u8 = 0;
            for (entry.value_ptr.getItemsConst()) |object| {
                combined_arches |= object.arches.flags;
                var buf: [40]u8 = undefined;
                const def_prefix = buf[0..try object.arches.formatCase(&buf)];
                const kind = (try jsonObjGetRequired(object.obj, "Kind", sdk_file)).string;
                writer.depth += 1;
                defer writer.depth -= 1;
                try generateTypeDefinition(sdk_file, writer, object.obj, &enum_alias_conflicts, object.arches, kind, name, def_prefix, ",");
            }
            if (combined_arches != ArchFlags.all.flags) {
                //try writer.line("    else => @compileError(\"unsupported on this arch\"),");
                try writer.line("    else => usize, // NOTE: this should be a @compileError but can't because of https://github.com/ziglang/zig/issues/9682");
            }
            try writer.line("};");
        }
    }
    try writer.line("");
    try writer.line("//--------------------------------------------------------------------------------");
    try writer.linef("// Section: Functions ({})", .{functions_array.items.len});
    try writer.line("//--------------------------------------------------------------------------------");
    for (functions_array.items) |*function_node_ptr| {
        try generateFunction(sdk_file, writer, function_node_ptr.object, .fixed);
        try writer.line("");
    }
    std.debug.assert(functions_array.items.len >= sdk_file.func_exports.count());
    try writer.line("");
    try writer.line("//--------------------------------------------------------------------------------");
    try writer.linef("// Section: Unicode Aliases ({})", .{unicode_aliases.items.len});
    try writer.line("//--------------------------------------------------------------------------------");
    try generateUnicodeAliases(sdk_file, writer, unicode_aliases.items);
    const import_total = @intFromBool(sdk_file.uses_guid) + sdk_file.top_level_api_imports.count();
    try writer.line("//--------------------------------------------------------------------------------");
    try writer.linef("// Section: Imports ({})", .{import_total});
    try writer.line("//--------------------------------------------------------------------------------");
    if (sdk_file.uses_guid) {
        try writer.linef("const Guid = @import(\"{s}zig.zig\").Guid;", .{sdk_file.getWin32DirImportPrefix()});
    }
    {
        var arch_specific_imports = ArchSpecificMap(StringPool.Val).init(allocator);
        defer arch_specific_imports.deinit();

        const NamedApiImport = struct {
            name: StringPool.Val,
            import: ApiImport,
            pub fn asciiLessThanIgnoreCase(_: Nothing, lhs: @This(), rhs: @This()) bool {
                return std.ascii.lessThanIgnoreCase(lhs.name.slice, rhs.name.slice);
            }
        };
        var sorted_imports = std.ArrayList(NamedApiImport).init(allocator);
        defer sorted_imports.deinit();
        {
            var it = sdk_file.top_level_api_imports.iterator();
            while (it.next()) |entry| {
                try sorted_imports.append(.{ .name = entry.key_ptr.*, .import = entry.value_ptr.* });
            }
        }
        std.mem.sort(NamedApiImport, sorted_imports.items, Nothing{}, NamedApiImport.asciiLessThanIgnoreCase);

        // print the arch-agnostic imports first
        for (sorted_imports.items) |import| {
            const api_upper = import.import.api;
            const arches = import.import.arches;

            if (arches.flags != ArchFlags.all.flags) {
                try addArchSpecific(StringPool.Val, &arch_specific_imports, import.name, arches, api_upper);
            } else {
                // TODO: should I cache this mapping from api ref to api import path?
                const api_path = try allocApiImportPathFromRef(api_upper.slice);
                defer allocator.free(api_path);
                try writer.linef("const {s} = @import(\"{s}{s}.zig\").{0s};", .{ import.name, sdk_file.getWin32DirImportPrefix(), api_path });
            }
        }
        if (arch_specific_imports.count() > 0) {
            try writer.linef("// {} arch-specific imports", .{arch_specific_imports.count()});
            var arch_imports_it = arch_specific_imports.iterator();
            while (arch_imports_it.next()) |arch_import_node| {
                const name = arch_import_node.key_ptr.*;
                try writer.linef("const {s} = switch(@import(\"{s}zig.zig\").arch) {{", .{ name, import_prefix_table[sdk_file.depth] });
                var combined_arches: u8 = 0;
                for (arch_import_node.value_ptr.getItemsConst()) |object| {
                    combined_arches |= object.arches.flags;
                    var buf: [40]u8 = undefined;
                    const def_prefix = buf[0..try object.arches.formatCase(&buf)];
                    const api_upper = object.obj;
                    // TODO: should I cache this mapping from api ref to api import path?
                    const api_path = try allocApiImportPathFromRef(api_upper.slice);
                    defer allocator.free(api_path);
                    try writer.linef("    {s}@import(\"{s}{s}.zig\").{s},", .{ def_prefix, sdk_file.getWin32DirImportPrefix(), api_path, name });
                }
                if (combined_arches != ArchFlags.all.flags) {
                    //try writer.line("    else => @compileError(\"unsupported on this arch\"),");
                    try writer.line("    else => usize, // NOTE: this should be a @compileError but can't because of https://github.com/ziglang/zig/issues/9682");
                }
                try writer.line("};");
            }
        }
    }

    try writer.writeBlock(comptime removeCr(
        \\
        \\test {
        \\
    ));
    if (sdk_file.tmp_func_ptr_workaround_list.items.len > 0) {
        try writer.line("    // The following '_ = <FuncPtrType>' lines are a workaround for https://github.com/ziglang/zig/issues/4476");
        for (sdk_file.tmp_func_ptr_workaround_list.items) |func_ptr_type| {
            try writer.linef("    if (@hasDecl(@This(), \"{s}\")) {{ _ = {0s}; }}", .{func_ptr_type});
        }
        try writer.line("");
    }
    try writer.writeBlock(comptime removeCr(
        \\    @setEvalBranchQuota(
        \\        comptime @import("std").meta.declarations(@This()).len * 3
        \\    );
        \\
        \\    // reference all the pub declarations
        \\    if (!@import("builtin").is_test) return;
        \\    inline for (comptime @import("std").meta.declarations(@This())) |decl| {
        \\        _ = @field(@This(), decl.name);
        \\    }
        \\}
        \\
    ));

    // check that all notnull stuff was applied
    {
        var it = sdk_file.not_null_funcs.iterator();
        var error_count: u32 = 0;
        while (it.next()) |api| {
            const pool_name = try global_symbol_pool.add(api.key_ptr.*);
            if (sdk_file.not_null_funcs_applied.get(pool_name)) |_| {} else {
                std.log.err("notnull.json api '{s}' function '{s}' was not applied", .{ sdk_file.json_name, pool_name });
                error_count += 1;
            }
        }
        sdk_file.not_null_funcs_applied.deinit();
        if (error_count > 0) {
            std.os.exit(0xff);
        }
    }
    // check that all union_pointer data was applied
    {
        var it = sdk_file.union_pointer_funcs.iterator();
        var error_count: u32 = 0;
        while (it.next()) |api| {
            const pool_name = try global_symbol_pool.add(api.key_ptr.*);
            if (sdk_file.union_pointer_funcs_applied.get(pool_name)) |_| {} else {
                std.log.err("notnull.json api '{s}' function '{s}' was not applied", .{ sdk_file.json_name, pool_name });
                error_count += 1;
            }
        }
        sdk_file.union_pointer_funcs_applied.deinit();
        if (error_count > 0) {
            std.os.exit(0xff);
        }
    }
}

fn typeIsVoid(type_obj: json.ObjectMap, sdk_file: *SdkFile) !bool {
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).string;
    if (std.mem.eql(u8, kind, "Native")) {
        const name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).string;
        return std.mem.eql(u8, name, "void");
    }
    return false;
}

// TODO: should I cache this mapping from api ref to api import path?
fn allocApiImportPathFromRef(api_ref: []const u8) ![]u8 {
    const api_path = try cameltosnake.camelToSnakeAlloc(allocator, api_ref);
    for (api_path, 0..) |c, i| {
        if (c == '.')
            api_path[i] = '/';
    }
    return api_path;
}

// convenient function that combines both adding type refs and creating a formatter
// for the type.   These 2 operations are orthogonal, however, combining them helps ensure
// that generating a type reference is not done without also adding that reference to the api
// being generated.
fn addTypeRefs(sdk_file: *SdkFile, arches: ArchFlags, type_ref: json.ObjectMap, options: TypeRefFormatter.Options, nested_context: ?*const NestedContext) anyerror!TypeRefFormatter {
    try addTypeRefsNoFormatter(sdk_file, arches, type_ref);
    return fmtTypeRef(type_ref, arches, options, nested_context);
}

fn addTypeRefsNoFormatter(sdk_file: *SdkFile, arches: ArchFlags, type_ref: json.ObjectMap) anyerror!void {
    const kind = (try jsonObjGetRequired(type_ref, "Kind", sdk_file)).string;
    if (std.mem.eql(u8, kind, "Native")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8{ "Kind", "Name" }, sdk_file);
        const name = (try jsonObjGetRequired(type_ref, "Name", sdk_file)).string;
        if (std.mem.eql(u8, name, "Void")) {
            // void is special
        } else if (std.mem.eql(u8, name, "Guid")) {
            sdk_file.uses_guid = true;
        } else if (global_native_type_map.get(name) == null) {
            std.debug.panic("unknown Native type '{s}'", .{name});
        }
    } else if (std.mem.eql(u8, kind, "ApiRef")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8{ "Kind", "Name", "TargetKind", "Api", "Parents" }, sdk_file);
        const tmp_name = (try jsonObjGetRequired(type_ref, "Name", sdk_file)).string;
        const api = (try jsonObjGetRequired(type_ref, "Api", sdk_file)).string;
        const parents = (try jsonObjGetRequired(type_ref, "Parents", sdk_file)).array;
        try sdk_file.addApiImport(arches, tmp_name, api, parents);
    } else if (std.mem.eql(u8, kind, "PointerTo")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8{ "Kind", "Child" }, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, arches, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).object);
    } else if (std.mem.eql(u8, kind, "Array")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8{ "Kind", "Shape", "Child" }, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, arches, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).object);
    } else if (std.mem.eql(u8, kind, "LPArray")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8{ "Kind", "NullNullTerm", "CountConst", "CountParamIndex", "Child" }, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, arches, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).object);
    } else if (std.mem.eql(u8, kind, "MissingClrType")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8{ "Kind", "Name", "Namespace" }, sdk_file);
    } else {
        jsonPanicMsg("kind '{s}' is not implemented", .{kind});
    }
}

const ContainerKind = enum { Struct, Union };
pub fn getAnonKind(s: []const u8) ?ContainerKind {
    //if (std.mem.startsWith(u8, s, "_Anonymous")) {
    if (std.mem.endsWith(u8, s, "_e__Struct"))
        return .Struct;
    if (std.mem.endsWith(u8, s, "_e__Union"))
        return .Union;
    //    jsonPanicMsg("type '{s}' starts with '_Anonymous' but does not have an expected end", .{s});
    //}
    return null;
}

// Provides access to nested types accessible from the current scope
const NestedContext = struct {
    nested_types: json.Array,
    parent: ?*const NestedContext,

    pub fn contains(self: NestedContext, name: []const u8) bool {
        std.debug.assert(self.nested_types.items.len > 0);
        for (self.nested_types.items) |*nested_type_node_ptr| {
            const nested_type_obj = nested_type_node_ptr.object;
            const nested_name = (nested_type_obj.get("Name") orelse jsonPanic()).string;
            if (std.mem.eql(u8, nested_name, name))
                return true;
        }
        if (self.parent) |p| return p.contains(name);
        return false;
    }
};

const NullModifier = u3;

// we need to know if the type is the top-level type or a child type of something like a pointer
// so we can generate the correct `void` type.  Top level void types become void, but pointers
// to void types must become pointers to the `anyopaque` type.
// Need to know if it is an array specifically because array pointers cannot point to opaque types
// with an unknown size.
const DepthContext = enum { top_level, child, array };
const TypeRefFormatter = struct {
    pub const Reason = enum { var_decl, direct_type_access };
    pub const Options = struct {
        reason: Reason,
        is_const: bool = false,
        in: bool = false,
        out: bool = false,
        optional: bool = false,
        union_pointer: bool = false,
        not_null_term: bool = false,
        // TODO: handle this option
        null_null_term: bool = true,
        // TODO: what to do with this?
        ret_val: bool = false,
        // TODO: don't know what to do with this yet
        com_out_ptr: bool = false,
        // TODO: don't know what to do with this yet
        do_not_release: bool = false,
        // TODO: don't know what to do with this yet
        reserved: bool = false,
        optional_bytes_param_index: ?i16 = null,
        anon_types: ?*const AnonTypes,

        null_modifier: NullModifier,
    };

    type_ref: json.ObjectMap,
    arches: ArchFlags,
    options: Options,
    nested_context: ?*const NestedContext,
};
pub fn fmtTypeRef(type_ref: json.ObjectMap, arches: ArchFlags, options: TypeRefFormatter.Options, nested_context: ?*const NestedContext) TypeRefFormatter {
    return .{ .type_ref = type_ref, .arches = arches, .options = options, .nested_context = nested_context };
}

fn generateTypeRef(sdk_file: *SdkFile, writer: *CodeWriter, self: TypeRefFormatter) !void {
    try generateTypeRefRec(sdk_file, writer, self, .top_level);
}
fn generateTypeRefRec(sdk_file: *SdkFile, writer: *CodeWriter, self: TypeRefFormatter, depth_context: DepthContext) anyerror!void {
    const kind = (try jsonObjGetRequired(self.type_ref, "Kind", sdk_file)).string;

    if (std.mem.eql(u8, kind, "Native")) {
        try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8{ "Kind", "Name" }, sdk_file);
        const name = (try jsonObjGetRequired(self.type_ref, "Name", sdk_file)).string;
        if (std.mem.eql(u8, name, "Void")) {
            const type_name: []const u8 = switch (depth_context) {
                .top_level => "void",
                .child => "anyopaque",
                // if we are rendering the element of an array, then we have to know the size, we default to u8
                // because most void pointers in C are measured in terms of u8 bytes
                .array => "u8",
            };
            try writer.writef("{s}", .{type_name}, .{ .start = .any, .nl = false });
        } else if (std.mem.eql(u8, name, "Guid")) {
            try writer.write("Guid", .{ .start = .any, .nl = false });
        } else {
            const native_type = global_native_type_map.get(name) orelse std.debug.panic("unknown Native type '{s}'", .{name});
            try writer.writef("{s}", .{nativeTypeToZigType(native_type)}, .{ .start = .any, .nl = false });
        }
    } else if (std.mem.eql(u8, kind, "ApiRef")) {
        try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8{ "Kind", "Name", "TargetKind", "Api", "Parents" }, sdk_file);
        const name = (try jsonObjGetRequired(self.type_ref, "Name", sdk_file)).string;
        const api = (try jsonObjGetRequired(self.type_ref, "Api", sdk_file)).string;

        if (getAnonKind(name)) |anon_kind| {
            const anon_types = self.options.anon_types orelse
                jsonPanicMsg("missing anonymous type '{s}' (this scope does not have any anonymous types)!", .{name});
            const name_pool = try global_symbol_pool.add(name);
            const type_obj = anon_types.types.get(name_pool) orelse
                jsonPanicMsg("missing anonymous type '{s}'!", .{name});
            try generateStructOrUnionDef(sdk_file, writer, type_obj, self.arches, anon_kind, self.nested_context);
            try writer.write("}", .{ .nl = false });
            return;
        }

        const parents = (try jsonObjGetRequired(self.type_ref, "Parents", sdk_file)).array;

        const type_kind_category = blk: {
            const pass1_api_map = (global_pass1.get(api) orelse
                jsonPanicMsg("type '{s}' is from API '{s}' that is missing from pass1 data", .{ name, api })).object;
            const pass1_type_obj = (pass1_api_map.get(name) orelse {
                if (parents.items.len == 0) {
                    const in_nested_context = if (self.nested_context) |c| c.contains(name) else false;
                    if (!in_nested_context) {
                        jsonPanicMsg("type '{s}' from API '{s}' is missing from pass1 data, has no parents and is not in the current nested context!", .{ name, api });
                    }
                }
                // this means its a nested type which are always structs/unions
                break :blk Pass1TypeKindCategory.default;
            }).object;
            try jsonObjEnforceKnownFieldsOnly(pass1_type_obj, &[_][]const u8{"Kind"}, sdk_file);
            const type_kind = (try jsonObjGetRequired(pass1_type_obj, "Kind", sdk_file)).string;
            break :blk pass1_type_kind_info.get(type_kind) orelse
                jsonPanicMsg("unknown pass1 type kind '{s}'", .{type_kind});
        };

        if (self.options.reason == .var_decl) {
            switch (type_kind_category) {
                .default => {},
                .ptr => {
                    if (self.options.null_modifier & 1 == 0) {
                        try writer.write("?", .{ .start = .any, .nl = false });
                    }
                },
                .com => {
                    if (self.options.null_modifier & 1 == 0) {
                        try writer.write("?", .{ .start = .any, .nl = false });
                    }
                    try writer.write("*", .{ .start = .any, .nl = false });
                },
            }
        }

        // special handling for PSTR and PWSTR for now.  This is because those types
        // have hardcoded non-const and null-terminated, so we can't reference them if our usage
        // doesn't match.
        // If there are more cases that behave like this, I will likely need to implement a 2-pass
        // system where the first pass I gather all the type definitions so that on the second pass
        // I'll know whether each type is a pointer like this and can fix things like this.
        const special: enum { pstr, pwstr, other } = blk: {
            if (std.mem.eql(u8, name, "PSTR")) break :blk .pstr;
            if (std.mem.eql(u8, name, "PWSTR")) break :blk .pwstr;
            break :blk .other;
        };
        if (special == .pstr or special == .pwstr) {
            // if we deviated from the options we set for PSTR/PWSTR, then generate the native zig
            // type directly instead of referencing the PSTR/PWSTR type
            if (self.options.is_const or self.options.not_null_term) {
                // can't put these expressions in the print argument tuple because of https://github.com/ziglang/zig/issues/8036
                const base_type = if (special == .pstr) "u8" else "u16";
                const sentinel_suffix = if (self.options.not_null_term) "" else ":0";
                const align_str = if (self.options.union_pointer) "align(1) " else "";
                const const_str = if (self.options.is_const) "const " else "";
                try writer.writef(
                    "[*{s}]{s}{s}{s}",
                    .{ sentinel_suffix, align_str, const_str, base_type },
                    .{ .start = .any, .nl = false },
                );
                return;
            }
        }

        // for now, all nested type references MUST be in the same scope so this
        // just causes issues
        //for (parents.items) |*parent_ptr| {
        //    try writer.writef("{s}", .{parent_ptr.string}, .{.start=.any,.nl=false});
        //    try writer.write(".", .{.start=.any,.nl=false});
        //}
        try writer.writef("{s}", .{name}, .{ .start = .any, .nl = false });
    } else if (std.mem.eql(u8, kind, "PointerTo")) {
        try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8{ "Kind", "Child" }, sdk_file);
        const child = (try jsonObjGetRequired(self.type_ref, "Child", sdk_file)).object;
        var child_options = self.options;
        if (self.options.reason == .var_decl and self.options.null_modifier & 1 == 0) {
            try writer.write("?", .{ .start = .any, .nl = false });
        }
        child_options.null_modifier = self.options.null_modifier >> 1;
        try writer.write("*", .{ .start = .any, .nl = false });
        if (self.options.union_pointer) {
            try writer.write("align(1) ", .{ .start = .any, .nl = false });
        }
        if (self.options.is_const) {
            child_options.is_const = false; // TODO: is this right?
            try writer.write("const ", .{ .start = .any, .nl = false });
        }
        try generateTypeRefRec(sdk_file, writer, fmtTypeRef(child, self.arches, child_options, self.nested_context), .child);
    } else if (std.mem.eql(u8, kind, "Array")) {
        try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8{ "Kind", "Shape", "Child" }, sdk_file);
        const child = (try jsonObjGetRequired(self.type_ref, "Child", sdk_file)).object;
        const shape_size = init: {
            switch (try jsonObjGetRequired(self.type_ref, "Shape", sdk_file)) {
                // TODO: should we use size 1 here?
                .null => break :init 1,
                .object => |shape_obj| {
                    try jsonObjEnforceKnownFieldsOnly(shape_obj, &[_][]const u8{"Size"}, sdk_file);
                    break :init (try jsonObjGetRequired(shape_obj, "Size", sdk_file)).integer;
                },
                else => jsonPanic(),
            }
        };
        try writer.writef("[{}]", .{shape_size}, .{ .start = .any, .nl = false });
        try generateTypeRefRec(sdk_file, writer, fmtTypeRef(child, self.arches, self.options, self.nested_context), .child);
    } else if (std.mem.eql(u8, kind, "LPArray")) {
        try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8{ "Kind", "NullNullTerm", "CountConst", "CountParamIndex", "Child" }, sdk_file);
        const null_null_term = (try jsonObjGetRequired(self.type_ref, "NullNullTerm", sdk_file)).bool;
        const count_const = (try jsonObjGetRequired(self.type_ref, "CountConst", sdk_file)).integer;
        const count_param_index = (try jsonObjGetRequired(self.type_ref, "CountParamIndex", sdk_file)).integer;
        _ = count_param_index; // ignored for now
        const type_ref_kind = (try jsonObjGetRequired(self.type_ref, "Kind", sdk_file)).string;
        _ = type_ref_kind; // ignored for now
        // TODO: can Zig use count_param_index?
        const child = (try jsonObjGetRequired(self.type_ref, "Child", sdk_file)).object;
        var child_options = self.options;
        if (self.options.optional) {
            child_options.optional = false;
            try writer.write("?", .{ .start = .any, .nl = false });
        }
        if (null_null_term) {
            try writer.write("*extern struct{{comment:[*]const u8=\"TODO: LPArray with null_null_term\"}}", .{ .start = .any, .nl = false });
        } else {
            var sentinel_suffix: []const u8 = "";
            if ((!self.options.not_null_term) and isByteOrCharOrUInt16Type(child, sdk_file)) {
                sentinel_suffix = ":0";
            }

            if (count_const == -1 or count_const == 0) {
                try writer.writef("[*{s}]", .{sentinel_suffix}, .{ .start = .any, .nl = false });
            } else {
                try writer.writef("*[{}]", .{count_const}, .{ .start = .any, .nl = false });
            }
            if (count_const <= 0 and self.options.is_const)
                try writer.write("const ", .{ .start = .any, .nl = false });
            try generateTypeRefRec(sdk_file, writer, fmtTypeRef(child, self.arches, child_options, self.nested_context), .array);
        }
    } else if (std.mem.eql(u8, kind, "MissingClrType")) {
        try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8{ "Kind", "Name", "Namespace" }, sdk_file);
        const name = (try jsonObjGetRequired(self.type_ref, "Name", sdk_file)).string;
        const namespace = (try jsonObjGetRequired(self.type_ref, "Namespace", sdk_file)).string;
        try writer.writef("*struct{{comment: []const u8 = \"MissingClrType {s}.{s}\"}}", .{ name, namespace }, .{ .start = .any, .nl = false });
    } else {
        jsonPanicMsg("fmtTypeRef kind '{s}' is not implemented", .{kind});
    }
}

fn isByteOrCharOrUInt16Type(type_obj: json.ObjectMap, sdk_file: *SdkFile) bool {
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).string;
    if (!std.mem.eql(u8, kind, "Native"))
        return false;

    const name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).string;
    if (std.mem.eql(u8, name, "Void"))
        return false;
    const native_type = global_native_type_map.get(name) orelse jsonPanicMsg("unknown Native type '{s}'", .{name});
    return switch (native_type) {
        .Byte, .Char, .UInt16 => true,
        else => false,
    };
}

fn fmtConstValue(value_type: ValueType, value: json.Value, sdk_file: *SdkFile) ConstValueFormatter {
    return .{ .value_type = value_type, .value = value, .sdk_file = sdk_file };
}
const ConstValueFormatter = struct {
    value_type: ValueType,
    value: json.Value,
    sdk_file: *SdkFile,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        _ = fmt;
        _ = options;
        if (self.value_type == .String) {
            switch (self.value) {
                .null => try writer.writeAll("null"),
                .string => |s| try writer.print("\"{}\"", .{std.zig.fmtEscapes(s)}),
                else => std.debug.panic("uhandled type '{s}'", .{@tagName(self.value)}),
            }
            return;
        }
        const zig_type = valueTypeToZigType(self.value_type);
        if (self.value_type == .Single or self.value_type == .Double) {
            switch (self.value) {
                .string => |float_str| {
                    if (std.mem.eql(u8, float_str, "inf")) {
                        try writer.print("@import(\"std\").math.inf({s})", .{zig_type});
                        return;
                    } else if (std.mem.eql(u8, float_str, "-inf")) {
                        try writer.print("-@import(\"std\").math.inf({s})", .{zig_type});
                        return;
                    } else if (std.mem.eql(u8, float_str, "nan")) {
                        try writer.print("@import(\"std\").math.nan({s})", .{zig_type});
                        return;
                    } else {
                        std.debug.panic("unexpected float string value '{s}'", .{float_str});
                    }
                    return;
                },
                else => {},
            }
        }
        try writer.print("@as({s}, {})", .{ zig_type, fmtJson(self.value) });
    }
};

const constants_to_skip = std.ComptimeStringMap(Nothing, .{
    // skip this constant because its name conflicts with the name of a type!
    .{ "PEERDIST_RETRIEVAL_OPTIONS_CONTENTINFO_VERSION", .{} },
    // skip these because these constants are integer values being cast to string pointers, however,
    // those string pointers need to be aligned.  The types that accept these constants should probably
    // be properly declared as union types.
    .{ "RT_CURSOR", .{} },
    .{ "RT_BITMAP", .{} },
    .{ "RT_ICON", .{} },
    .{ "RT_MENU", .{} },
    .{ "RT_DIALOG", .{} },
    .{ "RT_FONTDIR", .{} },
    .{ "RT_FONT", .{} },
    .{ "RT_ACCELERATOR", .{} },
    .{ "RT_MESSAGETABLE", .{} },
    .{ "RT_VERSION", .{} },
    .{ "RT_DLGINCLUDE", .{} },
    .{ "RT_PLUGPLAY", .{} },
    .{ "RT_VXD", .{} },
    .{ "RT_ANICURSOR", .{} },
    .{ "RT_ANIICON", .{} },
    .{ "RT_HTML", .{} },

    //.{ "IDC_ARROW", .{} }, This one is aligned so we can generate it
    .{ "IDC_IBEAM", .{} },
    .{ "IDC_WAIT", .{} },
    .{ "IDC_CROSS", .{} },
    .{ "IDC_UPARROW", .{} },
    .{ "IDC_SIZE", .{} },
    .{ "IDC_ICON", .{} },
    .{ "IDC_SIZENWSE", .{} },
    .{ "IDC_SIZENESW", .{} },
    .{ "IDC_SIZEWE", .{} },
    .{ "IDC_SIZENS", .{} },
    .{ "IDC_SIZEALL", .{} },
    .{ "IDC_NO", .{} },
    .{ "IDC_HAND", .{} },
    .{ "IDC_APPSTARTING", .{} },
    .{ "IDC_HELP", .{} },
    .{ "IDC_PIN", .{} },
    .{ "IDC_PERSON", .{} },

    //.{ "IDI_APPLICATION", .{} }, This one is aligned so we can generate it
    .{ "IDI_HAND", .{} },
    .{ "IDI_QUESTION", .{} },
    .{ "IDI_EXCLAMATION", .{} },
    .{ "IDI_ASTERISK", .{} },
    .{ "IDI_WINLOGO", .{} },
    .{ "IDI_SHIELD", .{} },

    // HWND_DESKTOP and HWND_TOP are HWND types, but they are 0 so they need to be ?HWND
    .{ "HWND_DESKTOP", .{} },
    .{ "HWND_TOP", .{} },

    // This is both a constant and a type definition in Networking.HttpServer
    .{ "HTTP_VERSION", .{} },
});
fn generateConstant(sdk_file: *SdkFile, writer: *CodeWriter, constant_obj: json.ObjectMap) !void {
    try jsonObjEnforceKnownFieldsOnly(constant_obj, &[_][]const u8{ "Name", "Type", "Value", "ValueType", "Attrs" }, sdk_file);
    const name_tmp = (try jsonObjGetRequired(constant_obj, "Name", sdk_file)).string;
    const type_ref = (try jsonObjGetRequired(constant_obj, "Type", sdk_file)).object;
    const value_type_str = (try jsonObjGetRequired(constant_obj, "ValueType", sdk_file)).string;
    const value_node = try jsonObjGetRequired(constant_obj, "Value", sdk_file);

    const attrs_node = (try jsonObjGetRequired(constant_obj, "Attrs", sdk_file)).array;
    _ = attrs_node; // TODO: handle Attrs

    const name_pool = try global_symbol_pool.add(name_tmp);
    try sdk_file.const_exports.append(name_pool);

    const value_type = global_value_type_map.get(value_type_str) orelse
        fatal("unknown ValueType '{s}'", .{value_type_str});

    if (constants_to_skip.get(name_pool.slice)) |_| {
        try writer.linef("// skipped '{}'", .{name_pool});
        return;
    }
    const zig_type_formatter = try addTypeRefs(sdk_file, ArchFlags.all, type_ref, .{ .reason = .direct_type_access, .is_const = true, .in = false, .out = false, .anon_types = null, .null_modifier = 0 }, null);

    const kind = (jsonObjGetRequired(type_ref, "Kind", sdk_file) catch unreachable).string;
    if (std.mem.eql(u8, kind, "Native")) {
        jsonEnforce(value_type != .PropertyKey);
        jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8{ "Kind", "Name" }, sdk_file) catch unreachable;
        const name = (jsonObjGetRequired(type_ref, "Name", sdk_file) catch unreachable).string;
        const native_type = global_native_type_map.get(name) orelse std.debug.panic("unknown Native type '{s}'", .{name});
        if (native_type == .Guid) {
            try writer.linef("pub const {s} = Guid.initString({});", .{ name_pool, fmtConstValue(value_type, value_node, sdk_file) });
        } else {
            try writer.linef("pub const {s} = {};", .{ name_pool, fmtConstValue(value_type, value_node, sdk_file) });
        }
    } else {
        if (value_type == .PropertyKey) {
            const value_obj = switch (value_node) {
                .object => |obj| obj,
                else => jsonPanicMsg("expected PropertyKey to be an object but got: {s}", .{fmtJson(value_node)}),
            };
            try jsonObjEnforceKnownFieldsOnly(value_obj, &[_][]const u8{ "Fmtid", "Pid" }, sdk_file);
            const fmtid = (try jsonObjGetRequired(value_obj, "Fmtid", sdk_file)).string;
            const pid = (try jsonObjGetRequired(value_obj, "Pid", sdk_file)).integer;
            try writer.writef("pub const {s} = ", .{name_pool}, .{ .nl = false });
            try generateTypeRef(sdk_file, writer, zig_type_formatter);
            sdk_file.uses_guid = true;
            try writer.writef(" {{ .fmtid = Guid.initString(\"{s}\"), .pid = {} }};", .{ fmtid, pid }, .{ .start = .mid });
        } else {
            try writer.writef("pub const {s} = @import(\"{s}zig.zig\").typedConst(", .{
                name_pool,
                sdk_file.getWin32DirImportPrefix(),
            }, .{ .nl = false });
            try generateTypeRef(sdk_file, writer, zig_type_formatter);
            try writer.writef(", {});", .{
                fmtConstValue(value_type, value_node, sdk_file),
            }, .{ .start = .mid });
        }
    }
}

// workaround https://github.com/microsoft/win32metadata/issues/389
const also_usable_type_api_map = std.ComptimeStringMap([]const u8, .{
    .{ "HDC", "Graphics.Gdi" },
    .{ "HGDIOBJ", "Graphics.Gdi" },
    .{ "HICON", "UI.WindowsAndMessaging" },
    .{ "HANDLE", "System.SystemServices" },
    .{ "HeapHandle", "System.SystemServices" },
});

const Depth = u3;

const CodeWriter = struct {
    writer: BufferedWriter.Writer,
    depth: u4,
    midline: bool,

    pub fn writeBlock(self: CodeWriter, comptime s: []const u8) !void {
        std.debug.assert(s[s.len - 1] == '\n');
        std.debug.assert(self.depth == 0);
        std.debug.assert(!self.midline);
        try self.writer.writeAll(s);
    }

    pub const LineOpt = struct {
        start: enum { line, any, mid } = .line,
        nl: bool = true,
    };
    pub fn writef(self: *CodeWriter, comptime fmt: []const u8, args: anytype, comptime opt: LineOpt) !void {
        std.debug.assert(null == std.mem.indexOf(u8, fmt, "\n"));
        const do_indent = blk: {
            switch (opt.start) {
                .line => {
                    std.debug.assert(!self.midline);
                    break :blk true;
                },
                .any => break :blk !self.midline,
                .mid => {
                    std.debug.assert(self.midline);
                    break :blk false;
                },
            }
        };
        if (do_indent) {
            var i: @TypeOf(self.depth) = 0;
            while (i < self.depth) : (i += 1) {
                try self.writer.writeAll("    ");
            }
            self.midline = true;
        }
        if (@typeInfo(@TypeOf(args)).Struct.fields.len == 0) {
            try self.writer.writeAll(fmt ++ (if (opt.nl) "\n" else ""));
        } else {
            try self.writer.print(fmt ++ (if (opt.nl) "\n" else ""), args);
        }
        self.midline = !opt.nl;
    }

    pub fn write(self: *CodeWriter, comptime s: []const u8, comptime opt: LineOpt) !void {
        try self.writef(s, .{}, opt);
    }
    pub fn line(self: *CodeWriter, comptime s: []const u8) !void {
        try self.writef(s, .{}, .{});
    }
    pub fn linef(self: *CodeWriter, comptime fmt: []const u8, args: anytype) !void {
        try self.writef(fmt, args, .{});
    }
};

pub fn addArchSpecific(comptime T: type, arch_specific: *ArchSpecificMap(T), pool_name: StringPool.Val, arches: ArchFlags, obj: T) !void {
    std.debug.assert(arches.flags != ArchFlags.all.flags);
    if (arch_specific.getPtr(pool_name)) |object| {
        object.add(.{ .arches = arches, .obj = obj });
    } else {
        var objects = ArchSpecificObjects(T){};
        objects.object_array[0] = .{ .arches = arches, .obj = obj };
        objects.object_count = 1;
        try arch_specific.put(pool_name, objects);
    }
}

fn generateType(
    sdk_file: *SdkFile,
    writer: *CodeWriter,
    arch_specific: *ArchSpecificMap(json.ObjectMap),
    type_obj: json.ObjectMap,
    enum_alias_conflicts: *StringPool.HashMap(StringPool.Val),
) !void {
    const arches = ArchFlags.initJson((try jsonObjGetRequired(type_obj, "Architectures", sdk_file)).array.items);
    {
        const platform_node = try jsonObjGetRequired(type_obj, "Platform", sdk_file);
        try generatePlatformComment(writer, platform_node);
    }
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).string;
    const tmp_name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).string;

    if (std.mem.eql(u8, kind, "ComClassID")) {
        if (arches.flags != ArchFlags.all.flags)
            jsonPanicMsg("not impl", .{});
        try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8{ "Name", "Platform", "Architectures", "Kind", "Guid" }, sdk_file);
        const guid = (try jsonObjGetRequired(type_obj, "Guid", sdk_file)).string;
        const clsid_pool = try global_symbol_pool.addFormatted("CLSID_{s}", .{tmp_name});
        sdk_file.uses_guid = true;
        try writer.linef("const {s}_Value = Guid.initString(\"{s}\");", .{ clsid_pool, guid });
        try writer.linef("pub const {s} = &{0s}_Value;", .{clsid_pool});
        try sdk_file.const_exports.append(clsid_pool);
        return;
    }

    const pool_name = try global_symbol_pool.add(tmp_name);

    // TODO: should I be adding this to type_exports if it's arch specific?
    //       type_exports may need to have an ArchFlags for each symbol
    if (arches.flags == ArchFlags.all.flags) {
        std.debug.assert(sdk_file.type_exports.get(pool_name) == null);
    }
    try sdk_file.type_exports.put(pool_name, .{});

    if (types_that_conflict_with_consts.get(tmp_name)) |_| {
        try writer.line("// WARNING: this type symbol conflicts with a const!");
        try writer.linef("pub const {s}_CONFLICT_ = usize;", .{tmp_name});
    } else if (types_that_conflict_with_something.get(tmp_name)) |_| {
        try writer.line("// WARNING: this type symbol conflicts with something!");
        try writer.linef("pub const {s}_CONFLICT_ = usize;", .{tmp_name});
    } else if (types_to_skip.get(tmp_name)) |msg| {
        try writer.linef("// TODO: not generating this type because {s}", .{msg});
        try writer.linef("pub const {s} = usize;", .{tmp_name});
    } else if (arches.flags != ArchFlags.all.flags) {
        try addArchSpecific(json.ObjectMap, arch_specific, pool_name, arches, type_obj);
    } else {
        const def_prefix = try std.fmt.allocPrint(allocator, "pub const {s} = ", .{std.zig.fmtId(tmp_name)});
        defer allocator.free(def_prefix);
        try generateTypeDefinition(sdk_file, writer, type_obj, enum_alias_conflicts, arches, kind, pool_name, def_prefix, ";");
    }
}

fn generateTypeDefinition(
    sdk_file: *SdkFile,
    writer: *CodeWriter,
    type_obj: json.ObjectMap,
    enum_alias_conflicts: *StringPool.HashMap(StringPool.Val),
    arches: ArchFlags,
    kind: []const u8,
    pool_name: StringPool.Val,
    def_prefix: []const u8,
    def_suffix: []const u8,
) !void {
    if (std.mem.eql(u8, kind, "NativeTypedef")) {
        try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8{ "Name", "Platform", "Architectures", "AlsoUsableFor", "Kind", "Def", "FreeFunc", "InvalidHandleValue" }, sdk_file);
        const also_usable_for_node = try jsonObjGetRequired(type_obj, "AlsoUsableFor", sdk_file);
        const def_type = (try jsonObjGetRequired(type_obj, "Def", sdk_file)).object;
        const optional_free_func: ?[]const u8 = switch (try jsonObjGetRequired(type_obj, "FreeFunc", sdk_file)) {
            .null => null,
            .string => |s| s,
            else => jsonPanic(),
        };
        if (optional_free_func) |free_func| {
            try writer.linef("// TODO: this type has a FreeFunc '{s}', what can Zig do with this information?", .{free_func});
        }
        const invalid_handle_value_opt: ?i64 = switch (try jsonObjGetRequired(type_obj, "InvalidHandleValue", sdk_file)) {
            .null => null,
            .integer => |i| i,
            else => jsonPanic(),
        };
        if (invalid_handle_value_opt) |v| {
            try writer.linef("// TODO: this type has an InvalidHandleValue of '{}', what can Zig do with this information?", .{v});
        }

        // HANDLE PSTR and PWSTR specially because win32metadata is not properly declaring them as arrays, only pointers
        // not sure if this is a real issue with the metadata or intentional
        const special: enum { pstr, pwstr, other } = blk: {
            if (std.mem.eql(u8, pool_name.slice, "PSTR")) break :blk .pstr;
            if (std.mem.eql(u8, pool_name.slice, "PWSTR")) break :blk .pwstr;
            break :blk .other;
        };
        if (special == .pstr or special == .pwstr) {
            //
            // verify the definition is what we expect, if not, we might be able to remove out workaround
            //
            const def_kind = (try jsonObjGetRequired(def_type, "Kind", sdk_file)).string;
            jsonEnforceMsg(std.mem.eql(u8, def_kind, "PointerTo"), "definition of {s} has changed! (Def.Kind != PointerTo, it is {s})", .{ pool_name, def_kind });
            try jsonObjEnforceKnownFieldsOnly(def_type, &[_][]const u8{ "Kind", "Child" }, sdk_file);
            const child_type = (try jsonObjGetRequired(def_type, "Child", sdk_file)).object;
            const child_kind = (try jsonObjGetRequired(child_type, "Kind", sdk_file)).string;
            jsonEnforceMsg(std.mem.eql(u8, child_kind, "Native"), "definition of {s} has changed! (Def.Child.Kind != Native", .{pool_name});
            try jsonObjEnforceKnownFieldsOnly(child_type, &[_][]const u8{ "Kind", "Name" }, sdk_file);
            const child_native_name = (try jsonObjGetRequired(child_type, "Name", sdk_file)).string;
            // TODO: is something is referencing PSTR or PWSTR and is NotNullTerm, then
            //       maybe I'll do something like @import("zig.zig").NotNullTerm(PSTR)
            const native_type = global_native_type_map.get(child_native_name) orelse jsonPanic();
            switch (native_type) {
                .Byte => {
                    jsonEnforce(special == .pstr);
                    try writer.linef("{s}[*:0]u8{s}", .{ def_prefix, def_suffix });
                },
                .Char => {
                    jsonEnforce(special == .pwstr);
                    try writer.linef("{s}[*:0]u16{s}", .{ def_prefix, def_suffix });
                },
                else => jsonPanic(),
            }
            return;
        }

        switch (also_usable_for_node) {
            .string => |also_usable_for| {
                if (also_usable_type_api_map.get(also_usable_for)) |api| {
                    try sdk_file.addApiImport(arches, also_usable_for, api, json.Array{ .items = &[_]json.Value{}, .capacity = 0, .allocator = allocator });
                    try writer.linef("//TODO: type '{s}' is \"AlsoUsableFor\" '{s}' which means this type is implicitly", .{ pool_name, also_usable_for });
                    try writer.linef("//      convertible to '{s}' but not the other way around.  I don't know how to do this", .{also_usable_for});
                    try writer.line("//      in Zig so for now I'm just defining it as an alias");
                    try writer.linef("{s}{s}{s}", .{ def_prefix, also_usable_for, def_suffix });
                    //try writer.linef("{s}extern struct {{ base: {s} }}{s}", .{def_prefix, also_usable_for, def_suffix});
                } else std.debug.panic("AlsoUsableFor type '{s}' is missing from alsoUsableForApiMap", .{also_usable_for});
                return;
            },
            .null => {},
            else => jsonPanic(),
        }

        // NOTE: for now, I'm just hardcoding a few types to redirect to the ones defined in 'std'
        //       this allows apps to use values of these types interchangeably with bindings in std
        if (@import("handletypes.zig").std_handle_types.get(pool_name.slice)) |std_sym| {
            try writer.linef("{s}@import(\"std\").{s}{s}", .{ def_prefix, std_sym, def_suffix });
            return;
        }
        // workaround https://github.com/microsoft/win32metadata/issues/395
        if (@import("handletypes.zig").handle_types.get(pool_name.slice)) |_| {
            try writer.linef("{s}*opaque{{}}{s}", .{ def_prefix, def_suffix });
            return;
        }

        // TODO: set is_const, in and out properly
        const zig_type_formatter = try addTypeRefs(sdk_file, arches, def_type, .{ .reason = .direct_type_access, .is_const = false, .in = false, .out = false, .anon_types = null, .null_modifier = 0 }, null);
        try writer.writef("{s}", .{def_prefix}, .{ .nl = false });
        try generateTypeRef(sdk_file, writer, zig_type_formatter);
        try writer.writef("{s}", .{def_suffix}, .{ .start = .mid });
    } else if (std.mem.eql(u8, kind, "Enum")) {
        try generateEnum(sdk_file, writer, type_obj, pool_name, enum_alias_conflicts, def_prefix, def_suffix);
    } else if (std.mem.eql(u8, kind, "Union")) {
        try generateStructOrUnion(sdk_file, writer, type_obj, arches, pool_name, def_prefix, def_suffix, .Union, null);
    } else if (std.mem.eql(u8, kind, "Struct")) {
        try generateStructOrUnion(sdk_file, writer, type_obj, arches, pool_name, def_prefix, def_suffix, .Struct, null);
    } else if (std.mem.eql(u8, kind, "FunctionPointer")) {
        if (funcPtrHasDependencyLoop(pool_name.slice)) {
            try writer.line("// TODO: this function pointer causes dependency loop problems, so it's stubbed out");
            try writer.linef("{s}switch (@import(\"builtin\").zig_backend) {{ " ++
                ".stage1 => fn() callconv(@import(\"std\").os.windows.WINAPI) void" ++
                ", else => *const fn() callconv(@import(\"std\").os.windows.WINAPI) void" ++
                "}}{s}", .{ def_prefix, def_suffix });
            return;
        }
        try generateFunction(sdk_file, writer, type_obj, .{ .ptr = .{ .both = .{ .def_prefix = def_prefix, .def_suffix = def_suffix } } });
        try sdk_file.tmp_func_ptr_workaround_list.append(pool_name);
    } else if (std.mem.eql(u8, kind, "Com")) {
        try generateCom(sdk_file, writer, type_obj, arches, pool_name, def_prefix);
    } else {
        jsonPanicMsg("{s}: unknown type Kind '{s}'", .{ sdk_file.json_basename, kind });
    }
}

const types_to_skip = std.ComptimeStringMap([]const u8, .{
    .{ "FILEGROUPDESCRIPTORA", "array of 'win32.ui.shell.FILEDESCRIPTORA' not allowed in packed struct due to padding bits" },
});
const types_that_conflict_with_consts = std.ComptimeStringMap(Nothing, .{
    // This symbol conflicts with a constant with the exact same name
    .{ "AE_SRVSTATUS", .{} },
    .{ "AE_SESSLOGON", .{} },
    .{ "AE_SESSLOGOFF", .{} },
    .{ "AE_SESSPWERR", .{} },
    .{ "AE_CONNSTART", .{} },
    .{ "AE_CONNSTOP", .{} },
    .{ "AE_CONNREJ", .{} },
    .{ "AE_RESACCESS", .{} },
    .{ "AE_RESACCESSREJ", .{} },
    .{ "AE_CLOSEFILE", .{} },
    .{ "AE_SERVICESTAT", .{} },
    .{ "AE_ACLMOD", .{} },
    .{ "AE_UASMOD", .{} },
    .{ "AE_NETLOGON", .{} },
    .{ "AE_NETLOGOFF", .{} },
    .{ "AE_LOCKOUT", .{} },
});
const types_that_conflict_with_something = std.ComptimeStringMap(Nothing, .{
    // https://github.com/microsoft/win32metadata/issues/632
    // There's something weird going on with these types.  The types are empty
    // but they are also defined as nested types inside the other types that use them.
    // The reason they must be skipped right now is they are causing name conflict errors
    // becuase they are duplicated.
    .{ "DHCP_SUBNET_ELEMENT_UNION", .{} },
    .{ "DHCP_OPTION_ELEMENT_UNION", .{} },
    .{ "DHCP_OPTION_SCOPE_UNION6", .{} },
    .{ "DHCP_CLIENT_SEARCH_UNION", .{} },
    .{ "DHCP_SUBNET_ELEMENT_UNION_V4", .{} },
    .{ "DHCP_SUBNET_ELEMENT_UNION_V6", .{} },
});

const com_types_to_skip = std.ComptimeStringMap(Nothing, .{
    .{ "placeholder_ignore_me", .{} },
});

fn generatePlatformComment(writer: *CodeWriter, platform_node: std.json.Value) !void {
    switch (platform_node) {
        .string => |platform| {
            try writer.linef("// TODO: this type is limited to platform '{s}'", .{platform});
        },
        .null => {},
        else => jsonPanic(),
    }
}

const AnonTypes = struct {
    types: StringPool.HashMap(json.ObjectMap),
    pub fn init() AnonTypes {
        return .{
            .types = StringPool.HashMap(json.ObjectMap).init(allocator),
        };
    }
    pub fn deinit(self: *AnonTypes) void {
        self.types.deinit();
    }
};

fn generateStructOrUnion(sdk_file: *SdkFile, writer: *CodeWriter, type_obj: json.ObjectMap, arches: ArchFlags, pool_name: StringPool.Val, def_prefix: []const u8, def_suffix: []const u8, kind: ContainerKind, nested_context: ?*const NestedContext) !void {
    std.debug.assert(getAnonKind(pool_name.slice) == null);
    try writer.writef("{s}", .{def_prefix}, .{ .nl = false });
    try generateStructOrUnionDef(sdk_file, writer, type_obj, arches, kind, nested_context);
    try writer.linef("}}{s}", .{def_suffix});
}

fn generateStructOrUnionDef(sdk_file: *SdkFile, writer: *CodeWriter, type_obj: json.ObjectMap, arches: ArchFlags, kind: ContainerKind, nested_context: ?*const NestedContext) anyerror!void {
    try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8{ "Kind", "Name", "Platform", "Architectures", "Size", "PackingSize", "Fields", "Comment", "NestedTypes" }, sdk_file);
    const struct_size = (try jsonObjGetRequired(type_obj, "Size", sdk_file)).integer;
    _ = struct_size; // ignored for now
    const struct_packing_size = (try jsonObjGetRequired(type_obj, "PackingSize", sdk_file)).integer;
    const struct_fields = (try jsonObjGetRequired(type_obj, "Fields", sdk_file)).array;
    const struct_nested_types = (try jsonObjGetRequired(type_obj, "NestedTypes", sdk_file)).array;

    const zig_type = if (kind == .Struct) "struct" else "union";

    try writer.writef("extern {s} {{", .{zig_type}, .{ .start = .any });
    writer.depth += 1;
    defer writer.depth -= 1;

    var anon_types = AnonTypes.init();
    defer anon_types.deinit();

    const this_nested_context_data = NestedContext{
        .nested_types = struct_nested_types,
        .parent = nested_context,
    };
    const this_nested_context = if (struct_nested_types.items.len > 0) &this_nested_context_data else nested_context;

    for (struct_nested_types.items) |*nested_type_node_ptr| {
        const nested_type_obj = nested_type_node_ptr.object;
        const nested_kind = (try jsonObjGetRequired(nested_type_obj, "Kind", sdk_file)).string;
        const nested_tmp_name = (try jsonObjGetRequired(nested_type_obj, "Name", sdk_file)).string;
        const architectures = (try jsonObjGetRequired(nested_type_obj, "Architectures", sdk_file)).array;
        const pool_name = try global_symbol_pool.add(nested_tmp_name);
        if (getAnonKind(nested_tmp_name)) |_| {
            if (architectures.items.len > 0) // we don't handle architectures in this case
                jsonPanicMsg("not impl", .{});
            try anon_types.types.put(pool_name, nested_type_obj);
        } else {
            // TODO: I don't know why this isn't working!!!
            //const def_prefix = try std.fmt.allocPrint(allocator, "pub const {s} = ", .{std.zig.fmtId(pool_name)});
            //defer allocator.free(def_prefix);
            try writer.writef("pub const {s} = ", .{pool_name}, .{ .nl = false });
            if (std.mem.eql(u8, nested_kind, "Union")) {
                try generateStructOrUnionDef(sdk_file, writer, nested_type_obj, arches, .Union, this_nested_context);
            } else if (std.mem.eql(u8, nested_kind, "Struct")) {
                try generateStructOrUnionDef(sdk_file, writer, nested_type_obj, arches, .Struct, this_nested_context);
            } else jsonPanicMsg("not impl", .{});
            try writer.line("};");
        }
    }

    if (struct_fields.items.len == 0) {
        try writer.line("placeholder: usize, // TODO: why is this type empty?");
    } else {
        for (struct_fields.items) |*field_node_ptr| {
            const field_obj = field_node_ptr.object;
            try jsonObjEnforceKnownFieldsOnly(field_obj, &[_][]const u8{ "Name", "Type", "Attrs" }, sdk_file);
            const field_name = (try jsonObjGetRequired(field_obj, "Name", sdk_file)).string;
            const field_type = (try jsonObjGetRequired(field_obj, "Type", sdk_file)).object;
            const field_attrs = (try jsonObjGetRequired(field_obj, "Attrs", sdk_file)).array;
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            // TODO: implement null_modifier
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            var field_options = TypeRefFormatter.Options{ .reason = .var_decl, .anon_types = &anon_types, .null_modifier = 0 };
            for (field_attrs.items) |*attr_node_ptr| {
                const attr_str = attr_node_ptr.string;
                if (std.mem.eql(u8, attr_str, "Const")) {
                    field_options.is_const = true;
                } else if (std.mem.eql(u8, attr_str, "NotNullTerminated")) {
                    field_options.not_null_term = true;
                } else if (std.mem.eql(u8, attr_str, "NullNullTerminated")) {
                    field_options.null_null_term = true;
                } else if (std.mem.eql(u8, attr_str, "Obselete")) {
                    try writer.line("/// Deprecated");
                } else if (std.mem.eql(u8, attr_str, "Optional")) {
                    field_options.optional = true;
                } else {
                    jsonPanicMsg("unhandled custom field attribute {s}", .{attr_str});
                }
            }
            const field_type_formatter = try addTypeRefs(sdk_file, arches, field_type, field_options, this_nested_context);
            try writer.writef("{}: ", .{std.zig.fmtId(field_name)}, .{ .nl = false });
            try generateTypeRef(sdk_file, writer, field_type_formatter);
            if (struct_packing_size >= 1) {
                try writer.writef(" align({})", .{struct_packing_size}, .{ .start = .mid, .nl = false });
            }
            try writer.write(",", .{ .start = .mid });
        }
    }
}

// Not sure whether enums should be exhaustive or not, for now
// I'll default to all of them being exhaustive except the ones
// in this list that I know are currently not exhaustive.
const non_exhaustive_enums = std.ComptimeStringMap(Nothing, .{
    // This enum is not exhaustive because it is missing a value, see
    //     https://github.com/microsoft/win32metadata/issues/203
    .{ "CLSCTX", .{} },
    // SEND_FLAGS is missing the value 0
    .{ "SEND_FLAGS", .{} },
    .{ "WINDOW_LONG_PTR_INDEX", .{} },
});

fn shortEnumValueName(enum_type_name: []const u8, full_value_name: []const u8) []const u8 {
    if (full_value_name.len == 0) {
        // NOTE: this is probably a bug in the win32metadata
        return "_noname_";
    }
    const offset = init: {
        if ((full_value_name.len <= enum_type_name.len + 1) or
            (full_value_name[enum_type_name.len] != '_') or
            !std.mem.startsWith(u8, full_value_name, enum_type_name))
        {
            break :init 0;
        }
        const first_c = full_value_name[enum_type_name.len + 1];
        if (first_c <= '9' and first_c >= '0') {
            break :init enum_type_name.len;
        }
        break :init enum_type_name.len + 1;
    };
    return full_value_name[offset..];
}

// TODO: this is a set of enums whose value symbols conflict with other symbols
const suppress_enum_aliases = blk: {
    @setEvalBranchQuota(3000);
    break :blk std.ComptimeStringMap(Nothing, .{

        // suppress this one because the CFE_UNDERLINE enum value alias conflicts with the name of an enum type
        .{ "CFE_EFFECTS", .{} },
        // these types have values that conflict with their own enum type name
        .{ "INTERNET_DEFAULT_PORT", .{} },
        .{ "PDH_VERSION", .{} },
        .{ "POWER_PLATFORM_ROLE_VERSION", .{} },
        // --------------------------------------------------------------------------------
        // suppress these enum value aliases because there is already a constant with the same name
        // --------------------------------------------------------------------------------
        .{ "JsRuntimeVersion", .{} },
        .{ "GetIconInfo_hicon", .{} },
        .{ "PFN_WdsCliCallback_dwMessageIdFlags", .{} },
        .{ "MIB_IPFORWARD_TYPE", .{} },
        .{ "OLEMISC", .{} },
        .{ "IMAGEHLP_CBA_EVENT_SEVERITY", .{} },
        .{ "PFN_WDS_CLI_CALLBACK_MESSAGE_ID", .{} },
        // --------------------------------------------------------------------------------
        // suppress the rest because there is another enum with the same enum value alias
        // --------------------------------------------------------------------------------
        // Security
        .{ "NCrypt_dwFlags", .{} },
        .{ "IAzClientContext3_GetGroups_ulOptionsFlags", .{} },
        .{ "NCryptNotifyChangeKey_dwFlags", .{} },
        .{ "SECPKG_ATTR_1", .{} },
        .{ "CryptImportPKCS8_dwFlags", .{} },
        .{ "NCryptDecrypt_dwFlags", .{} },
        .{ "KERB_CERTIFICATE_LOGON_MessageTypeFlags", .{} },
        .{ "SC_ACTION_TypeFlags", .{} },
        .{ "IIdentityProvider_Advise_dwIdentityUpdateEventsFlags", .{} },
        .{ "CRYPT_KEY_PROV_FLAGS", .{} },
        // WindowsProgramming
        .{ "VER_MASK", .{} },
        .{ "SetHandleInformation_dwFlags", .{} },
        .{ "DuplicateHandle_dwOptionsFlags", .{} },
        .{ "REG_OPEN_CREATE_OPTIONS", .{} },
        // SystemServices
        .{ "QueryInformationJobObject_JobObjectInformationClassFlags", .{} },
        .{ "HeapSetInformation_HeapInformationClassFlags", .{} },
        .{ "JOBOBJECT_NOTIFICATION_LIMIT_INFORMATION_2_IoRateControlToleranceInterval", .{} },
        .{ "JOBOBJECT_RATE_CONTROL_TOLERANCE_INTERVAL", .{} },
        .{ "JOBOBJECT_LIMIT_VIOLATION_INFORMATION_2_RateControlTolerance", .{} },
        .{ "JOBOBJECT_IO_RATE_CONTROL_INFORMATIONFlags", .{} },
        .{ "CreateFileMapping_flProtect", .{} },
        .{ "PFM_FLAGS", .{} },
        .{ "JOBOBJECT_BASIC_LIMIT_INFORMATIONFlags", .{} },
        .{ "JOBOBJECT_SECURITY_LIMIT_INFORMATIONFlags", .{} },
        .{ "JOBOBJECT_BASIC_UI_RESTRICTIONS_UIRestrictionsClassFlags", .{} },
        // NetManagement
        .{ "NetWkstaSetInfo_levelFlags", .{} },
        // ComponentServices
        .{ "ICOMAdminCatalog2_IsSafeToDelete_pCOMAdminInUseFlags", .{} },
        .{ "ImportUnconfiguredComponents_pVarComponentType", .{} },
        .{ "ICOMAdminCatalog_InstallApplication_lOptionsFlags", .{} },
        .{ "ICOMAdminCatalog_ExportApplication_lOptionsFlags", .{} },
        .{ "WerRegisterFile_regFileTypeFlags", .{} },
        .{ "WerReportSubmit_pSubmitResultFlags", .{} },
        .{ "WerReportCreate_repTypeFlags", .{} },
        .{ "WerReportSubmit_consentFlags", .{} },
        // FileSystem
        .{ "DefineDosDevice_dwFlags", .{} },
        .{ "CreateFile_dwShareMode", .{} },
        .{ "CreateLogFile_fCreateDispositionFlags", .{} },
        .{ "ReOpenFile_dwFlagsAndAttributes", .{} },
        // Parental Controls
        .{ "IWindowsParentalControlsCore_GetVisibility_peVisibilityFlags", .{} },
        .{ "GetRestrictions_pdwRestrictions", .{} },
        .{ "IWPCWebSettings_GetSettings_pdwSettingsFlags", .{} },
        // Gdi
        .{ "CombineRgn_iMode", .{} },
        .{ "CreateDIBitmap_iUsage", .{} },
        .{ "PatBlt_ropFlags", .{} },
        .{ "GetCurrentObject_typeFlags", .{} },
        .{ "SetROP2_rop2Flags", .{} },
        // MachineLearning
        .{ "MLOperatorTensorDataType", .{} },
        .{ "MLOperatorExecutionType", .{} },
        .{ "MLOperatorEdgeType", .{} },
        // Com
        .{ "IPropertyPageSite_OnStatusChangeFlags", .{} },
        .{ "IOleControlSite_TransformCoordsFlags", .{} },
        // ApplicationInstallationAndServicing
        .{ "LPDISPLAYVAL_uiTypeFlags", .{} },
        .{ "MsiSourceList_dwContext", .{} },
        .{ "MsiAdvertiseScript_dwFlags", .{} },
        .{ "MsiViewModify_eModifyModeFlags", .{} },
        .{ "MsiCreateTransformSummaryInfo_iErrorConditions", .{} },
        .{ "MsiCreateTransformSummaryInfo_iValidation", .{} },
        .{ "MsiEnumClientsEx_dwContext", .{} },
        // WindowsAndMessaging
        .{ "DrawIconEx_diFlags", .{} },
        // Debug
        .{ "SymGetHomeDirectory_type", .{} },
        .{ "SymGetSymbolFile_Type", .{} },
        // Multimedia
        .{ "MIDI_OPEN_TYPE", .{} },
    });
};

const EnumValue = struct {
    pool_name: StringPool.Val,
    short_name: []const u8,
    value: json.Value,
    no_alias: bool,
    conflict_index: ?usize,
    pub fn valueIsZero(self: EnumValue) bool {
        return switch (self.value) {
            .integer => |i| i == 0,
            else => false,
        };
    }

    pub const FlagsValue = union(enum) {
        zero: void,
        flag: u8,
        mask: i64,
    };
    pub fn flagsValue(self: EnumValue) FlagsValue {
        switch (self.value) {
            .integer => |i| {
                if (i == 0) return .zero;

                var index: u6 = 0;
                while (true) : (index += 1) {
                    if ((@as(i64, 1) << index) == i) return .{ .flag = index };
                    if (index == 63) break;
                }

                return .{ .mask = i };
            },
            .number_string => |s| {
                if (std.mem.eql(u8, s, "9223372036854775808"))
                    return .{ .flag = 63 }; // TODO: verify this is not off-by-one
                std.debug.panic(
                    "todo: handle enum flag value json number string '{s}' ('{s}' '{s}')",
                    .{s, self.pool_name, self.short_name },
                );
            },
            else => {
                std.debug.panic("todo: flagIndex for json value {s}", .{@tagName(self.value)});
            },
        }
    }
};
fn matchLen(a: []const u8, b: []const u8) usize {
    var i: usize = 0;
    while (i < a.len and i < b.len and a[i] == b[i]) : (i += 1) {}
    return i;
}
fn setShortNames(values: []EnumValue) void {
    var at_first = true;
    var longest_prefix_match: []const u8 = undefined;
    for (values) |*val_ref| {
        if ((val_ref.pool_name.eql(global_symbol_none) or
            val_ref.pool_name.eql(global_symbol_None)) and
            val_ref.valueIsZero())
        {
            val_ref.short_name = val_ref.pool_name.slice;
            val_ref.no_alias = true;
            continue;
        }

        if (at_first) {
            longest_prefix_match = val_ref.pool_name.slice;
            at_first = false;
        } else {
            longest_prefix_match.len = matchLen(longest_prefix_match, val_ref.pool_name.slice);
        }
    }
    for (values) |*val_ref| {
        if (val_ref.no_alias)
            continue;

        if (val_ref.pool_name.slice.len == 0) {
            // TODO: this happens to snmp:AS_ANY_TYPE, it's probably a bug that should be filed
            val_ref.short_name = "__no_name__";
        } else {
            var cutoff = longest_prefix_match.len;
            if (cutoff > 0 and cutoff == val_ref.pool_name.slice.len) {
                cutoff -= 1;
            }
            val_ref.short_name = val_ref.pool_name.slice[cutoff..];
        }
    }
}

fn generateEnum(
    sdk_file: *SdkFile,
    writer: *CodeWriter,
    type_obj: json.ObjectMap,
    pool_name: StringPool.Val,
    enum_alias_conflicts: *StringPool.HashMap(StringPool.Val),
    def_prefix: []const u8,
    def_suffix: []const u8,
) !void {
    try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8{ "Name", "Platform", "Architectures", "Kind", "Flags", "Scoped", "Values", "IntegerBase" }, sdk_file);
    const flags = (try jsonObjGetRequired(type_obj, "Flags", sdk_file)).bool;
    const scoped = (try jsonObjGetRequired(type_obj, "Scoped", sdk_file)).bool;
    const json_values = (try jsonObjGetRequired(type_obj, "Values", sdk_file)).array;
    const integer_base = switch (try jsonObjGetRequired(type_obj, "IntegerBase", sdk_file)) {
        .null => "i32",
        .string => |s| nativeTypeToZigType(global_native_type_map.get(s) orelse
            fatal("enum '{}' has an unknown IntegerBase '{s}'", .{ pool_name, s })),
        else => jsonPanic(),
    };
    const values = try allocator.alloc(EnumValue, json_values.items.len);
    var values_initialized_len: usize = 0;
    defer allocator.free(values);
    for (json_values.items) |*value_node_ptr| {
        const value_obj = value_node_ptr.object;
        try jsonObjEnforceKnownFieldsOnly(value_obj, &[_][]const u8{ "Name", "Value" }, sdk_file);
        const value_tmp_name = (try jsonObjGetRequired(value_obj, "Name", sdk_file)).string;
        values[values_initialized_len] = .{
            .pool_name = try global_symbol_pool.add(value_tmp_name),
            .short_name = "",
            .value = try jsonObjGetRequired(value_obj, "Value", sdk_file),
            .no_alias = false,
            .conflict_index = null,
        };
        values_initialized_len += 1;
    }
    setShortNames(values);

    // find conflicts
    for (values, 0..) |val, i| {
        for (values[0..i], 0..) |other_val, j| {
            if (jsonEql(val.value, other_val.value)) {
                values[i].conflict_index = j;
                break;
            }
        }
    }
    var flag_map = [1]?*EnumValue{ null } ** 64;

    const enum_type = if (flags) "packed struct" else "enum";

    try writer.linef("{s}{s}({s}) {{", .{ def_prefix, enum_type, integer_base });
    if (values.len == 0) {
        // zig doesn't allow empty enums
        try writer.line("    _");
    } else if (!flags) {
        for (values) |val| {
            if (val.conflict_index) |conflict_index| {
                try writer.linef("    // {s} = {}, this enum value conflicts with {s}", .{ std.zig.fmtId(val.short_name), fmtJson(val.value), std.zig.fmtId(values[conflict_index].short_name) });
            } else {
                try writer.linef("    {s} = {},", .{ std.zig.fmtId(val.short_name), fmtJson(val.value) });
            }
        }
        if (non_exhaustive_enums.get(pool_name.slice)) |_| {
            try writer.linef("    _,", .{});
        }
    }
    if (flags) {
        for (values) |*val| {
            if (val.conflict_index) |_| continue;
            switch (val.flagsValue()) {
                .zero => {},
                .flag => |index| {
                    // should have had a conflict_index
                    std.debug.assert(flag_map[index] == null);
                    flag_map[index] = val;
                },
                .mask => {},
            }
        }

        const bit_count: usize = blk: {
            if (std.mem.eql(u8, integer_base, "u16")) break :blk 16;
            if (std.mem.eql(u8, integer_base, "i32")) break :blk 32;
            if (std.mem.eql(u8, integer_base, "u32")) break :blk 32;
            if (std.mem.eql(u8, integer_base, "u64")) break :blk 64;
            std.debug.panic("todo: handle integer base '{s}'", .{integer_base});
        };
        for (flag_map[0..bit_count], 0..) |maybe_flag, i| {
            const flag = maybe_flag orelse {
                try writer.linef("    _{}: u1 = 0,", .{i});
                continue;
            };
            try writer.linef("    {s}: u1 = 0,", .{ std.zig.fmtId(flag.short_name) });
        }
        for (flag_map[bit_count..]) |maybe_flag| {
            if (maybe_flag) |_|
                jsonPanicMsg("enum value is out-of-range for this flag integer base type", .{});
        }

        // print any flags (only 1-bit values) that had conflicts
        for (values) |*val| {
            switch (val.flagsValue()) {
                .zero => {},
                .flag => {
                    if (val.conflict_index) |conflict_index| {
                        try writer.linef("    // {s} ({}) conflicts with {s}", .{
                            std.zig.fmtId(val.short_name),
                            fmtJson(val.value),
                            std.zig.fmtId(values[conflict_index].short_name),
                        });
                    }
                },
                .mask => {},
            }
        }
    }
    try writer.linef("}}{s}", .{def_suffix});

    if (std.mem.eql(u8, def_suffix, ",")) {
        @panic("can't generate arch-specific enum aliases right now");
    }
    std.debug.assert(std.mem.eql(u8, def_suffix, ";"));

    if (scoped) {
        try writer.linef("// NOTE: not creating aliases because this enum is 'Scoped'", .{});
        return;
    }
    if (suppress_enum_aliases.get(pool_name.slice)) |_| {
        try writer.linef("// TODO: enum '{}' has known issues with its value aliases", .{pool_name});
        return;
    }

    // create value aliases
    var alias_count: u32 = 0;
    for (values) |val| {
        if (enum_alias_conflicts.get(val.pool_name)) |existing| {
            std.debug.print("error: enum value alias '{}' is defined by 2 enum types.\n", .{val.pool_name});
            std.debug.print("       add one of the following lines to the suppress_enum_aliases list:\n", .{});
            std.debug.print("    .{{ \"{}\", .{{}} }},\n", .{existing});
            std.debug.print("    .{{ \"{}\", .{{}} }},\n", .{pool_name});
            std.os.exit(0xff);
        }
        if (val.no_alias) {
            continue;
        }
        alias_count += 1;
        try enum_alias_conflicts.put(val.pool_name, pool_name);
        try sdk_file.const_exports.append(val.pool_name);
        const target_short_name = if (val.conflict_index) |i| values[i].short_name else val.short_name;
        if (flags) switch (val.flagsValue()) {
            .zero => try writer.linef("pub const {} = {}{{ }};", .{
                val.pool_name, pool_name
            }),
            .flag => try writer.linef("pub const {} = {}{{ .{} = 1 }};", .{
                val.pool_name, pool_name, std.zig.fmtId(target_short_name)
            }),
            .mask => |mask| {
                try writer.linef("pub const {} = {}{{", .{
                    val.pool_name, pool_name
                });
                var mask_left = mask;
                var index: u6 = 0;
                while (true) : (index += 1) {
                    const next_flag_bit: i64 = (@as(i64, 1) << index);
                    if (0 != (next_flag_bit & mask)) {
                        if (flag_map[index]) |flag| {
                            const flag_target_short_name = if (flag.conflict_index) |i| values[i].short_name else flag.short_name;
                            try writer.linef("    .{} = 1,", .{std.zig.fmtId(flag_target_short_name)});
                        } else {
                            try writer.linef("    ._{} = 1,", .{index});
                        }
                        mask_left &= ~next_flag_bit;
                    }
                    if (mask_left == 0) break;
                }
                try writer.line("};");
            },
        } else {
            try writer.linef("pub const {} = {}.{};", .{ val.pool_name, pool_name, std.zig.fmtId(target_short_name) });
        }
    }
}

fn generateCom(sdk_file: *SdkFile, writer: *CodeWriter, type_obj: json.ObjectMap, arches: ArchFlags, com_pool_name: StringPool.Val, def_prefix: []const u8) !void {
    try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8{ "Kind", "Name", "Platform", "Architectures", "Guid", "Attrs", "Interface", "Methods" }, sdk_file);

    const com_optional_guid: ?[]const u8 = switch (try jsonObjGetRequired(type_obj, "Guid", sdk_file)) {
        .null => null,
        .string => |s| s,
        else => jsonPanic(),
    };
    var is_agile = false;
    {
        const attr_nodes = (try jsonObjGetRequired(type_obj, "Attrs", sdk_file)).array;
        for (attr_nodes.items) |attr_node| {
            switch (attr_node) {
                .string => |s| {
                    if (std.mem.eql(u8, s, "Agile")) {
                        is_agile = true;
                    } else jsonPanic();
                },
                else => jsonPanic(),
            }
        }
    }
    if (is_agile) {
        try writer.line("// This COM type is Agile, not sure what that means");
    }
    const com_optional_iface: ?json.ObjectMap = switch (try jsonObjGetRequired(type_obj, "Interface", sdk_file)) {
        .null => null,
        .object => |o| o,
        else => jsonPanic(),
    };
    const com_methods = (try jsonObjGetRequired(type_obj, "Methods", sdk_file)).array;
    const skip = com_types_to_skip.has(com_pool_name.slice);
    if (skip) {
        try writer.line("// WARNING: this COM type has been skipped because it causes some sort of error");
    }

    const iid_pool = try global_symbol_pool.addFormatted("IID_{s}", .{com_pool_name.slice});
    if (com_optional_guid) |guid| {
        sdk_file.uses_guid = true;
        try writer.linef("const {s}_Value = Guid.initString(\"{s}\");", .{ iid_pool, guid });
        try writer.linef("pub const {s} = &{0s}_Value;", .{iid_pool});
        try sdk_file.const_exports.append(iid_pool);
    }

    try writer.linef("{s}extern struct {{", .{def_prefix});
    try writer.line("    pub const VTable = extern struct {");
    var iface_formatter: TypeRefFormatter = undefined;

    if (skip) {
        try writer.line("        _: *opaque{}, // just a placeholder because this COM type is skipped");
    } else {
        if (com_optional_iface) |iface| {
            iface_formatter = try addTypeRefs(sdk_file, arches, iface, .{ .reason = .direct_type_access, .anon_types = null, .null_modifier = 0 }, null);
            try writer.write("        base: ", .{ .nl = false });
            try generateTypeRef(sdk_file, writer, iface_formatter);
            try writer.write(".VTable,", .{ .start = .mid });
        }

        // some COM objects have methods with the same name and only differ in parameter types
        var method_conflicts = StringHashMap(u8).init(allocator);
        defer method_conflicts.deinit();

        for (com_methods.items) |*method_node_ptr| {
            const method_name = (try jsonObjGetRequired(method_node_ptr.object, "Name", sdk_file)).string;
            const count = method_conflicts.get(method_name) orelse 0;
            try method_conflicts.put(method_name, count + 1);
            writer.depth += 2;
            try generateFunction(sdk_file, writer, method_node_ptr.object, .{ .com = .{ .both = .{
                .symbol_suffix = if (count == 0) null else count,
                .self_type = com_pool_name.slice,
            } } });
            writer.depth -= 2;
        }
    }

    try writer.line("    };");
    try writer.linef("    vtable: *const VTable,", .{});

    // some COM objects have methods with the same name and only differ in parameter types
    var method_conflicts = StringHashMap(u8).init(allocator);
    defer method_conflicts.deinit();

    // Generate wrapper methods for every entry in the vtable
    try writer.line("    pub fn MethodMixin(comptime T: type) type { return struct {");
    if (!skip) {
        if (com_optional_iface) |_| {
            // For now we're putting this inside a sub-struct to avoid name conflicts
            try writer.write("        pub usingnamespace ", .{ .nl = false });
            try generateTypeRef(sdk_file, writer, iface_formatter);
            try writer.write(".MethodMixin(T);", .{ .start = .mid });
        }
        for (com_methods.items) |*method_node_ptr| {
            const method_obj = method_node_ptr.object;
            const method_name = (try jsonObjGetRequired(method_obj, "Name", sdk_file)).string;
            const return_type = (try jsonObjGetRequired(method_obj, "ReturnType", sdk_file)).object;
            const params = (try jsonObjGetRequired(method_obj, "Params", sdk_file)).array;

            const count = method_conflicts.get(method_name) orelse 0;
            try method_conflicts.put(method_name, count + 1);

            try writer.line("        // NOTE: method is namespaced with interface name to avoid conflicts for now");
            try writer.writef("        pub fn {s}_{s}", .{ com_pool_name, method_name }, .{ .nl = false });
            if (count > 0) {
                try writer.writef("{}", .{count}, .{ .start = .mid, .nl = false });
            }
            try writer.write("(self: *const T", .{ .start = .mid, .nl = false });
            for (params.items) |*param_node_ptr| {
                const param_obj = param_node_ptr.object;
                try jsonObjEnforceKnownFieldsOnly(param_obj, &[_][]const u8{ "Name", "Type", "Attrs" }, sdk_file);
                const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).string;
                const param_type = (try jsonObjGetRequired(param_obj, "Type", sdk_file)).object;
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // TODO: set null_modifier properly
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                const modifiers = ParamModifiers{};
                const param_options = processParamAttrs(
                    (try jsonObjGetRequired(param_obj, "Attrs", sdk_file)).array,
                    .var_decl,
                    modifiers,
                    sdk_file,
                );
                // NOTE: don't need to call addTypeRefs because it was already called in generateFunction above
                const param_type_formatter = fmtTypeRef(param_type, arches, param_options, null);
                if (param_options.optional_bytes_param_index) |bytes_param_index| {
                    _ = bytes_param_index; // NOTE: can't print this because we are currently inline
                    //try writer.linef("// TODO: what to do with BytesParamIndex {}?", .{bytes_param_index});
                }
                try writer.writef(", {s}: ", .{fmtParamId(param_name, sdk_file.param_names_to_avoid_map_get_fn)}, .{ .start = .mid, .nl = false });
                try generateTypeRef(sdk_file, writer, param_type_formatter);
            }
            // NOTE: don't need to call addTypeRefs because it was already called in generateFunction above
            // TODO: set is_const, in and out properly
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            // TODO: set null_modifier properly
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
            const return_type_formatter = fmtTypeRef(return_type, arches, .{ .reason = .var_decl, .is_const = false, .in = false, .out = false, .anon_types = null, .null_modifier = 0 }, null);
            try writer.write(") callconv(.Inline) ", .{ .start = .mid, .nl = false });
            try generateTypeRef(sdk_file, writer, return_type_formatter);
            try writer.write(" {", .{ .start = .mid });
            try writer.writef("            return @as(*const {s}.VTable, @ptrCast(self.vtable)).{s}(@as(*const {0s}, @ptrCast(self))", .{ com_pool_name, std.zig.fmtId(method_name) }, .{ .nl = false });
            for (params.items) |*param_node_ptr| {
                const param_obj = param_node_ptr.object;
                const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).string;
                try writer.writef(", {s}", .{fmtParamId(param_name, sdk_file.param_names_to_avoid_map_get_fn)}, .{ .start = .mid, .nl = false });
            }
            try writer.write(");", .{ .start = .any });
            try writer.line("        }");
        }
    }
    try writer.line("    };}");
    try writer.line("    pub usingnamespace MethodMixin(@This());");
    try writer.line("};");
}

fn processParamAttrs(
    attrs: json.Array,
    reason: TypeRefFormatter.Reason,
    modifiers: ParamModifiers,
    sdk_file: *const SdkFile,
) TypeRefFormatter.Options {
    var opts = TypeRefFormatter.Options{
        .reason = reason,
        .anon_types = null,
        .union_pointer = modifiers.union_pointer,
        .null_modifier = modifiers.not_null,
    };
    for (attrs.items) |*attr_node_ptr| {
        switch (attr_node_ptr.*) {
            .object => |attr_obj| {
                const kind = (try jsonObjGetRequired(attr_obj, "Kind", sdk_file)).string;
                if (std.mem.eql(u8, kind, "MemorySize")) {
                    try jsonObjEnforceKnownFieldsOnly(attr_obj, &[_][]const u8{ "Kind", "BytesParamIndex" }, sdk_file);
                    opts.optional_bytes_param_index = @intCast((try jsonObjGetRequired(attr_obj, "BytesParamIndex", sdk_file)).integer);
                } else if (std.mem.eql(u8, kind, "FreeWith")) {
                    try jsonObjEnforceKnownFieldsOnly(attr_obj, &[_][]const u8{ "Kind", "Func" }, sdk_file);
                    const func = (try jsonObjGetRequired(attr_obj, "Func", sdk_file)).string;
                    _ = func; // TODO: what to do with this?
                } else jsonPanicMsg("unknown param attr Kind '{s}'", .{kind});
            },
            .string => |attr_str| {
                if (std.mem.eql(u8, attr_str, "Const")) {
                    opts.is_const = true;
                } else if (std.mem.eql(u8, attr_str, "In")) {
                    opts.in = true;
                } else if (std.mem.eql(u8, attr_str, "Out")) {
                    opts.out = true;
                } else if (std.mem.eql(u8, attr_str, "Optional")) {
                    opts.optional = true;
                } else if (std.mem.eql(u8, attr_str, "RetVal")) {
                    opts.ret_val = true;
                } else if (std.mem.eql(u8, attr_str, "NotNullTerminated")) {
                    opts.not_null_term = true;
                } else if (std.mem.eql(u8, attr_str, "NullNullTerminated")) {
                    opts.null_null_term = true;
                } else if (std.mem.eql(u8, attr_str, "ComOutPtr")) {
                    opts.com_out_ptr = true;
                } else if (std.mem.eql(u8, attr_str, "DoNotRelease")) {
                    opts.do_not_release = true;
                } else if (std.mem.eql(u8, attr_str, "Reserved")) {
                    opts.reserved = true;
                } else {
                    jsonPanicMsg("unhandled custom param attribute '{s}'", .{attr_str});
                }
            },
            else => jsonPanic(),
        }
    }
    return opts;
}

// Skip these function pointers to workaround: https://github.com/ziglang/zig/issues/4476
fn funcPtrHasDependencyLoop(name: []const u8) bool {
    if (func_ptr_dependency_loop_problems.get(name)) |_| return true;
    if (std.mem.startsWith(u8, name, "PFN_")) return std.mem.startsWith(u8, name, "PFN_CPD_") or std.mem.startsWith(u8, name, "PFN_PROVIDER_") or std.mem.startsWith(u8, name, "PFN_PROVUI_");
    if (std.mem.startsWith(u8, name, "PIBIO_")) return std.mem.startsWith(u8, name, "PIBIO_SENSOR_") or std.mem.startsWith(u8, name, "PIBIO_ENGINE_") or std.mem.startsWith(u8, name, "PIBIO_STORAGE_") or std.mem.startsWith(u8, name, "PIBIO_FRAMEWORK_");
    if (std.mem.startsWith(u8, name, "LPDDHAL")) return std.mem.startsWith(u8, name, "LPDDHAL_") or std.mem.startsWith(u8, name, "LPDDHALSURFCB_") or std.mem.startsWith(u8, name, "LPDDHALPALCB_") or std.mem.startsWith(u8, name, "LPDDHALVPORTCB_") or std.mem.startsWith(u8, name, "LPDDHALCOLORCB_") or std.mem.startsWith(u8, name, "LPDDHALMOCOMPCB_");
    return std.mem.startsWith(u8, name, "UText") or std.mem.startsWith(u8, name, "UCharIterator");
}
const func_ptr_dependency_loop_problems = std.ComptimeStringMap(Nothing, .{
    .{ "FREEOBJPROC", .{} },
    .{ "LPEXCEPFINO_DEFERRED_FILLIN", .{} },
    .{ "LPDDENUMSURFACESCALLBACK", .{} },
    .{ "LPDDENUMSURFACESCALLBACK2", .{} },
    .{ "LPDDENUMSURFACESCALLBACK7", .{} },
    .{ "OEMCUIPCALLBACK", .{} },
    .{ "PAudioStateMonitorCallback", .{} },
    .{ "PFN_IO_COMPLETION", .{} },
    .{ "PFN_RPCNOTIFICATION_ROUTINE", .{} },
    .{ "PFNFILLTEXTBUFFER", .{} },
    .{ "WSD_STUB_FUNCTION", .{} },
    .{ "PWSD_SOAP_MESSAGE_HANDLER", .{} },
    .{ "WS_ASYNC_FUNCTION", .{} },
    .{ "CALLERRELEASE", .{} },
    .{ "PIO_IRP_EXT_PROCESS_TRACKED_OFFSET_CALLBACK", .{} },
    .{ "MI_MethodDecl_Invoke", .{} },
    .{ "MI_ProviderFT_GetInstance", .{} },
    .{ "MI_ProviderFT_CreateInstance", .{} },
    .{ "MI_ProviderFT_ModifyInstance", .{} },
    .{ "MI_ProviderFT_DeleteInstance", .{} },
    .{ "MI_ProviderFT_AssociatorInstances", .{} },
    .{ "MI_ProviderFT_ReferenceInstances", .{} },
    .{ "MI_ProviderFT_Invoke", .{} },
    .{ "PCMSCALLBACKW", .{} },
    .{ "PCMSCALLBACKA", .{} },
    .{ "PEVENT_TRACE_BUFFER_CALLBACKW", .{} },
    .{ "PEVENT_TRACE_BUFFER_CALLBACKA", .{} },
    .{ "EXPR_EVAL", .{} },
    .{ "XMIT_HELPER_ROUTINE", .{} },
});

const funcs_with_issues = std.ComptimeStringMap(Nothing, .{
    // These functions don't work yet because Zig doesn't support the 16-byte Guid struct in the C ABI yet
    // See: https://github.com/ziglang/zig/issues/1481
    .{ "CorePrinterDriverInstalledA", .{} },
    .{ "CorePrinterDriverInstalledW", .{} },
    // workaround https://github.com/microsoft/win32metadata/issues/520
    .{ "AuthzInitializeResourceManagerEx", .{} },
    // The 3rd parameter "ObjectType" is "Optional" but is typed as an enum?
    // but the docs says it's a pointer?? wtf is going on with this one?
    .{ "BuildTrusteeWithObjectsAndNameA", .{} },
    .{ "BuildTrusteeWithObjectsAndNameW", .{} },
    // these functions contain invalid optional types (https://github.com/microsoft/win32metadata/issues/519)
    .{ "NCryptOpenKey", .{} },
    .{ "NCryptTranslateHandle", .{} },
    .{ "CryptSignAndEncodeCertificate", .{} },
    .{ "MFPCreateMediaPlayer", .{} },
    .{ "QOSRemoveSocketFromFlow", .{} },
    .{ "PrjUpdateFileIfNeeded", .{} },
    .{ "PrjDeleteFile", .{} },
    .{ "JetSetSystemParameterA", .{} },
    .{ "JetSetSystemParameterW", .{} },
    .{ "MsiGetComponentPathExA", .{} },
    .{ "MsiGetComponentPathExW", .{} },
    .{ "SymLoadModuleEx", .{} },
    .{ "SymLoadModuleExW", .{} },
    .{ "PssDuplicateSnapshot", .{} },
});

const ArchCaseContext = enum { outside_arch_case, inside_arch_case };
const FuncPtrKind = union(enum) {
    fixed: void,
    ptr: union(enum) {
        stage1,
        not_stage1,
        both: struct { def_prefix: []const u8, def_suffix: []const u8 },
    },
    com: union(enum) {
        stage1: struct { self_type: []const u8 },
        not_stage1: struct { self_type: []const u8 },
        both: struct {
            symbol_suffix: ?u8,
            self_type: []const u8,
        },
    },
};

fn generateArchPrefix(writer: *CodeWriter, module_depth: u2, arches: ArchFlags, prefix: []const u8) !void {
    std.debug.assert(arches.flags != ArchFlags.all.flags);
    try writer.linef("{s}usingnamespace switch (@import(\"{s}zig.zig\").arch) {{", .{ prefix, import_prefix_table[module_depth] });

    var buf: [40]u8 = undefined;
    const case_prefix = buf[0..try arches.formatCase(&buf)];
    try writer.linef("{s}struct {{", .{case_prefix});
    try writer.line("");
}
fn generateArchSuffix(writer: *CodeWriter) void {
    writer.line("") catch @panic("here");
    writer.line("}, else => struct { } };") catch @panic("here");
}

const ParamModifiers = struct {
    not_null: NullModifier = 0,
    union_pointer: bool = false,
};
const ParamModifierSet = struct {
    const max_params = 30;
    ret: ParamModifiers = .{},
    params: [max_params]ParamModifiers = [_]ParamModifiers{.{}} ** max_params,
};

fn findParam(
    sdk_file: *SdkFile,
    params: []const json.Value,
    name: []const u8,
) ?usize {
    for (params, 0..) |*param_node_ptr, i| {
        const param_obj = param_node_ptr.object;
        const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).string;
        if (std.mem.eql(u8, param_name, name))
            return i;
    }
    return null;
}

fn generateFunction(
    sdk_file: *SdkFile,
    writer: *CodeWriter,
    function_obj: json.ObjectMap,
    func_kind: FuncPtrKind,
) !void {
    switch (func_kind) {
        .fixed => try jsonObjEnforceKnownFieldsOnly(function_obj, &[_][]const u8{ "Name", "Platform", "Architectures", "SetLastError", "DllImport", "ReturnType", "ReturnAttrs", "Attrs", "Params" }, sdk_file),
        .ptr, .com => try jsonObjEnforceKnownFieldsOnly(function_obj, &[_][]const u8{ "Kind", "Name", "Platform", "Architectures", "SetLastError", "ReturnType", "ReturnAttrs", "Attrs", "Params" }, sdk_file),
    }

    const func_name_tmp = (try jsonObjGetRequired(function_obj, "Name", sdk_file)).string;
    const platform_node = try jsonObjGetRequired(function_obj, "Platform", sdk_file);
    const arches = ArchFlags.initJson((try jsonObjGetRequired(function_obj, "Architectures", sdk_file)).array.items);
    const set_last_error = (try jsonObjGetRequired(function_obj, "SetLastError", sdk_file)).bool;
    _ = set_last_error; // ignored for now
    const dll_import = if (func_kind == .fixed) (try jsonObjGetRequired(function_obj, "DllImport", sdk_file)).string else "";
    const return_type = (try jsonObjGetRequired(function_obj, "ReturnType", sdk_file)).object;
    const return_attrs = (try jsonObjGetRequired(function_obj, "ReturnAttrs", sdk_file)).array;
    const attrs = (try jsonObjGetRequired(function_obj, "Attrs", sdk_file)).array;
    const params = (try jsonObjGetRequired(function_obj, "Params", sdk_file)).array;

    var modifier_set = ParamModifierSet{};

    const func_name_pool = try global_symbol_pool.add(func_name_tmp);
    if (func_kind == .fixed or func_kind == .ptr) {
        if (func_kind == .fixed) {
            try sdk_file.func_exports.put(func_name_pool, .{});
        }
        if (sdk_file.not_null_funcs.get(func_name_pool.slice)) |notnull_node| {
            try sdk_file.not_null_funcs_applied.put(func_name_pool, .{});
            jsonEnforce(notnull_node.array.items.len > 0);
            modifier_set.ret.not_null = @as(NullModifier, @intCast(notnull_node.array.items[0].integer));
            for (notnull_node.array.items[1..], 0..) |item, i| {
                jsonEnforce(i < modifier_set.params.len); // if we hit this, increase max param count
                jsonEnforce(i < params.items.len);
                modifier_set.params[i].not_null = @as(NullModifier, @intCast(item.integer));
            }
        }
        if (sdk_file.union_pointer_funcs.get(func_name_pool.slice)) |union_pointer_node| {
            try sdk_file.union_pointer_funcs_applied.put(func_name_pool, .{});
            jsonEnforce(union_pointer_node.array.items.len > 0);
            for (union_pointer_node.array.items) |name_node| {
                const name = switch (name_node) {
                    .string => |name| name,
                    else => jsonPanic(),
                };
                const index = findParam(sdk_file, params.items, name) orelse jsonPanicMsg(
                    "function '{s}' from unionpointers.json does not have a parameter named '{s}'",
                    .{ func_name_pool, name },
                );
                modifier_set.params[index].union_pointer = true;
            }
        }
    }

    if (func_kind != .ptr and arches.flags != ArchFlags.all.flags) {
        std.debug.assert(func_kind != .com); // I don't think COM is supposed to support arch specific methods
        try generateArchPrefix(writer, sdk_file.depth, arches, "pub ");
    }
    defer {
        if (func_kind != .ptr and arches.flags != ArchFlags.all.flags) generateArchSuffix(writer);
    }

    var is_noreturn = false;
    for (attrs.items) |attr_node| {
        switch (attr_node) {
            .string => |attr| {
                if (std.mem.eql(u8, attr, "SpecialName")) {
                    try writer.line("// TODO: this function has a \"SpecialName\", should Zig do anything with this?");
                } else if (std.mem.eql(u8, attr, "PreserveSig")) {
                    // we don't care about PreserveSig because we don't automatically turn HRESULT return
                    // values into errors
                } else if (std.mem.eql(u8, attr, "DoesNotReturn")) {
                    is_noreturn = true;
                } else jsonPanic();
            },
            else => jsonPanic(),
        }
    }
    if (func_kind != .ptr) {
        // if it's a function ptr then this comment will already have been generated in generateType
        try generatePlatformComment(writer, platform_node);
    }
    if (funcs_with_issues.get(func_name_tmp)) |_| {
        try writer.linef("// This function from dll '{s}' is being skipped because it has some sort of issue", .{dll_import});
        try writer.linef("pub fn {s}() void {{ @panic(\"this function is not working\"); }}", .{func_name_tmp});
        return;
    }

    switch (func_kind) {
        .fixed => {
            // we modify the dll_import to be lowercase because zig generates
            // the .lib files using lowercase since that's what mingw uses.
            // note the casing only matters on case-sensitive filesystems
            try writer.linef("pub extern \"{s}\" fn {s}(", .{ fmtLower(dll_import, 100), std.zig.fmtId(func_name_tmp) });
        },
        .ptr => |ptr_data_union| switch (ptr_data_union) {
            .stage1 => try writer.line(".stage1 => fn("),
            .not_stage1 => try writer.line("else => *const fn("),
            .both => |ptr_data| {
                try writer.linef("{s}switch (@import(\"builtin\").zig_backend) {{", .{ptr_data.def_prefix});
                writer.depth += 1;
                try generateFunction(sdk_file, writer, function_obj, .{ .ptr = .stage1 });
                try generateFunction(sdk_file, writer, function_obj, .{ .ptr = .not_stage1 });
                writer.depth -= 1;
                try writer.linef("}} {s}", .{ptr_data.def_suffix});
                return;
            },
        },
        .com => |com_data_union| {
            const self_type = blk: {
                switch (com_data_union) {
                    .stage1 => |com_data| {
                        try writer.line(".stage1 => fn(");
                        break :blk com_data.self_type;
                    },
                    .not_stage1 => |com_data| {
                        try writer.line("else => *const fn(");
                        break :blk com_data.self_type;
                    },
                    .both => |com_data| {
                        if (com_data.symbol_suffix) |s| {
                            try writer.writef("{s}{}", .{ func_name_tmp, s }, .{ .nl = false });
                        } else {
                            try writer.writef("{s}", .{std.zig.fmtId(func_name_tmp)}, .{ .nl = false });
                        }
                        try writer.write(": switch (@import(\"builtin\").zig_backend) {", .{ .start = .mid });
                        writer.depth += 1;
                        try generateFunction(sdk_file, writer, function_obj, .{ .com = .{ .stage1 = .{ .self_type = com_data.self_type } } });
                        try generateFunction(sdk_file, writer, function_obj, .{ .com = .{ .not_stage1 = .{ .self_type = com_data.self_type } } });
                        writer.depth -= 1;
                        try writer.line("},");
                        return;
                    },
                }
            };
            try writer.linef("    self: *const {s},", .{self_type});
        },
    }

    try generateParams(sdk_file, writer, arches, modifier_set, params.items);

    try writer.writef(") callconv(@import(\"std\").os.windows.WINAPI) ", .{}, .{ .nl = false });
    if (is_noreturn) {
        try writer.write("noreturn", .{ .start = .mid, .nl = false });
    } else {
        // TODO: set is_const, in and out properly
        const return_opts = processParamAttrs(return_attrs, .var_decl, modifier_set.ret, sdk_file);
        const return_type_formatter = try addTypeRefs(sdk_file, arches, return_type, return_opts, null);
        try generateTypeRef(sdk_file, writer, return_type_formatter);
    }
    const term = switch (func_kind) {
        .fixed => ";",
        .ptr => |ptr_data| switch (ptr_data) {
            .stage1, .not_stage1 => ",",
            .both => @panic("code bug"),
        },
        .com => ",",
    };
    try writer.writef("{s}", .{term}, .{ .start = .mid });
}

fn generateParams(
    sdk_file: *SdkFile,
    writer: *CodeWriter,
    arches: ArchFlags,
    modifier_set: ParamModifierSet,
    params: []const json.Value,
) !void {
    for (params, 0..) |*param_node_ptr, i| {
        const param_obj = param_node_ptr.object;
        try jsonObjEnforceKnownFieldsOnly(param_obj, &[_][]const u8{ "Name", "Type", "Attrs" }, sdk_file);
        const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).string;
        const param_type = (try jsonObjGetRequired(param_obj, "Type", sdk_file)).object;
        const modifiers = modifier_set.params[i];
        const param_options = processParamAttrs((try jsonObjGetRequired(param_obj, "Attrs", sdk_file)).array, .var_decl, modifiers, sdk_file);
        const param_type_formatter = try addTypeRefs(sdk_file, arches, param_type, param_options, null);
        if (param_options.optional_bytes_param_index) |bytes_param_index| {
            try writer.linef("    // TODO: what to do with BytesParamIndex {}?", .{bytes_param_index});
        }
        try writer.writef("    {s}: ", .{std.zig.fmtId(param_name)}, .{ .nl = false });
        try generateTypeRef(sdk_file, writer, param_type_formatter);
        try writer.write(",", .{ .start = .mid });
    }
}

fn generateUnicodeAliases(sdk_file: *SdkFile, writer: *CodeWriter, unicode_aliases: []json.Value) !void {
    try writer.line("const thismodule = @This();");
    try writer.linef("pub usingnamespace switch (@import(\"{s}zig.zig\").unicode_mode) {{", .{sdk_file.getWin32DirImportPrefix()});
    try writer.line("    .ansi => struct {");
    for (unicode_aliases) |*alias_node_ptr| {
        try writer.linef("        pub const {s} = thismodule.{0s}A;", .{alias_node_ptr.string});
    }
    try writer.line("    },");
    try writer.line("    .wide => struct {");
    for (unicode_aliases) |*alias_node_ptr| {
        try writer.linef("        pub const {s} = thismodule.{0s}W;", .{alias_node_ptr.string});
    }
    try writer.line("    },");
    try writer.line("    .unspecified => if (@import(\"builtin\").is_test) struct {");
    for (unicode_aliases) |*alias_node_ptr| {
        try writer.linef("        pub const {s} = *opaque{{}};", .{alias_node_ptr.string});
    }
    try writer.line("    } else struct {");
    for (unicode_aliases) |*alias_node_ptr| {
        try writer.linef("        pub const {s} = @compileError(\"'{0s}' requires that UNICODE be set to true or false in the root module\");", .{alias_node_ptr.string});
    }
    try writer.line("    },");
    try writer.line("};");
}

const Arch = enum { X86, X64, Arm64 };
const arch_name_map = std.ComptimeStringMap(Arch, .{
    .{ "X86", Arch.X86 },
    .{ "X64", Arch.X64 },
    .{ "Arm64", Arch.Arm64 },
});
pub fn getFlag(arch: Arch) ArchFlags {
    return switch (arch) {
        .X86 => ArchFlags.X86,
        .X64 => ArchFlags.X64,
        .Arm64 => ArchFlags.Arm64,
    };
}
const ArchFlags = struct {
    pub const X86 = ArchFlags{ .flags = 0x01 };
    pub const X64 = ArchFlags{ .flags = 0x02 };
    pub const Arm64 = ArchFlags{ .flags = 0x04 };
    pub const all = ArchFlags{ .flags = X86.flags | X64.flags | Arm64.flags };

    flags: u8,

    pub fn initJson(architectures: []json.Value) ArchFlags {
        if (architectures.len == 0) {
            return ArchFlags.all;
        }
        var result = ArchFlags{ .flags = 0 };
        for (architectures) |arch_node| {
            const arch = arch_name_map.get(arch_node.string) orelse std.debug.panic("unhandled arch '{s}'", .{arch_node.string});
            result.flags |= getFlag(arch).flags;
        }
        return result;
    }

    pub fn formatCase(self: ArchFlags, buf: []u8) !usize {
        var fbs = std.io.fixedBufferStream(buf);
        const arch_writer = fbs.writer();
        var case_prefix: []const u8 = "";
        inline for (std.meta.fields(Arch)) |arch_field| {
            const arch = @field(Arch, arch_field.name);
            if ((self.flags & getFlag(arch).flags) != 0) {
                try arch_writer.print("{s}.{s}", .{ case_prefix, @tagName(arch) });
                case_prefix = ", ";
            }
        }
        try arch_writer.writeAll(" => ");
        return fbs.pos;
    }
};

fn ArchSpecificObject(comptime T: type) type {
    return struct {
        arches: ArchFlags,
        obj: T,
    };
}
fn ArchSpecificObjects(comptime T: type) type {
    return struct {
        object_array: [@typeInfo(Arch).Enum.fields.len]ArchSpecificObject(T) = undefined,
        object_count: u8 = 0,
        pub fn getItems(self: *@This()) []ArchSpecificObject(T) {
            return self.object_array[0..self.object_count];
        }
        pub fn getItemsConst(self: *const @This()) []const ArchSpecificObject(T) {
            return self.object_array[0..self.object_count];
        }
        pub fn add(self: *@This(), obj: ArchSpecificObject(T)) void {
            std.debug.assert(self.object_count < self.object_array.len);
            self.object_array[self.object_count] = obj;
            self.object_count += 1;
        }
    };
}

pub fn jsonObjEnforceKnownFieldsOnly(map: std.json.ObjectMap, known_fields: []const []const u8, file_thing: anytype) !void {
    if (@TypeOf(file_thing) == *SdkFile or @TypeOf(file_thing) == *const SdkFile)
        return common.jsonObjEnforceKnownFieldsOnly(map, known_fields, file_thing.json_basename);
    if (@TypeOf(file_thing) == []const u8)
        return common.jsonObjEnforceKnownFieldsOnly(map, known_fields, file_thing);
    @compileError("unhandled file_thing type: " ++ @typeName(@TypeOf(file_thing)));
}

fn jsonObjGetRequired(map: json.ObjectMap, field: []const u8, file_thing: anytype) !json.Value {
    if (@TypeOf(file_thing) == *SdkFile or @TypeOf(file_thing) == *const SdkFile)
        return jsonObjGetRequiredImpl(map, field, file_thing.json_basename);
    if (@TypeOf(file_thing) == []const u8)
        return jsonObjGetRequiredImpl(map, field, file_thing);
    @compileError("unhandled file_thing type: " ++ @typeName(@TypeOf(file_thing)));
}
fn jsonObjGetRequiredImpl(map: json.ObjectMap, field: []const u8, file_for_error: []const u8) !json.Value {
    return map.get(field) orelse {
        // TODO: print file location?
        std.debug.print("{s}: json object is missing '{s}' field: {}\n", .{ file_for_error, field, fmtJson(map) });
        jsonPanic();
    };
}

// TODO: this should probably be in std.json
pub fn jsonEql(a: json.Value, b: json.Value) bool {
    switch (a) {
        .integer => |a_val| switch (b) {
            .integer => |b_val| return a_val == b_val,
            else => return false,
        },
        .number_string => |a_val| switch (b) {
            .number_string => |b_val| return std.mem.eql(u8, a_val, b_val),
            else => return false,
        },
        else => @panic("not impl"),
    }
}

// TODO: would be nice to have isBuiltinId in the std lib
const builtin_ids = std.ComptimeStringMap(Nothing, .{
    .{ "type", .{} },
});
pub fn isBuiltinId(s: []const u8) bool {
    if (builtin_ids.get(s)) |_| return true;
    if (s.len >= 2 and (s[0] == 'i' or s[0] == 'u')) {
        if (blk: {
            for (s[1..]) |e| {
                if (e > '9' or e < '0') break :blk false;
            }
            break :blk true;
        }) return true;
    }
    return false;
}

// NOTE: this data could be generated automatically by doing a first pass
fn getParamNamesToAvoidMapGetFn(json_name: []const u8) AvoidLookupFn {
    if (std.mem.eql(u8, json_name, "System.Mmc")) return std.ComptimeStringMap(Nothing, .{
        .{ "Node", .{} },
        .{ "Nodes", .{} },
        .{ "Frame", .{} },
        .{ "Column", .{} },
        .{ "Columns", .{} },
        .{ "ScopeNamespace", .{} },
        .{ "SnapIn", .{} },
        .{ "Extension", .{} },
        .{ "View", .{} },
        .{ "Document", .{} },
        .{ "MenuItem", .{} },
        .{ "Views", .{} },
        .{ "SnapIns", .{} },
        .{ "Property", .{} },
        .{ "Properties", .{} },
        .{ "Extensions", .{} },
        .{ "ContextMenu", .{} },
        .{ "Guid", .{} },
    }).get;
    if (std.mem.eql(u8, json_name, "UI.TabletPC")) return std.ComptimeStringMap(Nothing, .{
        .{ "EventMask", .{} },
        .{ "InkDisplayMode", .{} },
        .{ "Guid", .{} },
    }).get;
    if (std.mem.eql(u8, json_name, "UI.Shell")) return std.ComptimeStringMap(Nothing, .{
        .{ "Folder", .{} },
    }).get;
    if (std.mem.eql(u8, json_name, "Media.DirectShow")) return std.ComptimeStringMap(Nothing, .{
        .{ "Quality", .{} },
        .{ "ScanModulationTypes", .{} },
        .{ "AnalogVideoStandard", .{} },
        .{ "Guid", .{} },
    }).get;
    if (std.mem.eql(u8, json_name, "Media.Speech")) return std.ComptimeStringMap(Nothing, .{
        .{ "Guid", .{} },
    }).get;
    if (std.mem.eql(u8, json_name, "Media.MediaFoundation")) return std.ComptimeStringMap(Nothing, .{
        .{ "Guid", .{} },
    }).get;
    if (std.mem.eql(u8, json_name, "System.Diagnostics.Debug")) return std.ComptimeStringMap(Nothing, .{
        .{ "Guid", .{} },
        .{ "Symbol", .{} },
    }).get;
    return EmptyComptimeStringMap(Nothing).get;
}

pub const FmtParamId = struct {
    s: []const u8,
    avoid_lookup: AvoidLookupFn,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        _ = fmt;
        _ = options;
        if (self.avoid_lookup(self.s)) |_| {
            try writer.print("_param_{s}", .{self.s});
        } else if (isBuiltinId(self.s)) {
            try writer.print("{s}_", .{self.s});
        } else {
            try writer.print("{}", .{std.zig.fmtId(self.s)});
        }
    }
};
pub fn fmtParamId(s: []const u8, avoid_lookup: AvoidLookupFn) FmtParamId {
    return FmtParamId{ .s = s, .avoid_lookup = avoid_lookup };
}

pub fn FmtLower(comptime buffer_size: comptime_int) type {
    return struct {
        s: []const u8,
        pub fn format(
            self: @This(),
            comptime fmt: []const u8,
            options: std.fmt.FormatOptions,
            writer: anytype,
        ) !void {
            _ = fmt;
            _ = options;
            var buffered = std.io.BufferedWriter(buffer_size, @TypeOf(writer)){ .unbuffered_writer = writer };
            for (self.s) |c| {
                const lower = [_]u8{std.ascii.toLower(c)};
                try buffered.writer().writeAll(&lower);
            }
            try buffered.flush();
        }
    };
}
pub fn fmtLower(s: []const u8, comptime buffer_size: comptime_int) FmtLower(buffer_size) {
    return .{ .s = s };
}

fn cleanDir(dir: std.fs.Dir, sub_path: []const u8) !void {
    try dir.deleteTree(sub_path);
    const MAX_ATTEMPTS = 30;
    var attempt: u32 = 1;
    while (true) : (attempt += 1) {
        if (attempt > MAX_ATTEMPTS)
            fatal("failed to delete '{s}' after {} attempts", .{ sub_path, MAX_ATTEMPTS });

        // ERROR: windows.OpenFile is not handling error.Unexpected NTSTATUS=0xc0000056
        dir.makeDir(sub_path) catch |e| switch (e) {
            else => {
                std.debug.print("[DEBUG] makedir failed with {}\n", .{e});
                //std.os.exit(0xff);
                continue;
            },
        };
        break;
    }
}

fn withoutCrLen(s: []const u8) usize {
    @setEvalBranchQuota(3000);
    return s.len - std.mem.count(u8, s, "\r");
}

fn removeCr(comptime s: []const u8) *const [withoutCrLen(s):0]u8 {
    comptime {
        const len = withoutCrLen(s);
        var without_cr: [len:0]u8 = undefined;
        var i: usize = 0;
        for (s) |e| {
            if (e != '\r') {
                without_cr[i] = e;
                i += 1;
            }
        }
        std.debug.assert(i == len);
        return &without_cr;
    }
}
