const std = @import("std");
const ArrayList = std.ArrayList;
const StringHashMap = std.StringHashMap;
const json = std.json;
const StringPool = @import("stringpool.zig").StringPool;
const path_sep = std.fs.path.sep_str;

const cameltosnake = @import("cameltosnake.zig");

var arena = std.heap.ArenaAllocator.init(std.heap.page_allocator);
const allocator = &arena.allocator;

const autogen_header = "//! NOTE: this file is autogenerated, DO NOT MODIFY\n";

var global_void_type_from_pool_ptr : [*]const u8 = undefined;
var global_symbol_pool = StringPool.init(allocator);
var global_type_map = StringPool.HashMap(TypeEntry).init(allocator);

const NativeType = enum {
    Boolean,
    SByte,
    Byte,
    Int16,
    UInt16,
    Int32,
    UInt32,
    Int64,
    UInt64,
    Char,
    Single,
    Double,
    String,
    IntPtr,
    UIntPtr,
    Guid,
};
const global_native_type_map = std.ComptimeStringMap(NativeType, .{
    .{ "Boolean", NativeType.Boolean },
    .{ "SByte", NativeType.SByte },
    .{ "Byte", NativeType.Byte },
    .{ "Int16", NativeType.Int16 },
    .{ "UInt16", NativeType.UInt16 },
    .{ "Int32", NativeType.Int32 },
    .{ "UInt32", NativeType.UInt32 },
    .{ "Int64", NativeType.Int64 },
    .{ "UInt64", NativeType.UInt64 },
    .{ "Char", NativeType.Char },
    .{ "Single", NativeType.Single },
    .{ "Double", NativeType.Double },
    .{ "String", NativeType.String },
    .{ "IntPtr", NativeType.IntPtr },
    .{ "UIntPtr", NativeType.UIntPtr },
    .{ "Guid", NativeType.Guid },
});
fn nativeTypeToZigType(t: NativeType) []const u8 {
    return switch (t) {
        .Boolean => return "bool",
        .SByte => return "i8",
        .Byte => return "u8",
        .Int16 => return "i16",
        .UInt16 => return "u16",
        .Int32 => return "i32",
        .UInt32 => return "u32",
        .Int64 => return "i64",
        .UInt64 => return "u64",
        .Char => return "u16",
        .Single => return "f32",
        .Double => return "f64",
        .String => return "[]const u8",
        .IntPtr => return "?*c_void",
        .UIntPtr => return "?*c_void",
        .Guid => @panic("cannot call nativeTypeToZigType for NativeType.Guid"),
    };
}

const TargetKind = enum {
    Default,
    FunctionPointer,
    Com,
};
const target_kind_map = std.ComptimeStringMap(TargetKind, .{
    .{ "Default", TargetKind.Default },
    .{ "FunctionPointer", TargetKind.FunctionPointer },
    .{ "Com", TargetKind.Com },
});

const Nothing = struct {};

const SdkFile = struct {
    json_basename: []const u8,
    name_original_case: []const u8,
    name_snake_case: []const u8,
    zig_filename: []const u8,
    const_exports: ArrayList(StringPool.Val),
    uses_guid: bool,
    top_level_api_imports: StringPool.HashMap(StringPool.Val),
    type_exports: StringPool.HashMap(Nothing),
    func_exports: StringPool.HashMap(Nothing),
    // this field is only needed to workaround: https://github.com/ziglang/zig/issues/4476
    tmp_func_ptr_workaround_list: ArrayList(StringPool.Val),

    pub fn create(json_basename: []const u8) !*SdkFile {
        const sdk_file = try allocator.create(SdkFile);
        errdefer allocator.destroy(sdk_file);
        const name_original_case = json_basename[0..json_basename.len - ".json".len];
        const name_snake_case = try cameltosnake.camelToSnakeAlloc(allocator, name_original_case);
        errdefer allocator.free(name_snake_case);
        const zig_filename = try std.mem.concat(allocator, u8, &[_][]const u8 {name_snake_case, ".zig"});
        errdefer allocator.free(zig_filename);

        sdk_file.* = .{
            .json_basename = json_basename,
            .name_original_case = name_original_case,
            .name_snake_case = name_snake_case,
            .zig_filename = zig_filename,
            .const_exports = ArrayList(StringPool.Val).init(allocator),
            .uses_guid = false,
            .top_level_api_imports = StringPool.HashMap(StringPool.Val).init(allocator),
            .type_exports = StringPool.HashMap(Nothing).init(allocator),
            .func_exports = StringPool.HashMap(Nothing).init(allocator),
            .tmp_func_ptr_workaround_list = ArrayList(StringPool.Val).init(allocator),
        };
        return sdk_file;
    }

    pub fn addApiImport(self: *SdkFile, name: []const u8, api: []const u8, parents: json.Array) !void {
        if (!std.mem.eql(u8, self.name_original_case, api)) {
            const top_level_symbol = try global_symbol_pool.add(
                if (parents.items.len == 0) name else parents.items[0].String);
            const pool_api = try global_symbol_pool.add(api);
            if (self.top_level_api_imports.get(top_level_symbol)) |other_api| {
                jsonEnforceMsg(pool_api.eql(other_api), "symbol conflict '{s}', api mismatch '{s}' and '{s}'", .{name, pool_api, other_api});
                //jsonEnforceMsg(other.parents.len == 0, "symbol conflict '{s}', parents mismatch", .{name});
            } else {
                try self.top_level_api_imports.put(top_level_symbol, pool_api);
            }
        }
    }
};

const Times = struct {
    parse_time_millis : i64 = 0,
    read_time_millis : i64 = 0,
    generate_time_millis : i64 = 0,
};
var global_times = Times {};

pub fn main() !u8 {
    return main2() catch |e| switch (e) {
        error.AlreadyReported => return 0xff,
        else => return e,
    };
}
fn main2() !u8 {
    const main_start_millis = std.time.milliTimestamp();
    var print_time_summary = false;
    defer {
        if (print_time_summary) {
            var total_millis = std.time.milliTimestamp() - main_start_millis;
            if (total_millis == 0) total_millis = 1; // prevent divide by 0
            std.debug.warn("Parse Time: {} millis ({}%)\n", .{global_times.parse_time_millis, @divTrunc(100 * global_times.parse_time_millis, total_millis)});
            std.debug.warn("Read Time : {} millis ({}%)\n", .{global_times.read_time_millis , @divTrunc(100 * global_times.read_time_millis, total_millis)});
            std.debug.warn("Gen Time  : {} millis ({}%)\n", .{global_times.generate_time_millis , @divTrunc(100 * global_times.generate_time_millis, total_millis)});
            std.debug.warn("Total Time: {} millis\n", .{total_millis});
        }
    }

    const win32json_dir_name = "deps" ++ path_sep ++ "win32json";
    const win32json_branch = "10.0.19041.5-preview.22";
    var win32json_dir = std.fs.cwd().openDir(win32json_dir_name, .{}) catch |e| switch (e) {
        error.FileNotFound => {
            std.debug.warn("Error: repository '{s}' does not exist, clone it with:\n", .{win32json_dir_name});
            std.debug.warn("    git clone https://github.com/marlersoft/win32json " ++
                "{s}" ++ path_sep ++ win32json_dir_name ++
                " -b " ++ win32json_branch ++ "\n", .{
                try getcwd(allocator)
            });
            return error.AlreadyReported;
        },
        else => return e,
    };
    defer win32json_dir.close();

    var api_dir = try win32json_dir.openDir("api", .{.iterate = true}) ;
    defer api_dir.close();

    const cwd = std.fs.cwd();

    const zigwin32_dir_name = "zigwin32";
    cwd.access(zigwin32_dir_name, .{}) catch |e| switch (e) {
        error.FileNotFound => {
            std.debug.warn("Error: repository '{s}' does not exist, clone it with:\n", .{zigwin32_dir_name});
            std.debug.warn("    git clone https://github.com/marlersoft/zigwin32 {s}" ++ path_sep ++ zigwin32_dir_name ++ "\n", .{
                try getcwd(allocator)
            });
            return error.AlreadyReported;
        },
        else => return e,
    };

    const out_dir_string = zigwin32_dir_name ++ path_sep ++ "src";
    try cleanDir(cwd, out_dir_string);
    var out_dir = try cwd.openDir(out_dir_string, .{});
    defer out_dir.close();

    try out_dir.makeDir("win32");
    var out_win32_dir = try out_dir.openDir("win32", .{});
    defer out_win32_dir.close();

    // copy zig.zig and missing.zig modules
    {
        var src_dir = try cwd.openDir("src", .{});
        defer src_dir.close();
        try src_dir.copyFile("zig.zig", out_win32_dir, "zig.zig", .{});
        try src_dir.copyFile("missing.zig", out_win32_dir, "missing.zig", .{});
    }

    var sdk_files = ArrayList(*SdkFile).init(allocator);
    defer sdk_files.deinit();
    {
        try out_win32_dir.makeDir("api");
        var out_api_dir = try out_win32_dir.openDir("api", .{});
        defer out_api_dir.close();

        std.debug.warn("-----------------------------------------------------------------------\n", .{});
        std.debug.warn("loading api json files...\n", .{});
        var dir_it = api_dir.iterate();
        while (try dir_it.next()) |entry| {
            if (!std.mem.endsWith(u8, entry.name, ".json")) {
                std.debug.warn("Error: expected all files to end in '.json' but got '{s}'\n", .{entry.name});
                return error.AlreadyReported;
            }
            if (std.mem.eql(u8, entry.name, "Js.json2")) {
                std.debug.warn("NOTE: skipping '{s}' because it has an integer that is too big: https://github.com/ziglang/zig/issues/7901\n", .{entry.name});
                continue;
            }
            std.debug.warn("loading '{s}'\n", .{entry.name});
            //
            // TODO: would things run faster if I just memory mapped the file?
            //
            var file = try api_dir.openFile(entry.name, .{});
            defer file.close();
            try readAndGenerateApiFile(out_api_dir, &sdk_files, entry.name, file);
        }

        {
            var api_file = try out_win32_dir.createFile("api.zig", .{});
            defer api_file.close();
            const writer = api_file.writer();
            try writer.writeAll(autogen_header);
            for (sdk_files.items) |sdk_file| {
                try writer.print("pub const {s} = @import(\"api/{0s}.zig\");\n", .{sdk_file.name_snake_case});
            }
            try writer.writeAll(
                \\test {
                \\
            );
            try writer.print("    const api_count = {};\n", .{sdk_files.items.len});
            try writer.writeAll(
                \\    @setEvalBranchQuota(api_count);
                \\    @import("std").testing.refAllDecls(@This());
                \\}
                \\
            );
        }

        {
            var everything_file = try out_win32_dir.createFile("everything.zig", .{});
            defer everything_file.close();
            const writer = everything_file.writer();
            try writer.writeAll(autogen_header ++
                \\//! This module contains aliases to ALL symbols inside the Win32 SDK.  It allows
                \\//! an application to access any and all symbols through a single import.
                \\
                \\pub const L = @import("zig.zig").L;
                \\
                \\pub usingnamespace @import("missing.zig");
                \\
            );

            // TODO: workaround issue where constants/functions are defined more than once, not sure what the right solution
            //       is for all these, maybe some modules are not compatible with each other.  This could just be the permanent
            //       solution as well, if there are conflicts, we could just say the user has to import the specific module they want.
            // TODO: I think the right way to reslve conflicts in everything.zig is to have a priority order for the apis.
            //       If I just sort the API's in the right order, more common apis go first, then my current logic will work.
            var shared_export_map = StringPool.HashMap(*SdkFile).init(allocator);
            defer shared_export_map.deinit();

            // populate the shared_export_map, start with types first
            // because types can be referenced within the modules (unlike consts/functions)
            for (sdk_files.items) |sdk_file| {
                var type_export_it = sdk_file.type_exports.iterator();
                while (type_export_it.next()) |kv| {
                    const type_name = kv.key;
                    if (shared_export_map.get(type_name)) |_| {
                        //try shared_export_map.put(type_name, .{ .first_sdk_file_ptr = entry.first_sdk_file_ptr, .duplicates = entry.duplicates + 1 });
                    } else {
                        //try shared_export_map.put(type_name, .{ .first_sdk_file_ptr = sdk_file, .duplicates = 0 });
                        try shared_export_map.put(type_name, sdk_file);
                    }
                }
            }


            // we wrap all the api symbols in a sub-struct because some of the api
            // names conflict some of the symbols.  This prevents those conflicts.
            try writer.print("const api = struct {{\n", .{});
            for (sdk_files.items) |sdk_file| {
                try writer.print("    const {s} = @import(\"api/{0s}.zig\");\n", .{sdk_file.name_snake_case});
            }
            try writer.print("}};\n", .{});
            for (sdk_files.items) |sdk_file| {
                try writer.print("// {s} exports {} constants:\n", .{sdk_file.name_snake_case, sdk_file.const_exports.items.len});
                for (sdk_file.const_exports.items) |constant| {
                    if (shared_export_map.get(constant)) |other_sdk_file| {
                        try writer.print("// WARNING: redifinition of constant symbol '{s}' in module '{s}' (going with module '{s}')\n", .{
                            constant, sdk_file.name_snake_case, other_sdk_file.name_snake_case});
                    } else {
                        try writer.print("pub const {s} = api.{s}.{0s};\n", .{constant, sdk_file.name_snake_case});
                        try shared_export_map.put(constant, sdk_file);
                    }
                }
                try writer.print("// {s} exports {} types:\n", .{sdk_file.name_snake_case, sdk_file.type_exports.count()});
                var export_it = sdk_file.type_exports.iterator();
                while (export_it.next()) |kv| {
                    const type_name = kv.key;
                    const first_type_sdk = shared_export_map.get(type_name) orelse unreachable;
                    if (first_type_sdk != sdk_file) {
                        try writer.print("// WARNING: redefinition of type symbol '{s}' from '{s}', going with '{s}'\n", .{
                            type_name, sdk_file.name_snake_case, first_type_sdk.name_snake_case});
                    } else {
                        try writer.print("pub const {s} = api.{s}.{0s};\n", .{type_name, sdk_file.name_snake_case});
                    }
                }
                try writer.print("// {s} exports {} functions:\n", .{sdk_file.name_snake_case, sdk_file.func_exports.count()});
                var func_it = sdk_file.func_exports.iterator();
                while (func_it.next()) |kv| {
                    const func = kv.key;
                    if (shared_export_map.get(func)) |other_sdk_file| {
                        try writer.print("// WARNING: redifinition of function '{s}' in module '{s}' (going with module '{s}')\n", .{
                            func, sdk_file.name_snake_case, other_sdk_file.name_snake_case});
                    } else {
                        try writer.print("pub const {s} = api.{s}.{0s};\n", .{func, sdk_file.name_snake_case});
                        try shared_export_map.put(func, sdk_file);
                    }
                }
            }
        }
    }

    {
        var win32_file = try out_dir.createFile("win32.zig", .{});
        defer win32_file.close();
        const writer = win32_file.writer();
        try writer.writeAll(autogen_header ++
            \\pub const api = @import("win32/api.zig");
            \\pub const zig = @import("win32/zig.zig");
            \\pub const missing = @import("win32/missing.zig");
            \\pub const everything = @import("win32/everything.zig");
            \\
            \\const std = @import("std");
            \\test {
            \\    std.testing.refAllDecls(@This());
            \\}
            \\
        );
    }
    print_time_summary = true;
    return 0;
}

fn readAndGenerateApiFile(out_dir: std.fs.Dir, sdk_files: *ArrayList(*SdkFile), json_basename: []const u8, file: std.fs.File) !void {

    const read_start_millis = std.time.milliTimestamp();
    const content = try file.readToEndAlloc(allocator, std.math.maxInt(usize));
    global_times.read_time_millis += std.time.milliTimestamp() - read_start_millis;
    defer allocator.free(content);
    std.debug.warn("  read {} bytes\n", .{content.len});

    // Parsing the JSON is VERY VERY SLOW!!!!!!
    var parser = json.Parser.init(allocator, false); // false is copy_strings
    defer parser.deinit();
    const parse_start_millis = std.time.milliTimestamp();

    const start = if (std.mem.startsWith(u8, content, "\xEF\xBB\xBF")) 3 else @as(usize, 0);
    const json_content = content[start..];
    var json_tree = try parser.parse(json_content);
    defer json_tree.deinit();
    global_times.parse_time_millis += std.time.milliTimestamp() - parse_start_millis;

    var sdk_file = try SdkFile.create(try std.mem.dupe(allocator, u8, json_basename));
    try sdk_files.append(sdk_file);
    const generate_start_millis = std.time.milliTimestamp();
    try generateFile(out_dir, sdk_file, json_tree);
    global_times.generate_time_millis += std.time.milliTimestamp() - generate_start_millis;
}

const ExtraTypeCounts = struct {
    enum_values: u32,
    com_iface_ids: u32,
    com_class_ids: u32,
};

fn generateFile(out_dir: std.fs.Dir, sdk_file: *SdkFile, tree: json.ValueTree) !void {
    var out_file = try out_dir.createFile(sdk_file.zig_filename, .{});
    defer out_file.close();
    const out_writer = out_file.writer();

    try out_writer.writeAll(autogen_header);
    // We can't import the everything module because it will re-introduce the same symbols we are exporting
    //try out_writer.print("usingnamespace @import(\"everything.zig\");\n", .{});
    const root_obj = tree.root.Object;
    const constants_array = (try jsonObjGetRequired(root_obj, "Constants", sdk_file)).Array;
    const types_array = (try jsonObjGetRequired(root_obj, "Types", sdk_file)).Array;
    const functions_array = (try jsonObjGetRequired(root_obj, "Functions", sdk_file)).Array;
    const unicode_aliases = (try jsonObjGetRequired(root_obj, "UnicodeAliases", sdk_file)).Array;
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    try out_writer.print("// Section: Constants ({})\n", .{constants_array.items.len});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    for (constants_array.items) |*constant_node_ptr| {
        try generateConstant(sdk_file, out_writer, constant_node_ptr.Object);
    }
    std.debug.assert(constants_array.items.len == sdk_file.const_exports.items.len);
    try out_writer.print("\n", .{});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    try out_writer.print("// Section: Types ({})\n", .{types_array.items.len});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    var extra_type_counts = ExtraTypeCounts {
        .enum_values = 0,
        .com_iface_ids = 0,
        .com_class_ids = 0,
    };
    for (types_array.items) |*type_node_ptr| {
        try generateType(sdk_file, out_writer, type_node_ptr.Object, &extra_type_counts);
        try out_writer.print("\n", .{});
    }
    std.debug.assert(sdk_file.const_exports.items.len ==
        constants_array.items.len +
        extra_type_counts.enum_values +
        extra_type_counts.com_iface_ids +
        extra_type_counts.com_class_ids);
    const expected_type_export_count = types_array.items.len - extra_type_counts.com_class_ids;
    std.debug.assert(expected_type_export_count == sdk_file.type_exports.count());
    try out_writer.print("\n", .{});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    try out_writer.print("// Section: Functions ({})\n", .{functions_array.items.len});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    for (functions_array.items) |*function_node_ptr| {
        try generateFunction(sdk_file, out_writer, function_node_ptr.Object, .fixed, null, null);
        try out_writer.print("\n", .{});
    }
    std.debug.assert(functions_array.items.len == sdk_file.func_exports.count());
    try out_writer.print("\n", .{});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    try out_writer.print("// Section: Unicode Aliases ({})\n", .{unicode_aliases.items.len});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    try generateUnicodeAliases(sdk_file, out_writer, unicode_aliases.items);
    const import_total = @boolToInt(sdk_file.uses_guid) + sdk_file.top_level_api_imports.count();
    try out_writer.print("\n", .{});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    try out_writer.print("// Section: Imports ({})\n", .{import_total});
    try out_writer.print("//--------------------------------------------------------------------------------\n", .{});
    if (sdk_file.uses_guid) {
        try out_writer.writeAll("const Guid = @import(\"../zig.zig\").Guid;\n");
    }
    {
        var it = sdk_file.top_level_api_imports.iterator();
        while (it.next()) |import| {
            const name = import.key;
            const api_upper = import.value;

            // TODO: should I cache this upper to lower mapping instead of allocating/freeing each time?
            const api_lower = try cameltosnake.camelToSnakeAlloc(allocator, api_upper.slice);
            defer allocator.free(api_lower);

            try out_writer.print("const {s} = @import(\"{s}.zig\").{0s};\n", .{name, api_lower});
        }
    }

    try out_writer.writeAll(
        \\
        \\test {
        \\
    );
    if (sdk_file.tmp_func_ptr_workaround_list.items.len > 0) {
        try out_writer.writeAll("    // The following '_ = <FuncPtrType>' lines are a workaround for https://github.com/ziglang/zig/issues/4476\n");
        for (sdk_file.tmp_func_ptr_workaround_list.items) |func_ptr_type| {
            try out_writer.print("    _ = {s};\n", .{func_ptr_type});
        }
        try out_writer.writeAll("\n");
    }
    try out_writer.print(
        \\    const constant_export_count = {};
        \\    const type_export_count = {};
        \\    const enum_value_export_count = {};
        \\    const com_iface_id_export_count = {};
        \\    const com_class_id_export_count = {};
        \\    const func_export_count = {};
        \\    const unicode_alias_count = {};
        \\    const import_count = {};
        \\    @setEvalBranchQuota(
        \\        constant_export_count +
        \\        type_export_count +
        \\        enum_value_export_count +
        \\        com_iface_id_export_count * 2 + // * 2 for value and ptr
        \\        com_class_id_export_count * 2 + // * 2 for value and ptr
        \\        func_export_count +
        \\        unicode_alias_count +
        \\        import_count +
        \\        2 // TODO: why do I need these extra 2?
        \\    );
        \\    @import("std").testing.refAllDecls(@This());
        \\}}
        \\
    , .{constants_array.items.len,
        sdk_file.type_exports.count(),
        extra_type_counts.enum_values,
        extra_type_counts.com_iface_ids,
        extra_type_counts.com_class_ids,
        sdk_file.func_exports.count(),
        unicode_aliases.items.len,
        import_total,
    });
}

fn typeIsVoid(type_obj: json.ObjectMap, sdk_file: *SdkFile) !bool {
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).String;
    if (std.mem.eql(u8, kind, "Native")) {
        const Name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).String;
        return std.mem.eql(u8, name, "void");
    }
    return false;
}

// convenient function that combines both adding type refs and creating a formatter
// for the type.   These 2 operations are orthogonal, however, combining them helps ensure
// that generating a type reference is not done without also adding that reference to the api
// being generated.
fn addTypeRefs(sdk_file: *SdkFile, type_ref: json.ObjectMap, options: TypeRefFormatter.Options) anyerror!TypeRefFormatter {
    try addTypeRefsNoFormatter(sdk_file, type_ref);
    return fmtTypeRef(type_ref, options, .top_level, sdk_file);
}

fn addTypeRefsNoFormatter(sdk_file: *SdkFile, type_ref: json.ObjectMap) anyerror!void {
    const kind = (try jsonObjGetRequired(type_ref, "Kind", sdk_file)).String;
    if (std.mem.eql(u8, kind, "Native")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Name"}, sdk_file);
        const name = (try jsonObjGetRequired(type_ref, "Name", sdk_file)).String;
        if (std.mem.eql(u8, name, "Void")) {
            // void is special
        } else if (std.mem.eql(u8, name, "Guid")) {
            sdk_file.uses_guid = true;
        } else if (global_native_type_map.get(name) == null) {
            std.debug.panic("unknown Native type '{s}'", .{name});
        }
    } else if (std.mem.eql(u8, kind, "ApiRef")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Name", "TargetKind", "Api", "Parents"}, sdk_file);
        const tmp_name = (try jsonObjGetRequired(type_ref, "Name", sdk_file)).String;
        const api = (try jsonObjGetRequired(type_ref, "Api", sdk_file)).String;
        const parents = (try jsonObjGetRequired(type_ref, "Parents", sdk_file)).Array;
        try sdk_file.addApiImport(tmp_name, api, parents);
    } else if (std.mem.eql(u8, kind, "PointerTo")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Child"}, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).Object);
    } else if (std.mem.eql(u8, kind, "Array")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Shape", "Child"}, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).Object);
    } else if (std.mem.eql(u8, kind, "LPArray")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "NullNullTerm", "SizeParamIndex", "BytesParamIndex", "SizeConst", "Child"}, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).Object);
    } else if (std.mem.eql(u8, kind, "MissingClrType")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Name", "Namespace"}, sdk_file);
    } else {
        jsonPanicMsg("kind '{s}' is not implemented", .{kind});
    }
}

const DepthContext = enum {top_level, child, array};
const TypeRefFormatter = struct {
    pub const Reason = enum { var_decl, direct_type_access };
    pub const Options = struct {
        reason: Reason,
        is_const: bool = false,
        in: bool = false,
        out: bool = false,
        optional: bool = false,
        // TODO: handle this option
        not_null_term: bool = false,
        // TODO: handle this option
        null_null_term: bool = true,
        // TODO: what to do with this?
        ret_val: bool = false,
        // TODO: don't know what to do with this yet
        com_out_ptr: bool = false,
    };

    type_ref: json.ObjectMap,
    options: Options,
    // we need to know if the type is the top-level type or a child type of something like a pointer
    // so we can generate the correct `void` type.  Top level void types become void, but pointers
    // to void types must become pointers to the `c_void` type.
    // Need to know if it is an array specifically because array pointers cannot point to opaque types
    // with an unknown size.
    depth_context: DepthContext,
    sdk_file: *SdkFile,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        fmt_options: std.fmt.FormatOptions,
        writer: anytype,
    ) std.os.WriteError!void {
        const kind = (jsonObjGetRequired(self.type_ref, "Kind", self.sdk_file) catch unreachable).String;
        if (std.mem.eql(u8, kind, "Native")) {
            jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Name"}, self.sdk_file) catch unreachable;
            const name = (jsonObjGetRequired(self.type_ref, "Name", self.sdk_file) catch unreachable).String;
            if (std.mem.eql(u8, name, "Void")) {
                try writer.writeAll(switch (self.depth_context) {
                    .top_level => "void",
                    .child => "c_void",
                    // if we are rendering the element of an array, then we have to know the size, we default to u8
                    // because most void pointers in C are measured in terms of u8 bytes
                    .array => "u8",
                });
            } else if (std.mem.eql(u8, name, "Guid")) {
                try writer.writeAll("Guid");
            } else {
                const native_type = global_native_type_map.get(name) orelse std.debug.panic("unknown Native type '{s}'", .{name});
                try writer.writeAll(nativeTypeToZigType(native_type));
            }
        } else if (std.mem.eql(u8, kind, "ApiRef")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Name", "TargetKind", "Api", "Parents"}, self.sdk_file);
            const name = (try jsonObjGetRequired(self.type_ref, "Name", self.sdk_file)).String;
            const target_kind_str = (try jsonObjGetRequired(self.type_ref, "TargetKind", self.sdk_file)).String;
            const target_kind = target_kind_map.get(target_kind_str) orelse
                jsonPanicMsg("unknown TargetKind '{s}'\n", .{target_kind_str});
            const parents = (try jsonObjGetRequired(self.type_ref, "Parents", self.sdk_file)).Array;

            if (self.options.reason == .var_decl) {
                if (self.options.optional) {
                    switch (target_kind) {
                        .Com, .FunctionPointer => {
                            try writer.writeAll("?");
                        },
                        .Default => {},
                    }
                }
                switch (target_kind) {
                    .Com => {
                        try writer.writeAll("*");
                    },
                    .FunctionPointer, .Default => {},
                }
            }

            // special handling for PSTR and PWSTR for now.  This is because those types
            // have hardcoded non-const and null-terminated, so we can't reference them if our usage
            // doesn't match.
            // If there are more cases that behave like this, I will likely need to implement a 2-pass
            // system where the first pass I gather all the type definitions so that on the second pass
            // I'll know whether each type is a pointer like this and can fix things like this.
            const special : enum { pstr, pwstr, other } = blk: {
                if (std.mem.eql(u8, name, "PSTR")) break :blk .pstr;
                if (std.mem.eql(u8, name, "PWSTR")) break :blk .pwstr;
                break :blk .other;
            };
            if (special == .pstr or special == .pwstr) {
                if (self.options.optional) {
                    try writer.writeAll("?");
                }

                // if we deviated from the options we set for PSTR/PWSTR, then generate the native zig
                // type directly instead of referencing the PSTR/PWSTR type
                if (self.options.is_const or self.options.not_null_term) {
                    const base = @as([]const u8, if (special == .pstr) "u8" else "u16");
                    // can't put these expressions in the print argument tuple because of https://github.com/ziglang/zig/issues/8036
                    const base_type = if (special == .pstr) "u8" else "u16";
                    const sentinel_suffix = if (self.options.not_null_term) "" else ":0";
                    const const_str = if (self.options.is_const) "const " else "";
                    try writer.print("[*{s}]{s}{s}", .{sentinel_suffix, const_str, base_type});
                    return;
                }
            }

            for (parents.items) |*parent_ptr| {
                try writer.writeAll(parent_ptr.String);
                try writer.writeAll(".");
            }
            try writer.writeAll(name);
        } else if (std.mem.eql(u8, kind, "PointerTo")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Child"}, self.sdk_file);
            const child = (try jsonObjGetRequired(self.type_ref, "Child", self.sdk_file)).Object;
            if (self.options.optional) {
                try writer.writeAll("?");
            }
            try writer.writeAll("*");
            if (self.options.is_const) {
                try writer.writeAll("const ");
            }
            try fmtTypeRef(child, self.options, .child, self.sdk_file).format(fmt, fmt_options, writer);
        } else if (std.mem.eql(u8, kind, "Array")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Shape", "Child"}, self.sdk_file);
            const child = (try jsonObjGetRequired(self.type_ref, "Child", self.sdk_file)).Object;
            const shape_size = init: { switch (try jsonObjGetRequired(self.type_ref, "Shape", self.sdk_file)) {
                // TODO: should we use size 1 here?
                .Null => break :init 1,
                .Object => |shape_obj| {
                    try jsonObjEnforceKnownFieldsOnly(shape_obj, &[_][]const u8 {"Size"}, self.sdk_file);
                    break :init (try jsonObjGetRequired(shape_obj, "Size", self.sdk_file)).Integer;
                },
                else => jsonPanic(),
            }};
            try writer.print("[{}]", .{shape_size});
            try fmtTypeRef(child, self.options, .child, self.sdk_file).format(fmt, fmt_options, writer);
        } else if (std.mem.eql(u8, kind, "LPArray")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "NullNullTerm", "SizeParamIndex", "BytesParamIndex", "SizeConst", "Child"}, self.sdk_file);
            const null_null_term = (try jsonObjGetRequired(self.type_ref, "NullNullTerm", self.sdk_file)).Bool;
            const size_param_index = (try jsonObjGetRequired(self.type_ref, "SizeParamIndex", self.sdk_file)).Integer;
            const bytes_param_index = (try jsonObjGetRequired(self.type_ref, "BytesParamIndex", self.sdk_file)).Integer;
            const size_const = (try jsonObjGetRequired(self.type_ref, "SizeConst", self.sdk_file)).Integer;
            const type_ref_kind = (jsonObjGetRequired(self.type_ref, "Kind", self.sdk_file) catch unreachable).String;
            // TODO: can Zig use size_param_index?
            const child = (try jsonObjGetRequired(self.type_ref, "Child", self.sdk_file)).Object;

            if (self.options.optional) {
                try writer.writeAll("?");
            }
            if (null_null_term) {
                try writer.print("*extern struct{{comment:[*]const u8=\"TODO: LPArray with null_null_term\"}}", .{});
            } else {
                var sentinel_suffix: []const u8 = "";
                if ((!self.options.not_null_term) and isByteOrCharOrUInt16Type(child, self.sdk_file)) {
                    sentinel_suffix = ":0";
                }

                if (size_const == -1 or size_const == 0) {
                    try writer.print("[*{s}]", .{sentinel_suffix});
                } else {
                    try writer.print("*[{}]", .{size_const});
                }
                if (size_const <= 0 and self.options.is_const)
                    try writer.writeAll("const ");
                try fmtTypeRef(child, self.options, .array, self.sdk_file).format(fmt, fmt_options, writer);
            }
        } else if (std.mem.eql(u8, kind, "MissingClrType")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Name", "Namespace"}, self.sdk_file);
            const name = (try jsonObjGetRequired(self.type_ref, "Name", self.sdk_file)).String;
            const namespace = (try jsonObjGetRequired(self.type_ref, "Namespace", self.sdk_file)).String;
            try writer.print("*struct{{comment: []const u8 = \"MissingClrType {s}.{s}\"}}", .{name, namespace});
        } else {
            jsonPanicMsg("fmtTypeRef kind '{s}' is not implemented", .{kind});
        }
    }
};
pub fn fmtTypeRef(type_ref: json.ObjectMap, options: TypeRefFormatter.Options, depth_context: DepthContext, sdk_file: *SdkFile) TypeRefFormatter {
    return .{ .type_ref = type_ref, .options = options, .depth_context = depth_context, .sdk_file = sdk_file };
}

fn isByteOrCharOrUInt16Type(type_obj: json.ObjectMap, sdk_file: *SdkFile) bool {
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).String;
    if (!std.mem.eql(u8, kind, "Native"))
        return false;

    const name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).String;
    if (std.mem.eql(u8, name, "Void"))
        return false;
    const native_type = global_native_type_map.get(name) orelse jsonPanicMsg("unknown Native type '{s}'", .{name});
    return switch (native_type) {
        .Byte, .Char, .UInt16 => true,
        else => false,
    };
}

fn fmtConstAssign(native_type: NativeType, value: json.Value) ConstValueFormatter {
    return .{ .native_type = native_type, .value = value };
}
const ConstValueFormatter = struct {
    native_type: NativeType,
    value: json.Value,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) std.os.WriteError!void {
        if (self.native_type == .String) {
            try writer.print("= {}", .{fmtJson(self.value)});
            return;
        }
        if (self.native_type == .Guid) {
            const s = switch (self.value) {
                .String => |s| s,
                else => jsonPanicMsg("expected Guid to be a string but got: {s}", .{fmtJson(self.value)}),
            };
            try writer.print("= @import(\"../zig.zig\").Guid.initString(\"{s}\")", .{s});
            return;
        }
        const zig_type = nativeTypeToZigType(self.native_type);
        if (self.native_type == .Single or self.native_type == .Double) {
            switch (self.value) {
                .String => |float_str| {
                    if (std.mem.eql(u8, float_str, "inf")) {
                        try writer.print("= @import(\"std\").math.inf({s})", .{zig_type});
                        return;
                    } else if (std.mem.eql(u8, float_str, "-inf")) {
                        try writer.print("= -@import(\"std\").math.inf({s})", .{zig_type});
                        return;
                    } else if (std.mem.eql(u8, float_str, "nan")) {
                        try writer.print("= @import(\"std\").math.nan({s})", .{zig_type});
                        return;
                    } else {
                        std.debug.panic("unexpected float string value '{s}'", .{float_str});
                    }
                    return;
                },
                else => {},
            }
        }
        try writer.print(": {s} = {}", .{zig_type, fmtJson(self.value)});
    }
};

fn generateConstant(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, constant_obj: json.ObjectMap) !void {
    try jsonObjEnforceKnownFieldsOnly(constant_obj, &[_][]const u8 {"Name", "NativeType", "Value","Attrs"}, sdk_file);
    const name_tmp = (try jsonObjGetRequired(constant_obj, "Name", sdk_file)).String;
    const native_type_str = (try jsonObjGetRequired(constant_obj, "NativeType", sdk_file)).String;
    const value_node = try jsonObjGetRequired(constant_obj, "Value", sdk_file);

    // TODO: handle Attrs
    const attrs_node = (try jsonObjGetRequired(constant_obj, "Attrs", sdk_file)).Array;

    const name_pool = try global_symbol_pool.add(name_tmp);
    try sdk_file.const_exports.append(name_pool);

    const native_type = global_native_type_map.get(native_type_str) orelse {
        std.log.err("constant '{s}' has an unknown NativeType '{s}'\n", .{name_pool, native_type_str});
        return error.AlreadyReported;
    };

    try out_writer.print("pub const {s} {};\n", .{name_pool, fmtConstAssign(native_type, value_node)});
}

fn generateType(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, type_obj: json.ObjectMap, extra_type_counts: *ExtraTypeCounts) !void {
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).String;
    const tmp_name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).String;

    if (std.mem.eql(u8, kind, "ComClassID")) {
        try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Name", "Kind", "Guid"}, sdk_file);
        const guid = (try jsonObjGetRequired(type_obj, "Guid", sdk_file)).String;
        const clsid_pool = try global_symbol_pool.addFormatted("CLSID_{s}", .{tmp_name});
        try out_writer.print("const {s}_Value = @import(\"../zig.zig\").Guid.initString(\"{s}\");\n", .{clsid_pool, guid});
        try out_writer.print("pub const {s} = &{0s}_Value;\n", .{clsid_pool});
        try sdk_file.const_exports.append(clsid_pool);
        extra_type_counts.com_class_ids += 1;
        return;
    }

    const pool_name = try global_symbol_pool.add(tmp_name);
    std.debug.assert(sdk_file.type_exports.get(pool_name) == null);
    try sdk_file.type_exports.put(pool_name, .{});

    if (types_to_skip.get(tmp_name)) |_| {
        try out_writer.print("// TODO: not generating this type because it is causing some sort of error\n", .{});
        try out_writer.print("pub const {s} = usize;\n", .{tmp_name});
    } else if (std.mem.eql(u8, kind, "NativeTypedef")) {
        try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Name", "Kind", "Def", "FreeFunc"}, sdk_file);
        const def_type = (try jsonObjGetRequired(type_obj, "Def", sdk_file)).Object;
        const optional_free_func : ?[]const u8 = switch (try jsonObjGetRequired(type_obj, "FreeFunc", sdk_file)) {
            .Null => null,
            .String => |s| s,
            else => jsonPanic(),
        };
        if (optional_free_func) |free_func| {
            try out_writer.print("// TODO: this type has a FreeFunc '{s}', what can Zig do with this information?\n", .{free_func});
        }

        // HANDLE PSTR and PWSTR specially because win32metadata is not properly declaring them as arrays, only pointers
        // not sure if this is a real issue with the metadata or intentional
        const special : enum { pstr, pwstr, other } = blk: {
            if (std.mem.eql(u8, tmp_name, "PSTR")) break :blk .pstr;
            if (std.mem.eql(u8, tmp_name, "PWSTR")) break :blk .pwstr;
            break :blk .other;
        };
        if (special == .pstr or special == .pwstr) {
            //
            // verify the definition is what we expect, if not, we might be able to remove out workaround
            //
            const def_kind = (try jsonObjGetRequired(def_type, "Kind", sdk_file)).String;
            jsonEnforceMsg(std.mem.eql(u8, def_kind, "PointerTo"), "definition of {s} has changed! (Def.Kind != PointerTo, it is {s})", .{tmp_name, def_kind});
            try jsonObjEnforceKnownFieldsOnly(def_type, &[_][]const u8 {"Kind", "Child"}, sdk_file);
            const child_type = (try jsonObjGetRequired(def_type, "Child", sdk_file)).Object;
            const child_kind = (try jsonObjGetRequired(child_type, "Kind", sdk_file)).String;
            jsonEnforceMsg(std.mem.eql(u8, child_kind, "Native"), "definition of {s} has changed! (Def.Child.Kind != Native", .{tmp_name});
            try jsonObjEnforceKnownFieldsOnly(child_type, &[_][]const u8 {"Kind", "Name"}, sdk_file);
            const child_native_name = (try jsonObjGetRequired(child_type, "Name", sdk_file)).String;
            // TODO: is something is referencing PSTR or PWSTR and is NotNullTerm, then
            //       maybe I'll do something like @import("zig.zig").NotNullTerm(PSTR)
            const native_type = global_native_type_map.get(child_native_name) orelse jsonPanic();
            switch (native_type) {
                .Byte => {
                    jsonEnforce(special == .pstr);
                    try out_writer.writeAll("pub const PSTR = [*:0]u8;\n");
                },
                .Char => {
                    jsonEnforce(special == .pwstr);
                    try out_writer.writeAll("pub const PWSTR = [*:0]u16;\n");
                },
                else => jsonPanic(),
            }
            return;
        }

        // TODO: set is_const, in and out properly
        const zig_type_formatter = try addTypeRefs(sdk_file, def_type, .{.reason = .direct_type_access, .is_const = false, .in = false, .out = false });
        try out_writer.print("pub const {s} = {};\n", .{tmp_name, zig_type_formatter});
    } else if (std.mem.eql(u8, kind, "Enum")) {
        try generateEnum(sdk_file, out_writer, type_obj, &extra_type_counts.enum_values, pool_name);
    } else if (std.mem.eql(u8, kind, "Struct")) {
        try generateStruct(sdk_file, out_writer, type_obj, pool_name);
    } else if (std.mem.eql(u8, kind, "FunctionPointer")) {
        if (func_ptr_dependency_loop_problems.get(tmp_name)) |_| {
            try out_writer.writeAll("// TODO: this function pointer causes dependency loop problems, so it's stubbed out\n");
            try out_writer.print("pub const {s} = fn() callconv(@import(\"std\").os.windows.WINAPI) void;\n", .{tmp_name});
            return;
        }
        try generateFunction(sdk_file, out_writer, type_obj, .ptr, null, null);
        try sdk_file.tmp_func_ptr_workaround_list.append(pool_name);
    } else if (std.mem.eql(u8, kind, "Com")) {
        try generateCom(sdk_file, out_writer, type_obj, pool_name, extra_type_counts);
    } else if (std.mem.eql(u8, kind, "StructOrUnion")) {
        if (dhcp_type_conflicts.get(tmp_name)) |_| {
            try out_writer.print("// TODO: this dhcp type has been removed because it conflicts with a nested type '{s}'\n", .{tmp_name});
            return;
        }
        try out_writer.print("pub const {s} = u32; // TODO: implement StructOrUnion types?\n", .{tmp_name});
    } else {
        jsonPanicMsg("{s}: unknown type Kind '{s}'", .{sdk_file.json_basename, kind});
    }
}

const types_to_skip = std.ComptimeStringMap(Nothing, .{
    // keep this around for a convenient way to disable types
    .{ "PlaceholderForNow", .{} },
});

const com_types_to_skip = std.ComptimeStringMap(Nothing, .{
    // This type appears in direct_show.zig and imports a type named IComponent from mmc.zig, however,
    // direct_show.zig also defines a type named IComponent, so this causes a conflict.  I dont' think
    // the metadata is supposed to have conflicts like this, so instead of detecting it I'm just going
    // to skip types that violate it for now.
    .{ "IMPEG2Component", .{} },
    // These types reference IResourceManager which causes a conflict because it is
    // defined in both component_services.zig and direct_show.zig
    .{ "IResourceManager2", .{} },
});

fn generateStruct(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, type_obj: json.ObjectMap, struct_pool_name: StringPool.Val) !void {
    try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Kind", "Name", "Size", "PackingSize", "Fields", "Comment", "NestedTypes"}, sdk_file);
    const struct_size = (try jsonObjGetRequired(type_obj, "Size", sdk_file)).Integer;
    const struct_packing_size = (try jsonObjGetRequired(type_obj, "PackingSize", sdk_file)).Integer;
    const struct_fields = (try jsonObjGetRequired(type_obj, "Fields", sdk_file)).Array;
    const struct_nested_types = (try jsonObjGetRequired(type_obj, "NestedTypes", sdk_file)).Array;

    if (struct_fields.items.len == 0) {
        // TODO: handle nested types
        try out_writer.print("pub const {} = extern struct {{ comment: [*]const u8 = \"TODO: why is this struct empty?\" }};\n", .{struct_pool_name});
    } else {
        try out_writer.print("pub const {} = extern struct {{\n", .{struct_pool_name});
        for (struct_fields.items) |*field_node_ptr| {
            const field_obj = field_node_ptr.Object;
            try jsonObjEnforceKnownFieldsOnly(field_obj, &[_][]const u8 {"Name", "Type", "Attrs"}, sdk_file);
            const field_name = (try jsonObjGetRequired(field_obj, "Name", sdk_file)).String;
            const field_type = (try jsonObjGetRequired(field_obj, "Type", sdk_file)).Object;
            const field_attrs = (try jsonObjGetRequired(field_obj, "Attrs", sdk_file)).Array;
            var field_options = TypeRefFormatter.Options { .reason = .var_decl };
            for (field_attrs.items) |*attr_node_ptr| {
                const attr_str = attr_node_ptr.String;
                if (std.mem.eql(u8, attr_str, "Const")) {
                    field_options.is_const = true;
                } else if (std.mem.eql(u8, attr_str, "NotNullTerminated")) {
                    field_options.not_null_term = true;
                } else if (std.mem.eql(u8, attr_str, "NullNullTerminated")) {
                    field_options.null_null_term = true;
                } else {
                    jsonPanicMsg("unhandled custom field attribute {s}\n", .{attr_str});
                }
            }
            const field_type_formatter = try addTypeRefs(sdk_file, field_type, field_options);
            try out_writer.print("    {}: {},\n", .{std.zig.fmtId(field_name), field_type_formatter});
        }
        for (struct_nested_types.items) |*nested_type_node_ptr| {
            const nested_type_obj = nested_type_node_ptr.Object;
            const nested_type_name = (try jsonObjGetRequired(nested_type_obj, "Name", sdk_file)).String;
            try out_writer.print("    const {s} = u32; // TODO: generate this nested type!\n", .{nested_type_name});
        }
        try out_writer.print("}};\n", .{});
    }
}

// Not sure whether enums should be exhaustive or not, for now
// I'll default to all of them being exhaustive except the ones
// in this list that I know are currently not exhaustive.
const non_exhaustive_enums = std.ComptimeStringMap(Nothing, .{
    // This enum is not exhaustive because it is missing a value, see
    //     https://github.com/microsoft/win32metadata/issues/203
    .{ "CLSCTX", .{} },
});

fn shortEnumValueName(enum_type_name: []const u8, full_value_name: []const u8) []const u8 {
    const offset = init: {
        if ((full_value_name.len <= enum_type_name.len + 1) or
            (full_value_name[enum_type_name.len] != '_') or
            !std.mem.startsWith(u8, full_value_name, enum_type_name)) {
            break :init 0;
        }
        const first_c = full_value_name[enum_type_name.len+1];
        if (first_c <= '9' and first_c >= '0') {
            break :init enum_type_name.len;
        }
        break :init enum_type_name.len + 1;
    };
    return full_value_name[offset..];
}

fn generateEnum(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, type_obj: json.ObjectMap, enum_value_export_count: *u32, pool_name: StringPool.Val) !void {
    try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Name", "Kind", "Flags", "Values", "IntegerBase"}, sdk_file);
    const flags = (try jsonObjGetRequired(type_obj, "Flags", sdk_file)).Bool;
    const values = (try jsonObjGetRequired(type_obj, "Values", sdk_file)).Array;
    const integer_base = switch (try jsonObjGetRequired(type_obj, "IntegerBase", sdk_file)) {
        .Null => "i32",
        .String => |s| nativeTypeToZigType(global_native_type_map.get(s) orelse {
            std.log.err("enum '{}' has an unknown IntegerBase '{s}'\n", .{pool_name, s});
            return error.AlreadyReported;
        }),
        else => jsonPanic(),
    };
    if (flags) {
        try out_writer.writeAll("// TODO: This Enum is marked as [Flags], what do I do with this?\n");
    }
    try out_writer.print("pub const {} = extern enum({s}) {{\n", .{pool_name, integer_base});
    if (values.items.len == 0) {
        // zig doesn't allow empty enums
        try out_writer.print("    _\n", .{});
    } else for (values.items) |*value_node_ptr| {
        const value_obj = value_node_ptr.Object;
        try jsonObjEnforceKnownFieldsOnly(value_obj, &[_][]const u8 {"Name", "Value"}, sdk_file);
        const value_tmp_name = (try jsonObjGetRequired(value_obj, "Name", sdk_file)).String;
        const value_short_name = shortEnumValueName(pool_name.slice, value_tmp_name);
        const value_literal = try jsonObjGetRequired(value_obj, "Value", sdk_file);
        try out_writer.print("    {s} = {},\n", .{std.zig.fmtId(value_short_name), fmtJson(value_literal)});
    }
    if (non_exhaustive_enums.get(pool_name.slice)) |_| {
        try out_writer.print("    _,\n", .{});
    }
    try out_writer.print("}};\n", .{});

    if (enums_with_value_conflicts.get(pool_name.slice)) |_| {
        try out_writer.print("// TODO: enum '{}' has known value symbol conflicts, skipping the value aliases\n", .{pool_name});
        return;
    }

    // create aliases
    for (values.items) |*value_node_ptr| {
        const value_obj = value_node_ptr.Object;
        try jsonObjEnforceKnownFieldsOnly(value_obj, &[_][]const u8 {"Name", "Value"}, sdk_file);
        const value_tmp_name = (try jsonObjGetRequired(value_obj, "Name", sdk_file)).String;
        const value_short_name = shortEnumValueName(pool_name.slice, value_tmp_name);
        const value_literal = try jsonObjGetRequired(value_obj, "Value", sdk_file);
        const pool_value_name = try global_symbol_pool.add(value_tmp_name);
        try sdk_file.const_exports.append(pool_value_name);
        try out_writer.print("pub const {s} = {}.{s};\n", .{value_tmp_name, pool_name, value_short_name});
    }
    enum_value_export_count.* += @intCast(u32, values.items.len);
}

fn generateCom(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, type_obj: json.ObjectMap, com_pool_name: StringPool.Val, extra_type_counts: *ExtraTypeCounts) !void {
    try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Kind", "Name", "Guid", "Interface", "Methods"}, sdk_file);
    const com_optional_guid : ?[]const u8 = switch (try jsonObjGetRequired(type_obj, "Guid", sdk_file)) {
        .Null => null,
        .String => |s| s,
        else => jsonPanic(),
    };
    const com_optional_iface : ?json.ObjectMap = switch (try jsonObjGetRequired(type_obj, "Interface", sdk_file)) {
        .Null => null,
        .Object => |o| o,
        else => jsonPanic(),
    };
    const com_methods = (try jsonObjGetRequired(type_obj, "Methods", sdk_file)).Array;
    const skip = com_types_to_skip.has(com_pool_name.slice);
    if (skip) {
        try out_writer.print("// WARNING: this COM type has been skipped because it causes some sort of error\n", .{});
    }

    const iid_pool = try global_symbol_pool.addFormatted("IID_{s}", .{com_pool_name.slice});
    if (com_optional_guid) |guid| {
        try out_writer.print("const {s}_Value = @import(\"../zig.zig\").Guid.initString(\"{s}\");\n", .{iid_pool, guid});
        try out_writer.print("pub const {s} = &{0s}_Value;\n", .{iid_pool});
        try sdk_file.const_exports.append(iid_pool);
        extra_type_counts.com_iface_ids += 1;
    }

    try out_writer.print("pub const {s} = extern struct {{\n", .{com_pool_name});
    try out_writer.print("    pub const VTable = extern struct {{\n", .{});
    var iface_formatter : TypeRefFormatter = undefined;

    if (skip) {
        try out_writer.print("        _: *opaque{{}}, // just a placeholder because this COM type is skipped\n", .{});
    } else {
        if (com_optional_iface) |iface| {
            iface_formatter = try addTypeRefs(sdk_file, iface, .{ .reason = .direct_type_access });
            try out_writer.print("        base: {}.VTable,\n", .{iface_formatter});
        }

        // some COM objects have methods with the same name and only differ in parameter types
        var method_conflicts = StringHashMap(u8).init(allocator);
        defer method_conflicts.deinit();

        for (com_methods.items) |*method_node_ptr| {
            const method_name = (try jsonObjGetRequired(method_node_ptr.Object, "Name", sdk_file)).String;
            const count = method_conflicts.get(method_name) orelse 0;
            try method_conflicts.put(method_name, count + 1);
            try generateFunction(sdk_file, out_writer, method_node_ptr.Object, .com, if (count == 0) null else count, com_pool_name.slice);
        }
    }

    try out_writer.print("    }};\n", .{});
    try out_writer.print("    vtable: *const VTable,\n", .{});

    // some COM objects have methods with the same name and only differ in parameter types
    var method_conflicts = StringHashMap(u8).init(allocator);
    defer method_conflicts.deinit();

    // Generate wrapper methods for every entry in the vtable
    try out_writer.print("    pub fn MethodMixin(comptime T: type) type {{ return struct {{\n", .{});
    if (!skip) {
        if (com_optional_iface) |iface| {
            // For now we're putting this inside a sub-struct to avoid name conflicts
            try out_writer.print("        pub usingnamespace {}.MethodMixin(T);\n", .{iface_formatter});
        }
        for (com_methods.items) |*method_node_ptr| {
            const method_obj = method_node_ptr.Object;
            const method_name = (try jsonObjGetRequired(method_obj, "Name", sdk_file)).String;
            const return_type = (try jsonObjGetRequired(method_obj, "ReturnType", sdk_file)).Object;
            const params = (try jsonObjGetRequired(method_obj, "Params", sdk_file)).Array;

            const count = method_conflicts.get(method_name) orelse 0;
            try method_conflicts.put(method_name, count + 1);

            try out_writer.print("        // NOTE: method is namespaced with interface name to avoid conflicts for now\n", .{});
            try out_writer.print("        pub fn {s}_{s}", .{com_pool_name, method_name});
            if (count > 0) {
                try out_writer.print("{}", .{count});
            }
            try out_writer.print("(self: *const T", .{});
            for (params.items) |*param_node_ptr| {
                const param_obj = param_node_ptr.Object;
                try jsonObjEnforceKnownFieldsOnly(param_obj, &[_][]const u8 {"Name", "Type", "Attrs"}, sdk_file);
                const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).String;
                const param_type = (try jsonObjGetRequired(param_obj, "Type", sdk_file)).Object;
                const param_options = processParamAttrs((try jsonObjGetRequired(param_obj, "Attrs", sdk_file)).Array, .var_decl);
                // NOTE: don't need to call addTypeRefs because it was already called in generateFunction above
                const param_type_formatter = fmtTypeRef(param_type, param_options, .top_level, sdk_file);
                try out_writer.print(", {s}: {}", .{std.zig.fmtId(param_name), param_type_formatter});
            }
            // NOTE: don't need to call addTypeRefs because it was already called in generateFunction above
            // TODO: set is_const, in and out properly
            const return_type_formatter = fmtTypeRef(return_type, .{ .reason = .var_decl, .is_const = false, .in = false, .out = false }, .top_level, sdk_file);
            try out_writer.print(") callconv(.Inline) {} {{\n", .{return_type_formatter});
            try out_writer.print("            return @ptrCast(*const {s}.VTable, self.vtable).{s}(@ptrCast(*const {0s}, self)", .{com_pool_name, std.zig.fmtId(method_name)});
            for (params.items) |*param_node_ptr| {
                const param_obj = param_node_ptr.Object;
                const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).String;
                try out_writer.print(", {s}", .{std.zig.fmtId(param_name)});
            }
            try out_writer.print(");\n", .{});
            try out_writer.print("        }}\n", .{});
        }
    }
    try out_writer.print("    }};}}\n", .{});
    try out_writer.print("    pub usingnamespace MethodMixin(@This());\n", .{});
    try out_writer.print("}};\n", .{});
}

fn processParamAttrs(attrs: json.Array, reason: TypeRefFormatter.Reason) TypeRefFormatter.Options {
    var opts = TypeRefFormatter.Options { .reason = reason };
    for (attrs.items) |*attr_node_ptr| {
        const attr_str = attr_node_ptr.String;
        if (std.mem.eql(u8, attr_str, "Const")) {
            opts.is_const = true;
        } else if (std.mem.eql(u8, attr_str, "In")) {
            opts.in = true;
        } else if (std.mem.eql(u8, attr_str, "Out")) {
            opts.out = true;
        } else if (std.mem.eql(u8, attr_str, "Optional")) {
            opts.optional = true;
        } else if (std.mem.eql(u8, attr_str, "RetVal")) {
            opts.ret_val = true;
        } else if (std.mem.eql(u8, attr_str, "NotNullTerminated")) {
            opts.not_null_term = true;
        } else if (std.mem.eql(u8, attr_str, "NullNullTerminated")) {
            opts.null_null_term = true;
        } else if (std.mem.eql(u8, attr_str, "ComOutPtr")) {
            opts.com_out_ptr = true;
        } else {
            jsonPanicMsg("unhandled custom param attribute '{s}'", .{attr_str});
        }
    }
    return opts;
}

// Skip these function pointers to workaround: https://github.com/ziglang/zig/issues/4476
const func_ptr_dependency_loop_problems = std.ComptimeStringMap(Nothing, .{
    .{ "FREEOBJPROC", .{} },
    .{ "LPDDHAL_WAITFORVERTICALBLANK", .{} },
});

// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// TODO: remove this when I figure out how to deal with these conflicts
//       they are top-level symbols that conflict with nested type names,
//       Zig doesn't seem to allow a nested type to shadow/overwrite a top-level type
// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
const dhcp_type_conflicts = std.ComptimeStringMap(Nothing, .{
    .{ "DHCP_SUBNET_ELEMENT_UNION", .{} },
    .{ "DHCP_OPTION_ELEMENT_UNION", .{} },
    .{ "DHCP_OPTION_SCOPE_UNION6", .{} },
    .{ "DHCP_CLIENT_SEARCH_UNION", .{} },
    .{ "DHCP_SUBNET_ELEMENT_UNION_V4", .{} },
    .{ "DHCP_SUBNET_ELEMENT_UNION_V6", .{} },
});
// TODO: this is a set of enums whose value symbols conflict with other symbols
const enums_with_value_conflicts = std.ComptimeStringMap(Nothing, .{
    .{ "ProcessAccessRights", .{} },
    .{ "MLOperatorTensorDataType", .{} },
    .{ "MLOperatorExecutionType", .{} },
    .{ "MLOperatorEdgeType", .{} },
    .{ "JsRuntimeVersion", .{} },
    .{ "__MIDL___MIDL_itf_autosvcs_0001_0159_0002", .{} },

});

const funcs_with_issues = std.ComptimeStringMap(Nothing, .{
    // These functions don't work yet because Zig doesn't support the 16-byte Guid struct in the C ABI yet
    // See: https://github.com/ziglang/zig/issues/1481
    .{ "CorePrinterDriverInstalledA", .{} },
    .{ "CorePrinterDriverInstalledW", .{} },
});

const FuncPtrKind = enum { ptr, fixed, com };

fn generateFunction(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, function_obj: json.ObjectMap, func_kind: FuncPtrKind, suffix: ?u8, optional_self_type: ?[]const u8) !void {
    const prefix = if (func_kind == .com) "        " else "";
    switch (func_kind) {
        .fixed => try jsonObjEnforceKnownFieldsOnly(function_obj, &[_][]const u8 {"Name", "SetLastError", "DllImport", "ReturnType", "Params"}, sdk_file),
        .ptr, .com => try jsonObjEnforceKnownFieldsOnly(function_obj, &[_][]const u8 {"Kind", "Name", "SetLastError", "ReturnType", "Params"}, sdk_file),
    }

    const func_name_tmp = (try jsonObjGetRequired(function_obj, "Name", sdk_file)).String;
    const set_last_error = (try jsonObjGetRequired(function_obj, "SetLastError", sdk_file)).Bool;
    const dll_import = if (func_kind == .fixed) (try jsonObjGetRequired(function_obj, "DllImport", sdk_file)).String else "";
    const return_type = (try jsonObjGetRequired(function_obj, "ReturnType", sdk_file)).Object;
    const params = (try jsonObjGetRequired(function_obj, "Params", sdk_file)).Array;

    if (func_kind == .fixed) {
        try sdk_file.func_exports.put(try global_symbol_pool.add(func_name_tmp), .{});
    }

    if (funcs_with_issues.get(func_name_tmp)) |_| {
        try out_writer.print("{s}// This function from dll '{s}' is being skipped because it has some sort of issue\n", .{prefix, dll_import});
        try out_writer.print("{s}pub fn {s}() void {{ @panic(\"this function is not working\"); }}\n", .{prefix, func_name_tmp});
        return;
    }

    switch (func_kind) {
        .fixed => {
            jsonEnforce(suffix == null);
            try out_writer.print("{s}pub extern \"{s}\" fn {s}(\n", .{prefix, dll_import, std.zig.fmtId(func_name_tmp)});
        },
        .ptr => {
            jsonEnforce(suffix == null);
            try out_writer.print("{s}pub const {s} = fn(\n", .{prefix, std.zig.fmtId(func_name_tmp)});
        },
        .com => {
            if (suffix) |s| {
                try out_writer.print("{s}{s}{}", .{prefix, func_name_tmp, s});
            } else {
                try out_writer.print("{s}{s}", .{prefix, std.zig.fmtId(func_name_tmp)});
            }
            try out_writer.print(": fn(\n", .{});
        },
    }
    if (optional_self_type) |self_type| {
        try out_writer.print("{s}    self: *const {s},\n", .{prefix, self_type});
    }
    for (params.items) |*param_node_ptr| {
        const param_obj = param_node_ptr.Object;
        try jsonObjEnforceKnownFieldsOnly(param_obj, &[_][]const u8 {"Name", "Type", "Attrs"}, sdk_file);
        const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).String;
        const param_type = (try jsonObjGetRequired(param_obj, "Type", sdk_file)).Object;
        const param_options = processParamAttrs((try jsonObjGetRequired(param_obj, "Attrs", sdk_file)).Array, .var_decl);
        const param_type_formatter = try addTypeRefs(sdk_file, param_type, param_options);
        try out_writer.print("{s}    {s}: {},\n", .{prefix, std.zig.fmtId(param_name), param_type_formatter});
    }
    // TODO: set is_const, in and out properly
    const return_type_formatter = try addTypeRefs(sdk_file, return_type, .{ .reason = .var_decl, .is_const = false, .in = false, .out = false });
    const term = if (func_kind == .com) "," else ";";
    try out_writer.print("{s}) callconv(@import(\"std\").os.windows.WINAPI) {}{s}\n", .{prefix, return_type_formatter, term});
}

fn getPoolStringWithParts(a: *std.mem.Allocator, slices: []const []const u8) ![]const u8 {
    const tmp = try std.mem.concat(a, u8, slices);
    defer a.free(tmp);
    return try global_symbol_pool.add(tmp);
}

fn generateUnicodeAliases(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, unicode_aliases: []json.Value) !void {
    try out_writer.writeAll("pub usingnamespace switch (@import(\"../zig.zig\").unicode_mode) {\n");
    try out_writer.writeAll("    .ansi => struct {\n");
    for (unicode_aliases) |*alias_node_ptr| {
        try out_writer.print("        pub const {s} = {0s}A;\n", .{alias_node_ptr.String});
    }
    try out_writer.writeAll("    },\n");
    try out_writer.writeAll("    .wide => struct {\n");
    for (unicode_aliases) |*alias_node_ptr| {
        try out_writer.print("        pub const {s} = {0s}W;\n", .{alias_node_ptr.String});
    }
    try out_writer.writeAll("    },\n");
    try out_writer.writeAll("    .unspecified => if (@import(\"builtin\").is_test) struct {\n");
    for (unicode_aliases) |*alias_node_ptr| {
        try out_writer.print("        pub const {s} = *opaque{{}};\n", .{alias_node_ptr.String});
    }
    try out_writer.writeAll("    } else struct {\n");
    for (unicode_aliases) |*alias_node_ptr| {
        try out_writer.print("        pub const {s} = @compileError(\"'{0s}' requires that UNICODE be set to true or false in the root module\");\n", .{alias_node_ptr.String});
    }
    try out_writer.writeAll("    },\n");
    try out_writer.writeAll("};");
}

pub fn SliceFormatter(comptime T: type, comptime spec: []const u8) type { return struct {
    slice: []const T,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        var first : bool = true;
        for (self.slice) |e| {
            if (first) {
                first = false;
            } else {
                try writer.writeAll(", ");
            }
            try std.fmt.format(writer, "{" ++ spec ++ "}", .{e});
        }
    }
};}
pub fn formatSliceT(comptime T: type, comptime spec: []const u8, slice: []const T) SliceFormatter(T, spec) {
    return .{ .slice = slice };
}
// TODO: implement this
//pub fn formatSlice(slice: anytype) SliceFormatter(T) {
//    return .{ .slice = slice };
//}

fn jsonPanic() noreturn {
    @panic("an assumption about the json format was violated");
}
fn jsonPanicMsg(comptime msg: []const u8, args: anytype) noreturn {
    std.debug.panic("an assumption about the json format was violated: " ++ msg, args);
}

fn jsonEnforce(cond: bool) void {
    if (!cond) {
        jsonPanic();
    }
}
fn jsonEnforceMsg(cond: bool, comptime msg: []const u8, args: anytype) void {
    if (!cond) {
        jsonPanicMsg(msg, args);
    }
}

fn jsonObjEnforceKnownFieldsOnly(map: json.ObjectMap, known_fields: []const []const u8, file_thing: anytype) !void {
    if (@TypeOf(file_thing) == *SdkFile or @TypeOf(file_thing) == *const SdkFile)
        return jsonObjEnforceKnownFieldsOnlyImpl(map, known_fields, file_thing.json_basename);
    if (@TypeOf(file_thing) == []const u8)
        return jsonObjEnforceKnownFieldsOnlyImpl(map, known_fields, file_thing);
    @compileError("unhandled file_thing type: " ++ @typeName(@TypeOf(file_thing)));
}

fn jsonObjEnforceKnownFieldsOnlyImpl(map: json.ObjectMap, known_fields: []const []const u8, file_for_error: []const u8) !void {
    var it = map.iterator();
    fieldLoop: while (it.next()) |kv| {
        for (known_fields) |known_field| {
            if (std.mem.eql(u8, known_field, kv.key))
                continue :fieldLoop;
        }
        std.debug.warn("{s}: Error: JSON object has unknown field '{s}', expected one of: {}\n", .{file_for_error, kv.key, formatSliceT([]const u8, "s", known_fields)});
        jsonPanic();
    }
}

fn jsonObjGetRequired(map: json.ObjectMap, field: []const u8, file_thing: anytype) !json.Value {
    if (@TypeOf(file_thing) == *SdkFile or @TypeOf(file_thing) == *const SdkFile)
        return jsonObjGetRequiredImpl(map, field, file_thing.json_basename);
    if (@TypeOf(file_thing) == []const u8)
        return jsonObjGetRequiredImpl(map, field, file_thing);
    @compileError("unhandled file_thing type: " ++ @typeName(@TypeOf(file_thing)));
}
fn jsonObjGetRequiredImpl(map: json.ObjectMap, field: []const u8, file_for_error: []const u8) !json.Value {
    return map.get(field) orelse {
        // TODO: print file location?
        std.debug.warn("{s}: json object is missing '{s}' field: {}\n", .{file_for_error, field, fmtJson(map)});
        jsonPanic();
    };
}

const JsonFormatter = struct {
    value: json.Value,
    pub fn format(
        self: JsonFormatter,
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        try std.json.stringify(self.value, .{}, writer);
    }
};
pub fn fmtJson(value: anytype) JsonFormatter {
    if (@TypeOf(value) == json.ObjectMap) {
        return .{ .value = .{ .Object = value } };
    }
    if (@TypeOf(value) == json.Array) {
        return .{ .value = .{ .Array = value } };
    }
    if (@TypeOf(value) == []json.Value) {
        return .{ .value = .{ .Array = json.Array  { .items = value, .capacity = value.len, .allocator = undefined } } };
    }
    return .{ .value = value };
}

fn cleanDir(dir: std.fs.Dir, sub_path: []const u8) !void {
    try dir.deleteTree(sub_path);
    const MAX_ATTEMPTS = 30;
    var attempt : u32 = 1;
    while (true) : (attempt += 1) {
        if (attempt > MAX_ATTEMPTS) {
            std.debug.warn("Error: failed to delete '{s}' after {} attempts\n", .{sub_path, MAX_ATTEMPTS});
            return error.AlreadyReported;
        }
        // ERROR: windows.OpenFile is not handling error.Unexpected NTSTATUS=0xc0000056
        dir.makeDir(sub_path) catch |e| switch (e) {
            else => {
                std.debug.warn("[DEBUG] makedir failed with {}\n", .{e});
                //return error.AlreadyReported;
                continue;
            },
        };
        break;
    }

}

fn getcwd(a: *std.mem.Allocator) ![]u8 {
    var path_buf : [std.fs.MAX_PATH_BYTES]u8 = undefined;
    const path = try std.os.getcwd(&path_buf);
    const path_allocated = try a.alloc(u8, path.len);
    std.mem.copy(u8, path_allocated, path);
    return path_allocated;
}
